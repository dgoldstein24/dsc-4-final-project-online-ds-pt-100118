{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: \n",
    "* Student pace: self paced / part time / full time\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: \n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import initial pacages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in csv created from basketballreference.com open source data\n",
    "#All stats are per 36 minutes played\n",
    "\n",
    "\n",
    "df = pd.read_csv('nba_mod_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Player</th>\n",
       "      <th>concat</th>\n",
       "      <th>count</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>...</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>Honors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>Álex Abrines</td>\n",
       "      <td>2019Álex Abrines</td>\n",
       "      <td>1</td>\n",
       "      <td>SG</td>\n",
       "      <td>25</td>\n",
       "      <td>OKC</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>Quincy Acy</td>\n",
       "      <td>2019Quincy Acy</td>\n",
       "      <td>1</td>\n",
       "      <td>PF</td>\n",
       "      <td>28</td>\n",
       "      <td>PHO</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>Jaylen Adams</td>\n",
       "      <td>2019Jaylen Adams</td>\n",
       "      <td>1</td>\n",
       "      <td>PG</td>\n",
       "      <td>22</td>\n",
       "      <td>ATL</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>2019Steven Adams</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>25</td>\n",
       "      <td>OKC</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>2669</td>\n",
       "      <td>...</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>14.9</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>Bam Adebayo</td>\n",
       "      <td>2019Bam Adebayo</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>21</td>\n",
       "      <td>MIA</td>\n",
       "      <td>82</td>\n",
       "      <td>28</td>\n",
       "      <td>1913</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8.1</td>\n",
       "      <td>11.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>13.7</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year        Player            concat  count Pos  Age   Tm   G  GS    MP  \\\n",
       "0  2019  Álex Abrines  2019Álex Abrines      1  SG   25  OKC  31   2   588   \n",
       "1  2019    Quincy Acy    2019Quincy Acy      1  PF   28  PHO  10   0   123   \n",
       "2  2019  Jaylen Adams  2019Jaylen Adams      1  PG   22  ATL  34   1   428   \n",
       "3  2019  Steven Adams  2019Steven Adams      1   C   25  OKC  80  80  2669   \n",
       "4  2019   Bam Adebayo   2019Bam Adebayo      1   C   21  MIA  82  28  1913   \n",
       "\n",
       "   ...  ORB  DRB   TRB  AST  STL  BLK  TOV   PF   PTS     Honors  \n",
       "0  ...  0.3  2.6   2.9  1.2  1.0  0.4  0.9  3.2  10.1  No_Honors  \n",
       "1  ...  0.9  6.4   7.3  2.3  0.3  1.2  1.2  7.0   5.0  No_Honors  \n",
       "2  ...  0.9  4.1   5.0  5.5  1.2  0.4  2.4  3.8   9.1  No_Honors  \n",
       "3  ...  5.3  5.0  10.3  1.7  1.6  1.0  1.8  2.8  14.9  No_Honors  \n",
       "4  ...  3.1  8.1  11.2  3.5  1.3  1.2  2.3  3.8  13.7  No_Honors  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preview the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicate entries for players who moved mid-season\n",
    "indeces_to_remove = list(df[(df['count'] > 1) & (df['Tm'] != 'TOT')].index)\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove columns used to find repeat entries\n",
    "df = df.drop(['concat', 'count'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a DataFrame without player names, games, played, and team\n",
    "df_anon = df.drop(['Player', 'G', 'GS', 'Tm'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year         0\n",
       "Pos          0\n",
       "Age          0\n",
       "MP           0\n",
       "FG           5\n",
       "FGA          5\n",
       "FG%         63\n",
       "3P           5\n",
       "3PA          5\n",
       "3P%       1864\n",
       "2P           5\n",
       "2PA          5\n",
       "2P%        107\n",
       "FT           5\n",
       "FTA          5\n",
       "FT%        541\n",
       "ORB          5\n",
       "DRB          5\n",
       "TRB          5\n",
       "AST          5\n",
       "STL          5\n",
       "BLK          5\n",
       "TOV          5\n",
       "PF           5\n",
       "PTS          5\n",
       "Honors       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for null values\n",
    "\n",
    "df_anon.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace nulls with 0\n",
    "#Can't use median because it assumes causes errors when using Standard Scaler \n",
    "\n",
    "for col in ['FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
    "           'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']:\n",
    "    df_anon[col] = df_anon[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm that all nulls are removed\n",
    "\n",
    "\n",
    "df_anon.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a df that has only stats and honors label\n",
    "df_quant_only = df_anon.drop(['Year', 'Pos', 'Age'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change data back from per36 to toatls in order to calculate another metric\n",
    "\n",
    "for col in ['FG', 'FGA', '3P', '3PA', '2P', '2PA', 'FT',\n",
    "       'FTA', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
    "       'PTS']:\n",
    "    df_quant_only[col] = (df_quant_only[col] / 36) * df_quant_only['MP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace nulls with 0\n",
    "#Can't use median because it assumes causes errors when using Standard Scaler \n",
    "\n",
    "for col in ['FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
    "           'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']:\n",
    "    df_quant_only[col] = df_quant_only[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilize True Shooting Percentage metric\n",
    "\n",
    "true_shooting_attempts = df_quant_only['FGA'] + (.44 * df_quant_only['FTA'])\n",
    "true_shooting_percentage = df_quant_only['PTS'] /  (2*true_shooting_attempts)\n",
    "df_quant_only['TSP'] = true_shooting_percentage\n",
    "\n",
    "df_quant_only['TSP'] = df_quant_only['TSP'].fillna(df_quant_only['TSP'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assist to turnover ratio measures risk-reducing playmaking ability, which is the ideal\n",
    "#for a basketball player\n",
    "\n",
    "df_quant_only['a/t_ratio'] = df_quant_only['AST'] / df_quant_only['TOV']\n",
    "df_quant_only['a/t_ratio'] = df_quant_only['a/t_ratio'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#I assume I will need to go back to per36 stats in order to avoid high multicolinearity\n",
    "#I will graph to confirm\n",
    "\n",
    "\n",
    "features_quant = df_quant_only.drop(['Honors'], axis = 1)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "#Check colinearity heat map\n",
    "sns.heatmap(features_quant.corr(), center=0);\n",
    "\n",
    "#Suspicion confirmed - need to change back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change data back from per36 to toatls in order to calculate another metric\n",
    "\n",
    "for col in ['FG', 'FGA', '3P', '3PA', '2P', '2PA', 'FT',\n",
    "       'FTA', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
    "       'PTS']:\n",
    "    df_quant_only[col] = (df_quant_only[col] / df_quant_only['MP']) * 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change data back from per36 to toatls in order to calculate another metric\n",
    "\n",
    "for col in ['FG', 'FGA', '3P', '3PA', '2P', '2PA', 'FT',\n",
    "       'FTA', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
    "       'PTS', 'TSP', 'a/t_ratio']:\n",
    "    df_quant_only[col]  = df_quant_only[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#Some entries have assists but no turnovers leading to an infinite assist to turnover ratio\n",
    "#I will replace those values with the 90th percentile value of a/t ratio\n",
    "\n",
    "percentile_90 = int(len(sorted(df_quant_only['a/t_ratio'], reverse = True)) * .9)\n",
    "\n",
    "ratio = df_quant_only['a/t_ratio']\n",
    "for index in range(len(ratio)):\n",
    "    if ratio[index] == math.inf:\n",
    "        ratio[index] = sorted(df_quant_only['a/t_ratio'])[percentile_90]\n",
    "df_quant_only['a/t_ratio'] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check multicollinearity matrix of the features\n",
    "\n",
    "features_quant = df_quant_only.drop(['Honors'], axis = 1)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "#Check colinearity heat map\n",
    "sns.heatmap(features_quant.corr(), center=0);\n",
    "\n",
    "#Per36 stats solved the prior issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First: With minutes played and original counting stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new df\n",
    "df_with_min = df_quant_only.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate target and features\n",
    "\n",
    "features_with_min = df_with_min.drop(['Honors'], axis = 1)\n",
    "target_with_min = df_with_min['Honors']\n",
    "\n",
    "#Standardize feature values with Standard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features_with_min = pd.DataFrame(scaler.fit_transform(features_with_min), columns = features_with_min.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicollinearity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check colinearity heat map\n",
    "sns.heatmap(scaled_features_with_min.corr(), center=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for colinearity numerically using .75 as a cutoff\n",
    "\n",
    "def collinearity_dict(dataframe, cutoff = .75):\n",
    "    df = dataframe\n",
    "    collinearity = {}\n",
    "\n",
    "    for col_index in range(len(df.columns)):\n",
    "        too_high = []\n",
    "        for row_index in range(len(df.columns)):\n",
    "            if col_index != row_index:\n",
    "                if (abs(df.corr()) > cutoff).iloc[col_index][row_index] == True:\n",
    "                     too_high.append([df.columns[row_index]])\n",
    "        collinearity[df.columns[col_index]] = too_high\n",
    "    \n",
    "    return collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MP': [],\n",
       " 'FG': [['FGA'], ['2P'], ['PTS']],\n",
       " 'FGA': [['FG'], ['PTS']],\n",
       " 'FG%': [['2P%'], ['TSP']],\n",
       " '3P': [['3PA']],\n",
       " '3PA': [['3P']],\n",
       " '3P%': [],\n",
       " '2P': [['FG'], ['2PA']],\n",
       " '2PA': [['2P']],\n",
       " '2P%': [['FG%']],\n",
       " 'FT': [['FTA']],\n",
       " 'FTA': [['FT']],\n",
       " 'FT%': [],\n",
       " 'ORB': [['TRB']],\n",
       " 'DRB': [['TRB']],\n",
       " 'TRB': [['ORB'], ['DRB']],\n",
       " 'AST': [],\n",
       " 'STL': [],\n",
       " 'BLK': [],\n",
       " 'TOV': [],\n",
       " 'PF': [],\n",
       " 'PTS': [['FG'], ['FGA']],\n",
       " 'TSP': [['FG%']],\n",
       " 'a/t_ratio': []}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check colinearity overlap issues\n",
    "collinearity_dict(scaled_features_with_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop overlapping features + advanced statistics (to be used later)\n",
    "\n",
    "scaled_features_with_min = scaled_features_with_min.drop(['FG', 'FGA', 'TRB',\n",
    "                                                         'FTA', 'FG%', '2P',\n",
    "                                                         '3P', 'TSP', 'a/t_ratio'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MP': [],\n",
       " '3PA': [],\n",
       " '3P%': [],\n",
       " '2PA': [],\n",
       " '2P%': [],\n",
       " 'FT': [],\n",
       " 'FT%': [],\n",
       " 'ORB': [],\n",
       " 'DRB': [],\n",
       " 'AST': [],\n",
       " 'STL': [],\n",
       " 'BLK': [],\n",
       " 'TOV': [],\n",
       " 'PF': [],\n",
       " 'PTS': []}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Double check multicolinearity\n",
    "\n",
    "collinearity_dict(scaled_features_with_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confirm with visualization\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "#Check colinearity heat map\n",
    "sns.heatmap(scaled_features_with_min.corr(), center=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import package for train and test sets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine pipeline test accuracy: 0.9835212489158717\n",
      "Decision Tree pipeline test accuracy: 0.9778837814397224\n",
      "Random Forest pipeline test accuracy: 0.9830875975715525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Create train and test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features_with_min, target_with_min, test_size = .2, random_state = 123)\n",
    "\n",
    "#Conduct Simple Classifications\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Create pipeline for SVM  model\n",
    "pipe_svm = Pipeline([('clf', svm.SVC(random_state=123))])\n",
    "\n",
    "#Create pipeline for Decision Tree model      \n",
    "pipe_tree = Pipeline([\n",
    "        ('clf', DecisionTreeClassifier(random_state=123))])\n",
    "\n",
    "#Create pipeline for Random Forest Model analysis\n",
    "pipe_rf = Pipeline([\n",
    "        ('clf', RandomForestClassifier(random_state=123))])\n",
    "\n",
    "#Loop through the pipelines to fit each pipeline to the dataset\n",
    "pipes = [pipe_svm, pipe_tree, pipe_rf]\n",
    "pipeline_names = ['Support Vector Machine','Decision Tree','Random Forest']\n",
    "for pipe in pipes:\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "# Compare model accuracies with default parameters\n",
    "for index, val in enumerate(pipes):\n",
    "    print('{} pipeline test accuracy: {}'.format(pipeline_names[index], val.score(X_test, y_test)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
      "[CV] clf__C=0.1, clf__kernel=linear ..................................\n",
      "[CV] ................... clf__C=0.1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=0.1, clf__kernel=linear ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... clf__C=0.1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=0.1, clf__kernel=linear ..................................\n",
      "[CV] ................... clf__C=0.1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=1, clf__kernel=linear ....................................\n",
      "[CV] ..................... clf__C=1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=1, clf__kernel=linear ....................................\n",
      "[CV] ..................... clf__C=1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=1, clf__kernel=linear ....................................\n",
      "[CV] ..................... clf__C=1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=10, clf__kernel=linear ...................................\n",
      "[CV] .................... clf__C=10, clf__kernel=linear, total=   0.3s\n",
      "[CV] clf__C=10, clf__kernel=linear ...................................\n",
      "[CV] .................... clf__C=10, clf__kernel=linear, total=   0.4s\n",
      "[CV] clf__C=10, clf__kernel=linear ...................................\n",
      "[CV] .................... clf__C=10, clf__kernel=linear, total=   0.3s\n",
      "[CV] clf__C=1, clf__gamma=0.001, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=1, clf__gamma=0.001, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=1, clf__gamma=0.001, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=1, clf__gamma=0.001, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=1, clf__gamma=0.001, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=1, clf__gamma=0.001, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=1, clf__gamma=0.01, clf__kernel=rbf ......................\n",
      "[CV] ....... clf__C=1, clf__gamma=0.01, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=1, clf__gamma=0.01, clf__kernel=rbf ......................\n",
      "[CV] ....... clf__C=1, clf__gamma=0.01, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=1, clf__gamma=0.01, clf__kernel=rbf ......................\n",
      "[CV] ....... clf__C=1, clf__gamma=0.01, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=10, clf__gamma=0.001, clf__kernel=rbf ....................\n",
      "[CV] ..... clf__C=10, clf__gamma=0.001, clf__kernel=rbf, total=   0.2s\n",
      "[CV] clf__C=10, clf__gamma=0.001, clf__kernel=rbf ....................\n",
      "[CV] ..... clf__C=10, clf__gamma=0.001, clf__kernel=rbf, total=   0.2s\n",
      "[CV] clf__C=10, clf__gamma=0.001, clf__kernel=rbf ....................\n",
      "[CV] ..... clf__C=10, clf__gamma=0.001, clf__kernel=rbf, total=   0.2s\n",
      "[CV] clf__C=10, clf__gamma=0.01, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=10, clf__gamma=0.01, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=10, clf__gamma=0.01, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=10, clf__gamma=0.01, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=10, clf__gamma=0.01, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=10, clf__gamma=0.01, clf__kernel=rbf, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 162 out of 162 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=30 ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=30, total=   0.4s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=30 ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=30, total=   0.4s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=30, total=   0.4s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=50, total=   0.6s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=50, total=   0.6s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=50, total=   0.6s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=70, total=   0.9s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=70, total=   0.9s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=70, total=   0.9s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=30, total=   0.4s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=30, total=   0.4s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=30, total=   0.4s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=50, total=   0.6s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=50, total=   0.6s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=50, total=   0.6s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=70, total=   0.9s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=70, total=   0.9s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=70, total=   0.9s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=30, total=   0.4s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=30, total=   0.4s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=30, total=   0.4s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=50, total=   0.6s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=50, total=   0.6s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=50, total=   0.6s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=70, total=   0.9s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=70, total=   0.9s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=70, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   18.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for SVM 0.9771248915871639\n",
      "Best params for SVM {'clf__C': 10, 'clf__gamma': 0.01, 'clf__kernel': 'rbf'}\n",
      "\n",
      "Best accuracy for Random Forest 0.9727883781439722\n",
      "Best params for Random Forest {'clf__criterion': 'entropy', 'clf__max_depth': 4, 'clf__min_samples_leaf': 0.05, 'clf__min_samples_split': 0.05, 'clf__n_estimators': 120}\n",
      "\n",
      "Best accuracy for Adaboost 0.9757155247181266\n",
      "Best params for Adaboost {'clf__learning_rate': 0.5, 'clf__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "#Grid search to find best parameters\n",
    "\n",
    "\n",
    "#SVM\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Create SVM pipeline\n",
    "pipe_svm = Pipeline([('clf', svm.SVC(random_state = 123))])\n",
    "\n",
    "# Set grid search parameters for SVM\n",
    "param_grid_svm = [\n",
    "  {'clf__C': [0.1, 1, 10]  , 'clf__kernel': ['linear']},\n",
    "  {'clf__C': [1, 10], 'clf__gamma': [0.001, 0.01], 'clf__kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# Construct grid search using the SVM pipeline and grid search parameters\n",
    "gs_svm = GridSearchCV(estimator=pipe_svm,\n",
    "            param_grid=param_grid_svm,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit SVM model using grid search\n",
    "gs_svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Random Forest\n",
    "\n",
    "#Create Random Forest pipeline\n",
    "pipe_rf = Pipeline([\n",
    "            ('clf', RandomForestClassifier(random_state = 123))])\n",
    "\n",
    "# Set grid search parameters for Random Forest\n",
    "param_grid_forest = [ \n",
    "  {'clf__n_estimators': [120],\n",
    "   'clf__criterion': ['entropy', 'gini'], \n",
    "   'clf__max_depth': [4, 5, 6],  \n",
    "   'clf__min_samples_leaf':[0.05 ,0.1, 0.2],  \n",
    "   'clf__min_samples_split':[0.05 ,0.1, 0.2]\n",
    "  }\n",
    "]\n",
    "\n",
    "# Construct grid search\n",
    "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "            param_grid=param_grid_forest,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit Random Forest model using grid search\n",
    "gs_rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Adaboost\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Construct Adaboost pipeline\n",
    "pipe_ab = Pipeline([\n",
    "            ('clf', AdaBoostClassifier(random_state = 123))])\n",
    "\n",
    "# Set grid search params for Adaboost\n",
    "adaboost_param_grid = {\n",
    "    'clf__n_estimators': [30, 50, 70],\n",
    "    'clf__learning_rate': [1.0, 0.5, 0.1]\n",
    "}\n",
    "\n",
    "# Construct grid search\n",
    "gs_ab = GridSearchCV(estimator=pipe_ab,\n",
    "            param_grid=adaboost_param_grid,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit Adaboost model using grid search\n",
    "gs_ab.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Print out the best accuracy scores and parameters for each model\n",
    "\n",
    "# Best accuracy SVM\n",
    "print('Best accuracy for SVM {}'.format(gs_svm.best_score_))\n",
    "# Best params SVM\n",
    "print('Best params for SVM {}'.format(gs_svm.best_params_))\n",
    "\n",
    "print()\n",
    "\n",
    "# Best accuracy Random Forest\n",
    "print('Best accuracy for Random Forest {}'.format(gs_rf.best_score_))\n",
    "# Best params Random Forest\n",
    "print('Best params for Random Forest {}'.format(gs_rf.best_params_))\n",
    "\n",
    "print()\n",
    "\n",
    "# Best accuracy Adaboost\n",
    "print('Best accuracy for Adaboost {}'.format(gs_ab.best_score_))\n",
    "# Best params Adaboost\n",
    "print('Best params for Adaboost {}'.format(gs_ab.best_params_))\n",
    "\n",
    "#Highest accuracy - SVM with C = 10, 'clf__gamma' = .01, and kernel = 'rbf'\n",
    "\n",
    "#Find classifier accuracy for SVM with best parameters\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#create SVM pipeline with best parameters\n",
    "pipe_svm_best = Pipeline([\n",
    "        ('clf', svm.SVC(C= 1, kernel = 'linear', random_state=123))])\n",
    "\n",
    "#Fit model to the dataaset\n",
    "pipe_svm_best.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "preds = pipe_svm_best.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for SVM 0.9771248915871639\n",
      "Best params for SVM {'clf__C': 10, 'clf__gamma': 0.01, 'clf__kernel': 'rbf'}\n",
      "\n",
      "Best accuracy for Random Forest 0.9727883781439722\n",
      "Best params for Random Forest {'clf__criterion': 'entropy', 'clf__max_depth': 4, 'clf__min_samples_leaf': 0.05, 'clf__min_samples_split': 0.05, 'clf__n_estimators': 120}\n",
      "\n",
      "Best accuracy for Adaboost 0.9757155247181266\n",
      "Best params for Adaboost {'clf__learning_rate': 0.5, 'clf__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "#Print out the best accuracy scores and parameters for each model\n",
    "\n",
    "# Best accuracy SVM\n",
    "print('Best accuracy for SVM {}'.format(gs_svm.best_score_))\n",
    "# Best params SVM\n",
    "print('Best params for SVM {}'.format(gs_svm.best_params_))\n",
    "\n",
    "print()\n",
    "\n",
    "# Best accuracy Random Forest\n",
    "print('Best accuracy for Random Forest {}'.format(gs_rf.best_score_))\n",
    "# Best params Random Forest\n",
    "print('Best params for Random Forest {}'.format(gs_rf.best_params_))\n",
    "\n",
    "print()\n",
    "\n",
    "# Best accuracy Adaboost\n",
    "print('Best accuracy for Adaboost {}'.format(gs_ab.best_score_))\n",
    "# Best params Adaboost\n",
    "print('Best params for Adaboost {}'.format(gs_ab.best_params_))\n",
    "\n",
    "#Highest accuracy - SVM with C = 10, 'clf__gamma' = .01, and kernel = 'rbf'\n",
    "\n",
    "#Find classifier accuracy for SVM with best parameters\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#create SVM pipeline with best parameters\n",
    "pipe_svm_best = Pipeline([\n",
    "        ('clf', svm.SVC(C= 10, gamma = .01, kernel = 'rbf', random_state=123))])\n",
    "\n",
    "#Fit model to the dataaset\n",
    "pipe_svm_best.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "preds = pipe_svm_best.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9839549002601908\n"
     ]
    }
   ],
   "source": [
    "#Test model accuracy\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second: Without minutes played, with original counting stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a quatnitative dataframe that does not include minutes played\n",
    "df_no_min = df_quant_only.drop(['MP'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove nulls\n",
    "\n",
    "for col in ['FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
    "           'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']:\n",
    "    df_no_min[col] = df_no_min[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate features and target\n",
    "features_no_min = df_no_min.drop(['Honors'], axis = 1)\n",
    "target_no_min = df_no_min['Honors']\n",
    "\n",
    "#Standardize feature values with Standard Scaler\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features_no_min = pd.DataFrame(scaler.fit_transform(features_no_min), columns = features_no_min.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop same multicolinearity columns\n",
    "\n",
    "scaled_features_no_min = scaled_features_no_min.drop(['FG', 'FGA', 'TRB',\n",
    "                                                      'FTA', 'FG%', '2P',\n",
    "                                                      '3P', 'TSP', 'a/t_ratio'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine pipeline test accuracy: 0.9822202948829142\n",
      "Decision Tree pipeline test accuracy: 0.9696444058976583\n",
      "Random Forest pipeline test accuracy: 0.9804856895056374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Create train and test splits with new set of features\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features_no_min, target_no_min, test_size = .2, random_state = 123)\n",
    "\n",
    "#Conduct Simple Classifications\n",
    "\n",
    "#Create pipeline for SVM  model\n",
    "pipe_svm = Pipeline([('clf', svm.SVC(random_state=123))])\n",
    "\n",
    "#Create pipeline for Decision Tree model      \n",
    "pipe_tree = Pipeline([\n",
    "        ('clf', DecisionTreeClassifier(random_state=123))])\n",
    "\n",
    "#Create pipeline for Random Forest Model analysis\n",
    "pipe_rf = Pipeline([\n",
    "        ('clf', RandomForestClassifier(random_state=123))])\n",
    "\n",
    "#Loop through the pipelines to fit each pipeline to the dataset\n",
    "pipes = [pipe_svm, pipe_tree, pipe_rf]\n",
    "pipeline_names = ['Support Vector Machine','Decision Tree','Random Forest']\n",
    "for pipe in pipes:\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "# Compare model accuracies with default parameters\n",
    "for index, val in enumerate(pipes):\n",
    "    print('{} pipeline test accuracy: {}'.format(pipeline_names[index], val.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
      "[CV] clf__C=0.1, clf__kernel=linear ..................................\n",
      "[CV] ................... clf__C=0.1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=0.1, clf__kernel=linear ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... clf__C=0.1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=0.1, clf__kernel=linear ..................................\n",
      "[CV] ................... clf__C=0.1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=1, clf__kernel=linear ....................................\n",
      "[CV] ..................... clf__C=1, clf__kernel=linear, total=   0.2s\n",
      "[CV] clf__C=1, clf__kernel=linear ....................................\n",
      "[CV] ..................... clf__C=1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=1, clf__kernel=linear ....................................\n",
      "[CV] ..................... clf__C=1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=10, clf__kernel=linear ...................................\n",
      "[CV] .................... clf__C=10, clf__kernel=linear, total=   0.7s\n",
      "[CV] clf__C=10, clf__kernel=linear ...................................\n",
      "[CV] .................... clf__C=10, clf__kernel=linear, total=   0.6s\n",
      "[CV] clf__C=10, clf__kernel=linear ...................................\n",
      "[CV] .................... clf__C=10, clf__kernel=linear, total=   0.6s\n",
      "[CV] clf__C=1, clf__gamma=0.001, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=1, clf__gamma=0.001, clf__kernel=rbf, total=   0.2s\n",
      "[CV] clf__C=1, clf__gamma=0.001, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=1, clf__gamma=0.001, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=1, clf__gamma=0.001, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=1, clf__gamma=0.001, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=1, clf__gamma=0.01, clf__kernel=rbf ......................\n",
      "[CV] ....... clf__C=1, clf__gamma=0.01, clf__kernel=rbf, total=   0.2s\n",
      "[CV] clf__C=1, clf__gamma=0.01, clf__kernel=rbf ......................\n",
      "[CV] ....... clf__C=1, clf__gamma=0.01, clf__kernel=rbf, total=   0.2s\n",
      "[CV] clf__C=1, clf__gamma=0.01, clf__kernel=rbf ......................\n",
      "[CV] ....... clf__C=1, clf__gamma=0.01, clf__kernel=rbf, total=   0.2s\n",
      "[CV] clf__C=10, clf__gamma=0.001, clf__kernel=rbf ....................\n",
      "[CV] ..... clf__C=10, clf__gamma=0.001, clf__kernel=rbf, total=   0.2s\n",
      "[CV] clf__C=10, clf__gamma=0.001, clf__kernel=rbf ....................\n",
      "[CV] ..... clf__C=10, clf__gamma=0.001, clf__kernel=rbf, total=   0.2s\n",
      "[CV] clf__C=10, clf__gamma=0.001, clf__kernel=rbf ....................\n",
      "[CV] ..... clf__C=10, clf__gamma=0.001, clf__kernel=rbf, total=   0.2s\n",
      "[CV] clf__C=10, clf__gamma=0.01, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=10, clf__gamma=0.01, clf__kernel=rbf, total=   0.2s\n",
      "[CV] clf__C=10, clf__gamma=0.01, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=10, clf__gamma=0.01, clf__kernel=rbf, total=   0.2s\n",
      "[CV] clf__C=10, clf__gamma=0.01, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=10, clf__gamma=0.01, clf__kernel=rbf, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 162 out of 162 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=30 ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=30, total=   0.4s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=30 ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=30, total=   0.4s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=30, total=   0.4s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=50, total=   0.6s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=50, total=   0.6s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=50, total=   0.6s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=70, total=   0.8s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=70, total=   0.9s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=70, total=   0.8s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=30, total=   0.4s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=30, total=   0.4s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=30, total=   0.4s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=50, total=   0.6s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=50, total=   0.6s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=50, total=   0.6s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=70, total=   0.8s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=70, total=   0.8s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=70, total=   0.8s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=30, total=   0.4s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=30, total=   0.4s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=30, total=   0.4s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=50, total=   0.6s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=50, total=   0.6s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=50, total=   0.6s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=70, total=   0.9s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=70, total=   0.8s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=70, total=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   17.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for SVM 0.9754986990459671\n",
      "Best params for SVM {'clf__C': 10, 'clf__gamma': 0.01, 'clf__kernel': 'rbf'}\n",
      "\n",
      "Best accuracy for Random Forest 0.9727883781439722\n",
      "Best params for Random Forest {'clf__criterion': 'entropy', 'clf__max_depth': 4, 'clf__min_samples_leaf': 0.05, 'clf__min_samples_split': 0.05, 'clf__n_estimators': 120}\n",
      "\n",
      "Best accuracy for Adaboost 0.9741977450130095\n",
      "Best params for Adaboost {'clf__learning_rate': 0.5, 'clf__n_estimators': 70}\n"
     ]
    }
   ],
   "source": [
    "#Grid search to find best parameters\n",
    "\n",
    "\n",
    "#SVM\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Create SVM pipeline\n",
    "pipe_svm = Pipeline([('clf', svm.SVC(random_state = 123))])\n",
    "\n",
    "# Set grid search parameters for SVM\n",
    "param_grid_svm = [\n",
    "  {'clf__C': [0.1, 1, 10]  , 'clf__kernel': ['linear']},\n",
    "  {'clf__C': [1, 10], 'clf__gamma': [0.001, 0.01], 'clf__kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# Construct grid search using the SVM pipeline and grid search parameters\n",
    "gs_svm = GridSearchCV(estimator=pipe_svm,\n",
    "            param_grid=param_grid_svm,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit SVM model using grid search\n",
    "gs_svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Random Forest\n",
    "\n",
    "#Create Random Forest pipeline\n",
    "pipe_rf = Pipeline([\n",
    "            ('clf', RandomForestClassifier(random_state = 123))])\n",
    "\n",
    "# Set grid search parameters for Random Forest\n",
    "param_grid_forest = [ \n",
    "  {'clf__n_estimators': [120],\n",
    "   'clf__criterion': ['entropy', 'gini'], \n",
    "   'clf__max_depth': [4, 5, 6],  \n",
    "   'clf__min_samples_leaf':[0.05 ,0.1, 0.2],  \n",
    "   'clf__min_samples_split':[0.05 ,0.1, 0.2]\n",
    "  }\n",
    "]\n",
    "\n",
    "# Construct grid search\n",
    "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "            param_grid=param_grid_forest,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit Random Forest model using grid search\n",
    "gs_rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Adaboost\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Construct Adaboost pipeline\n",
    "pipe_ab = Pipeline([\n",
    "            ('clf', AdaBoostClassifier(random_state = 123))])\n",
    "\n",
    "# Set grid search params for Adaboost\n",
    "adaboost_param_grid = {\n",
    "    'clf__n_estimators': [30, 50, 70],\n",
    "    'clf__learning_rate': [1.0, 0.5, 0.1]\n",
    "}\n",
    "\n",
    "# Construct grid search\n",
    "gs_ab = GridSearchCV(estimator=pipe_ab,\n",
    "            param_grid=adaboost_param_grid,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit Adaboost model using grid search\n",
    "gs_ab.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Print out the best accuracy scores and parameters for each model\n",
    "\n",
    "# Best accuracy SVM\n",
    "print('Best accuracy for SVM {}'.format(gs_svm.best_score_))\n",
    "# Best params SVM\n",
    "print('Best params for SVM {}'.format(gs_svm.best_params_))\n",
    "\n",
    "print()\n",
    "\n",
    "# Best accuracy Random Forest\n",
    "print('Best accuracy for Random Forest {}'.format(gs_rf.best_score_))\n",
    "# Best params Random Forest\n",
    "print('Best params for Random Forest {}'.format(gs_rf.best_params_))\n",
    "\n",
    "print()\n",
    "\n",
    "# Best accuracy Adaboost\n",
    "print('Best accuracy for Adaboost {}'.format(gs_ab.best_score_))\n",
    "# Best params Adaboost\n",
    "print('Best params for Adaboost {}'.format(gs_ab.best_params_))\n",
    "\n",
    "#Highest accuracy - SVM with C = 10, 'clf__gamma' = .01, and kernel = 'rbf'\n",
    "\n",
    "#Find classifier accuracy for SVM with best parameters\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#create SVM pipeline with best parameters\n",
    "pipe_svm_best = Pipeline([\n",
    "        ('clf', svm.SVC(C= 1, kernel = 'linear', random_state=123))])\n",
    "\n",
    "#Fit model to the dataaset\n",
    "pipe_svm_best.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "preds = pipe_svm_best.predict(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for SVM 0.9754986990459671\n",
      "Best params for SVM {'clf__C': 10, 'clf__gamma': 0.01, 'clf__kernel': 'rbf'}\n",
      "\n",
      "Best accuracy for Random Forest 0.9727883781439722\n",
      "Best params for Random Forest {'clf__criterion': 'entropy', 'clf__max_depth': 4, 'clf__min_samples_leaf': 0.05, 'clf__min_samples_split': 0.05, 'clf__n_estimators': 120}\n",
      "\n",
      "Best accuracy for Adaboost 0.9741977450130095\n",
      "Best params for Adaboost {'clf__learning_rate': 0.5, 'clf__n_estimators': 70}\n"
     ]
    }
   ],
   "source": [
    "#Print out the best accuracy scores and parameters for each model\n",
    "\n",
    "# Best accuracy SVM\n",
    "print('Best accuracy for SVM {}'.format(gs_svm.best_score_))\n",
    "# Best params SVM\n",
    "print('Best params for SVM {}'.format(gs_svm.best_params_))\n",
    "\n",
    "print()\n",
    "\n",
    "# Best accuracy Random Forest\n",
    "print('Best accuracy for Random Forest {}'.format(gs_rf.best_score_))\n",
    "# Best params Random Forest\n",
    "print('Best params for Random Forest {}'.format(gs_rf.best_params_))\n",
    "\n",
    "print()\n",
    "\n",
    "# Best accuracy Adaboost\n",
    "print('Best accuracy for Adaboost {}'.format(gs_ab.best_score_))\n",
    "# Best params Adaboost\n",
    "print('Best params for Adaboost {}'.format(gs_ab.best_params_))\n",
    "\n",
    "#Highest accuracy - SVM with C = 10, 'clf__gamma' = .01, and kernel = 'rbf'\n",
    "\n",
    "#Find classifier accuracy for SVM with best parameters\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#create SVM pipeline with best parameters\n",
    "pipe_svm_best = Pipeline([\n",
    "        ('clf', svm.SVC(C= 10,gamma = .01, kernel = 'rbf', random_state=123))])\n",
    "\n",
    "#Fit model to the dataaset\n",
    "pipe_svm_best.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "preds = pipe_svm_best.predict(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9822202948829142\n"
     ]
    }
   ],
   "source": [
    "#Test model accuracy\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With edited stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model is still far more accurate thatn I would have predicted \n",
    "#for it to be with minutes played excluded\n",
    "\n",
    "#The reason is that attempts is another indicator of playing tim\n",
    "#Next step: Try the model with a smaller selection of stats\n",
    "\n",
    "#Having points, attempts, and percentages may have some overcounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove asssist and turnovers - I will be using assist to turnover ratio\n",
    "df_no_min_edited = df_quant_only.drop(['AST', 'TOV', 'MP'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fouls committed tend not to be a large indicator of player performance, at least not traditionally\n",
    "\n",
    "df_no_min_edited.drop(['PF'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove shooting stats and replace with TSP \n",
    "df_no_min_edited.drop(['TRB', 'PTS', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'FT', 'FTA',\n",
    "       'FT%'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate target and features\n",
    "\n",
    "features_edited = df_no_min_edited.drop(['Honors'], axis = 1)\n",
    "target_edited= df_no_min_edited['Honors']\n",
    "\n",
    "#Standardize feature values with Standard Scaler\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features_edited = pd.DataFrame(scaler.fit_transform(features_edited), columns = features_edited.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine pipeline test accuracy: 0.9787510841283608\n",
      "Decision Tree pipeline test accuracy: 0.9509973980919341\n",
      "Random Forest pipeline test accuracy: 0.9778837814397224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Create train and test splits with edited features\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features_edited, target_edited, test_size = .2, random_state = 123)\n",
    "\n",
    "#Conduct Simple Classifications\n",
    "\n",
    "#Create pipeline for SVM  model\n",
    "pipe_svm = Pipeline([('clf', svm.SVC(random_state=123))])\n",
    "\n",
    "#Create pipeline for Decision Tree model      \n",
    "pipe_tree = Pipeline([\n",
    "        ('clf', DecisionTreeClassifier(random_state=123))])\n",
    "\n",
    "#Create pipeline for Random Forest Model analysis\n",
    "pipe_rf = Pipeline([\n",
    "        ('clf', RandomForestClassifier(random_state=123))])\n",
    "\n",
    "#Loop through the pipelines to fit each pipeline to the dataset\n",
    "pipes = [pipe_svm, pipe_tree, pipe_rf]\n",
    "pipeline_names = ['Support Vector Machine','Decision Tree','Random Forest']\n",
    "for pipe in pipes:\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "# Compare model accuracies with default parameters\n",
    "for index, val in enumerate(pipes):\n",
    "    print('{} pipeline test accuracy: {}'.format(pipeline_names[index], val.score(X_test, y_test)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
      "[CV] clf__C=0.1, clf__kernel=linear ..................................\n",
      "[CV] ................... clf__C=0.1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=0.1, clf__kernel=linear ..................................\n",
      "[CV] ................... clf__C=0.1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=0.1, clf__kernel=linear ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... clf__C=0.1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=1, clf__kernel=linear ....................................\n",
      "[CV] ..................... clf__C=1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=1, clf__kernel=linear ....................................\n",
      "[CV] ..................... clf__C=1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=1, clf__kernel=linear ....................................\n",
      "[CV] ..................... clf__C=1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=10, clf__kernel=linear ...................................\n",
      "[CV] .................... clf__C=10, clf__kernel=linear, total=   0.5s\n",
      "[CV] clf__C=10, clf__kernel=linear ...................................\n",
      "[CV] .................... clf__C=10, clf__kernel=linear, total=   0.5s\n",
      "[CV] clf__C=10, clf__kernel=linear ...................................\n",
      "[CV] .................... clf__C=10, clf__kernel=linear, total=   0.4s\n",
      "[CV] clf__C=1, clf__gamma=0.001, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=1, clf__gamma=0.001, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=1, clf__gamma=0.001, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=1, clf__gamma=0.001, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=1, clf__gamma=0.001, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=1, clf__gamma=0.001, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=1, clf__gamma=0.01, clf__kernel=rbf ......................\n",
      "[CV] ....... clf__C=1, clf__gamma=0.01, clf__kernel=rbf, total=   0.2s\n",
      "[CV] clf__C=1, clf__gamma=0.01, clf__kernel=rbf ......................\n",
      "[CV] ....... clf__C=1, clf__gamma=0.01, clf__kernel=rbf, total=   0.2s\n",
      "[CV] clf__C=1, clf__gamma=0.01, clf__kernel=rbf ......................\n",
      "[CV] ....... clf__C=1, clf__gamma=0.01, clf__kernel=rbf, total=   0.2s\n",
      "[CV] clf__C=10, clf__gamma=0.001, clf__kernel=rbf ....................\n",
      "[CV] ..... clf__C=10, clf__gamma=0.001, clf__kernel=rbf, total=   0.3s\n",
      "[CV] clf__C=10, clf__gamma=0.001, clf__kernel=rbf ....................\n",
      "[CV] ..... clf__C=10, clf__gamma=0.001, clf__kernel=rbf, total=   0.2s\n",
      "[CV] clf__C=10, clf__gamma=0.001, clf__kernel=rbf ....................\n",
      "[CV] ..... clf__C=10, clf__gamma=0.001, clf__kernel=rbf, total=   0.3s\n",
      "[CV] clf__C=10, clf__gamma=0.01, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=10, clf__gamma=0.01, clf__kernel=rbf, total=   0.6s\n",
      "[CV] clf__C=10, clf__gamma=0.01, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=10, clf__gamma=0.01, clf__kernel=rbf, total=   0.5s\n",
      "[CV] clf__C=10, clf__gamma=0.01, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=10, clf__gamma=0.01, clf__kernel=rbf, total=   0.5s\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    6.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 162 out of 162 | elapsed:   58.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=30 ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=30, total=   0.3s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=30 ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=30, total=   0.3s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=30, total=   0.3s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=50, total=   0.5s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=50, total=   0.5s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=50, total=   0.5s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=70, total=   0.7s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=70, total=   0.7s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=70, total=   0.7s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=30, total=   0.3s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=30, total=   0.3s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=30, total=   0.3s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=50, total=   0.5s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=50, total=   0.5s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=50, total=   0.5s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=70, total=   0.7s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=70, total=   0.7s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=70, total=   0.7s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=30, total=   0.3s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=30, total=   0.3s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=30, total=   0.3s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=50, total=   0.5s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=50, total=   0.5s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=50, total=   0.5s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=70, total=   0.7s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=70, total=   0.7s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=70, total=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   14.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('clf',\n",
       "                                        AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                                           base_estimator=None,\n",
       "                                                           learning_rate=1.0,\n",
       "                                                           n_estimators=50,\n",
       "                                                           random_state=123))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'clf__learning_rate': [1.0, 0.5, 0.1],\n",
       "                         'clf__n_estimators': [30, 50, 70]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid search to find best parameters\n",
    "\n",
    "\n",
    "#SVM\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Create SVM pipeline\n",
    "pipe_svm = Pipeline([('clf', svm.SVC(random_state=0))])\n",
    "\n",
    "# Set grid search parameters for SVM\n",
    "param_grid_svm = [\n",
    "  {'clf__C': [0.1, 1, 10]  , 'clf__kernel': ['linear']},\n",
    "  {'clf__C': [1, 10], 'clf__gamma': [0.001, 0.01], 'clf__kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# Construct grid search using the SVM pipeline and grid search parameters\n",
    "gs_svm = GridSearchCV(estimator=pipe_svm,\n",
    "            param_grid=param_grid_svm,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit SVM model using grid search\n",
    "gs_svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Random Forest\n",
    "\n",
    "#Create Random Forest pipeline\n",
    "pipe_rf = Pipeline([\n",
    "            ('clf', RandomForestClassifier(random_state = 123))])\n",
    "\n",
    "# Set grid search parameters for Random Forest\n",
    "param_grid_forest = [ \n",
    "  {'clf__n_estimators': [120],\n",
    "   'clf__criterion': ['entropy', 'gini'], \n",
    "   'clf__max_depth': [4, 5, 6],  \n",
    "   'clf__min_samples_leaf':[0.05 ,0.1, 0.2],  \n",
    "   'clf__min_samples_split':[0.05 ,0.1, 0.2]\n",
    "  }\n",
    "]\n",
    "\n",
    "# Construct grid search\n",
    "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "            param_grid=param_grid_forest,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit Random Forest model using grid search\n",
    "gs_rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Adaboost\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Construct Adaboost pipeline\n",
    "pipe_ab = Pipeline([\n",
    "            ('clf', AdaBoostClassifier(random_state = 123))])\n",
    "\n",
    "# Set grid search params for Adaboost\n",
    "adaboost_param_grid = {\n",
    "    'clf__n_estimators': [30, 50, 70],\n",
    "    'clf__learning_rate': [1.0, 0.5, 0.1]\n",
    "}\n",
    "\n",
    "# Construct grid search\n",
    "gs_ab = GridSearchCV(estimator=pipe_ab,\n",
    "            param_grid=adaboost_param_grid,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit Adaboost model using grid search\n",
    "gs_ab.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for SVM 0.9727883781439722\n",
      "Best params for SVM {'clf__C': 0.1, 'clf__kernel': 'linear'}\n",
      "\n",
      "Best accuracy for Random Forest 0.9727883781439722\n",
      "Best params for Random Forest {'clf__criterion': 'entropy', 'clf__max_depth': 4, 'clf__min_samples_leaf': 0.05, 'clf__min_samples_split': 0.05, 'clf__n_estimators': 120}\n",
      "\n",
      "Best accuracy for Adaboost 0.9727883781439722\n",
      "Best params for Adaboost {'clf__learning_rate': 0.1, 'clf__n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "#Print out the best accuracy scores and parameters for each model\n",
    "\n",
    "# Best accuracy SVM\n",
    "print('Best accuracy for SVM {}'.format(gs_svm.best_score_))\n",
    "# Best params SVM\n",
    "print('Best params for SVM {}'.format(gs_svm.best_params_))\n",
    "\n",
    "print()\n",
    "\n",
    "# Best accuracy Random Forest\n",
    "print('Best accuracy for Random Forest {}'.format(gs_rf.best_score_))\n",
    "# Best params Random Forest\n",
    "print('Best params for Random Forest {}'.format(gs_rf.best_params_))\n",
    "\n",
    "print()\n",
    "\n",
    "# Best accuracy Adaboost\n",
    "print('Best accuracy for Adaboost {}'.format(gs_ab.best_score_))\n",
    "# Best params Adaboost\n",
    "print('Best params for Adaboost {}'.format(gs_ab.best_params_))\n",
    "\n",
    "#Highest accuracy - SVM with C = .1 and kernel = 'linear'\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy with best model: 0.9787510841283608\n"
     ]
    }
   ],
   "source": [
    "#Find classifier accuracy for SVM with best parameters\n",
    "\n",
    "#create SVM pipeline with best parameters\n",
    "pipe_svm_best = Pipeline([\n",
    "        ('clf', svm.SVC(C= .1, kernel = 'linear', random_state=123))])\n",
    "\n",
    "#Fit model to the dataaset\n",
    "pipe_svm_best.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "preds = pipe_svm_best.predict(X_test)\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "#Test model accuracy\n",
    "print(\"Accuracy with best model: {}\".format(accuracy_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with different information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new df and drop further columns\n",
    "\n",
    "df_1 = df_no_min_edited.copy()\n",
    "df_1 = df_1.drop(['ORB', 'DRB', 'STL', 'BLK'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine pipeline test accuracy: 0.9787510841283608\n",
      "Decision Tree pipeline test accuracy: 0.9531656548135299\n",
      "Random Forest pipeline test accuracy: 0.9744145706851691\n",
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
      "[CV] clf__C=0.1, clf__kernel=linear ..................................\n",
      "[CV] ................... clf__C=0.1, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=0.1, clf__kernel=linear ..................................\n",
      "[CV] ................... clf__C=0.1, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=0.1, clf__kernel=linear ..................................\n",
      "[CV] ................... clf__C=0.1, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=1, clf__kernel=linear ....................................\n",
      "[CV] ..................... clf__C=1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=1, clf__kernel=linear ....................................\n",
      "[CV] ..................... clf__C=1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=1, clf__kernel=linear ....................................\n",
      "[CV] ..................... clf__C=1, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=10, clf__kernel=linear ...................................\n",
      "[CV] .................... clf__C=10, clf__kernel=linear, total=   0.1s\n",
      "[CV] clf__C=10, clf__kernel=linear ...................................\n",
      "[CV] .................... clf__C=10, clf__kernel=linear, total=   0.2s\n",
      "[CV] clf__C=10, clf__kernel=linear ...................................\n",
      "[CV] .................... clf__C=10, clf__kernel=linear, total=   0.2s\n",
      "[CV] clf__C=1, clf__gamma=0.001, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=1, clf__gamma=0.001, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=1, clf__gamma=0.001, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=1, clf__gamma=0.001, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=1, clf__gamma=0.001, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=1, clf__gamma=0.001, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=1, clf__gamma=0.01, clf__kernel=rbf ......................\n",
      "[CV] ....... clf__C=1, clf__gamma=0.01, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=1, clf__gamma=0.01, clf__kernel=rbf ......................\n",
      "[CV] ....... clf__C=1, clf__gamma=0.01, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=1, clf__gamma=0.01, clf__kernel=rbf ......................\n",
      "[CV] ....... clf__C=1, clf__gamma=0.01, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=10, clf__gamma=0.001, clf__kernel=rbf ....................\n",
      "[CV] ..... clf__C=10, clf__gamma=0.001, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=10, clf__gamma=0.001, clf__kernel=rbf ....................\n",
      "[CV] ..... clf__C=10, clf__gamma=0.001, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=10, clf__gamma=0.001, clf__kernel=rbf ....................\n",
      "[CV] ..... clf__C=10, clf__gamma=0.001, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=10, clf__gamma=0.01, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=10, clf__gamma=0.01, clf__kernel=rbf, total=   0.2s\n",
      "[CV] clf__C=10, clf__gamma=0.01, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=10, clf__gamma=0.01, clf__kernel=rbf, total=   0.1s\n",
      "[CV] clf__C=10, clf__gamma=0.01, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=10, clf__gamma=0.01, clf__kernel=rbf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.4s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.3s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 162 out of 162 | elapsed:   55.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=30 ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=30, total=   0.3s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=30 ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=30, total=   0.3s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=30, total=   0.3s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=50, total=   0.5s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=50, total=   0.5s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=50, total=   0.5s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=70, total=   0.6s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=70, total=   0.7s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=70, total=   0.6s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=30, total=   0.3s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=30, total=   0.3s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=30, total=   0.3s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=50, total=   0.5s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=50, total=   0.5s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=50, total=   0.5s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=70, total=   0.6s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=70, total=   0.6s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=70, total=   0.6s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=30, total=   0.3s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=30, total=   0.3s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=30, total=   0.3s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=50, total=   0.5s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=50, total=   0.5s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=50, total=   0.5s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=70, total=   0.7s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=70, total=   0.6s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=70, total=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   13.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('clf',\n",
       "                                        AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                                           base_estimator=None,\n",
       "                                                           learning_rate=1.0,\n",
       "                                                           n_estimators=50,\n",
       "                                                           random_state=123))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'clf__learning_rate': [1.0, 0.5, 0.1],\n",
       "                         'clf__n_estimators': [30, 50, 70]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run through process to see if the model changes\n",
    "\n",
    "features_1 = df_1.drop(['Honors'], axis = 1)\n",
    "target_1 =  df_1['Honors']\n",
    "\n",
    "#Standardize feature values with Standard Scaler\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features_1 = pd.DataFrame(scaler.fit_transform(features_1), columns = features_1.columns)\n",
    "\n",
    "\n",
    "\n",
    "#Create train and test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features_1, target_1, test_size = .2, random_state = 123)\n",
    "\n",
    "#Conduct Simple Classifications\n",
    "\n",
    "#Create pipeline for SVM  model\n",
    "pipe_svm = Pipeline([('clf', svm.SVC(random_state=123))])\n",
    "\n",
    "#Create pipeline for Decision Tree model      \n",
    "pipe_tree = Pipeline([\n",
    "        ('clf', DecisionTreeClassifier(random_state=123))])\n",
    "\n",
    "#Create pipeline for Random Forest Model analysis\n",
    "pipe_rf = Pipeline([\n",
    "        ('clf', RandomForestClassifier(random_state=123))])\n",
    "\n",
    "#Loop through the pipelines to fit each pipeline to the dataset\n",
    "pipes = [pipe_svm, pipe_tree, pipe_rf]\n",
    "pipeline_names = ['Support Vector Machine','Decision Tree','Random Forest']\n",
    "for pipe in pipes:\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "# Compare model accuracies with default parameters\n",
    "for index, val in enumerate(pipes):\n",
    "    print('{} pipeline test accuracy: {}'.format(pipeline_names[index], val.score(X_test, y_test)))\n",
    "    \n",
    "#Grid search to find best parameters\n",
    "\n",
    "\n",
    "#SVM\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Create SVM pipeline\n",
    "pipe_svm = Pipeline([('clf', svm.SVC(random_state=0))])\n",
    "\n",
    "# Set grid search parameters for SVM\n",
    "param_grid_svm = [\n",
    "  {'clf__C': [0.1, 1, 10]  , 'clf__kernel': ['linear']},\n",
    "  {'clf__C': [1, 10], 'clf__gamma': [0.001, 0.01], 'clf__kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# Construct grid search using the SVM pipeline and grid search parameters\n",
    "gs_svm = GridSearchCV(estimator=pipe_svm,\n",
    "            param_grid=param_grid_svm,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit SVM model using grid search\n",
    "gs_svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Random Forest\n",
    "\n",
    "#Create Random Forest pipeline\n",
    "pipe_rf = Pipeline([\n",
    "            ('clf', RandomForestClassifier(random_state = 123))])\n",
    "\n",
    "# Set grid search parameters for Random Forest\n",
    "param_grid_forest = [ \n",
    "  {'clf__n_estimators': [120],\n",
    "   'clf__criterion': ['entropy', 'gini'], \n",
    "   'clf__max_depth': [4, 5, 6],  \n",
    "   'clf__min_samples_leaf':[0.05 ,0.1, 0.2],  \n",
    "   'clf__min_samples_split':[0.05 ,0.1, 0.2]\n",
    "  }\n",
    "]\n",
    "\n",
    "# Construct grid search\n",
    "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "            param_grid=param_grid_forest,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit Random Forest model using grid search\n",
    "gs_rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Adaboost\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Construct Adaboost pipeline\n",
    "pipe_ab = Pipeline([\n",
    "            ('clf', AdaBoostClassifier(random_state = 123))])\n",
    "\n",
    "# Set grid search params for Adaboost\n",
    "adaboost_param_grid = {\n",
    "    'clf__n_estimators': [30, 50, 70],\n",
    "    'clf__learning_rate': [1.0, 0.5, 0.1]\n",
    "}\n",
    "\n",
    "# Construct grid search\n",
    "gs_ab = GridSearchCV(estimator=pipe_ab,\n",
    "            param_grid=adaboost_param_grid,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit Adaboost model using grid search\n",
    "gs_ab.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for SVM 0.9727883781439722\n",
      "Best params for SVM {'clf__C': 0.1, 'clf__kernel': 'linear'}\n",
      "\n",
      "Best accuracy for Random Forest 0.9727883781439722\n",
      "Best params for Random Forest {'clf__criterion': 'entropy', 'clf__max_depth': 4, 'clf__min_samples_leaf': 0.05, 'clf__min_samples_split': 0.05, 'clf__n_estimators': 120}\n",
      "\n",
      "Best accuracy for Adaboost 0.9727883781439722\n",
      "Best params for Adaboost {'clf__learning_rate': 0.5, 'clf__n_estimators': 30}\n",
      "\n",
      "Accuracy with best model: 0.9787510841283608\n"
     ]
    }
   ],
   "source": [
    "#Print out the best accuracy scores and parameters for each model\n",
    "\n",
    "# Best accuracy SVM\n",
    "print('Best accuracy for SVM {}'.format(gs_svm.best_score_))\n",
    "# Best params SVM\n",
    "print('Best params for SVM {}'.format(gs_svm.best_params_))\n",
    "\n",
    "print()\n",
    "\n",
    "# Best accuracy Random Forest\n",
    "print('Best accuracy for Random Forest {}'.format(gs_rf.best_score_))\n",
    "# Best params Random Forest\n",
    "print('Best params for Random Forest {}'.format(gs_rf.best_params_))\n",
    "\n",
    "print()\n",
    "\n",
    "# Best accuracy Adaboost\n",
    "print('Best accuracy for Adaboost {}'.format(gs_ab.best_score_))\n",
    "# Best params Adaboost\n",
    "print('Best params for Adaboost {}'.format(gs_ab.best_params_))\n",
    "\n",
    "#Highest accuracy - SVM with C = 1 and kernel = 'linear'\n",
    "\n",
    "#Most variance explained by using SVM without PCA  - 59% > 56%\n",
    "\n",
    "#Find classifier accuracy for SVM with best parameters\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#create SVM pipeline with best parameters\n",
    "pipe_svm_best = Pipeline([\n",
    "        ('clf', svm.SVC(C= 1, kernel = 'linear', random_state=123))])\n",
    "\n",
    "#Fit model to the dataaset\n",
    "pipe_svm_best.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "preds = pipe_svm_best.predict(X_test)\n",
    "\n",
    "\n",
    "#Best model - SVM with 'clf__C': 10, 'clf__gamma': 0.01, 'clf__kernel': 'rbf'\n",
    "\n",
    "print()\n",
    "\n",
    "#Test model accuracy\n",
    "print(\"Accuracy with best model: {}\".format(accuracy_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with best model: 0.9787510841283608\n"
     ]
    }
   ],
   "source": [
    "#Test model accuracy\n",
    "print(\"Accuracy with best model: {}\".format(accuracy_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is clear that, although the all-nba teamsa re not decided according to one specific\n",
    "#calculation of stats, the results of the honor selection for the same year\n",
    "#can very easily be predicted\n",
    "#based purely on the stats\n",
    "\n",
    "\n",
    "#Look at a more interesting question: including age as a factor for growth curve,\n",
    "#can an all-nba selection in the following year be predicted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt at more interesting approach - predicting all-nba from last year's stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-upload the original df in order to add the qualitative data back to the edited quant data\n",
    "\n",
    "df = pd.read_csv('nba_mod_4.csv')\n",
    "indeces_to_remove = list(df[(df['count'] > 1) & (df['Tm'] != 'TOT')].index)\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create copy of quant df\n",
    "df_2 = df_no_min_edited.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add qual data to quant data in df_2\n",
    "for col in ['Year', 'Player', 'concat', 'Pos', 'Age', 'Tm', 'MP']:\n",
    "    df_2[col] = df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#iterate throught the dataframe\n",
    "#find every entry with an honor\n",
    "#store the honor in the player's entry for the previous year by savin in 'new_honors'\n",
    "\n",
    "indices_to_change = []\n",
    "honors_to_change = []\n",
    "\n",
    "\n",
    "for i in range(len(df_2)):\n",
    "    if df_2.iloc[i]['Honors'] != 'No_Honors':\n",
    "        last_year = df_2.iloc[i]['Year'] - 1\n",
    "        name = df_2.iloc[i]['Player'] \n",
    "        honor = df_2.iloc[i]['Honors']\n",
    "       \n",
    "        for index in range(len(df_2)):\n",
    "            \n",
    "            \n",
    "            if (df_2.iloc[index]['Player'] == name) & (df_2.iloc[index]['Year'] == last_year):\n",
    "                indices_to_change.append(index)\n",
    "                honors_to_change.append(honor)\n",
    "                break\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column for the following year's honors with a default value of no honors\n",
    "\n",
    "new_honors = []\n",
    "for index in range(len(df_2)):\n",
    "    new_honors.append('No_Honors')\n",
    "\n",
    "for index in range(len(indices_to_change)):\n",
    "    new_honors[indices_to_change[index]] = honors_to_change[index]\n",
    "df_2.drop(['Honors'], axis = 1, inplace = True)\n",
    "df_2['Honors_Next_Year'] = new_honors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut out data from 2019 (don't know 2020 all nba teams) \n",
    "#and 2000 (don't have 1999 data to use for prediction)\n",
    "\n",
    "df_2 = df_2.iloc[662:11034]\n",
    "df_2.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate relevant features and target \n",
    "\n",
    "to_drop = []\n",
    "\n",
    "for col in df_2.columns:\n",
    "    if col not in ['MP','ORB', 'DRB', 'STL', 'BLK', 'TSP', 'a/t_ratio','Honors_Next_Year']:\n",
    "        to_drop.append(col)\n",
    "        \n",
    "\n",
    "df_3 = df_2.drop(to_drop,axis = 1)\n",
    "\n",
    "\n",
    "#Filter out players under 3000 minutes so that the ratio of selected players to non-selected\n",
    "#is more even -> should give better results, not just guesse of No_Honors\n",
    "df_3 = df_3[df_3['MP'] >= 3000]\n",
    "df_3 = df_3.drop(['MP'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up features and target\n",
    "features_3 = df_3.drop(['Honors_Next_Year'], axis = 1)\n",
    "target_3 = df_3['Honors_Next_Year']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features_3 = pd.DataFrame(scaler.fit_transform(features_3), columns = features_3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Develop model with machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine pipeline test accuracy: 0.8205128205128205\n",
      "Decision Tree pipeline test accuracy: 0.7692307692307693\n",
      "Random Forest pipeline test accuracy: 0.7948717948717948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Create train and test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features_3, target_3, test_size = .2, random_state = 123)\n",
    "\n",
    "#Conduct Simple Classifications\n",
    "\n",
    "\n",
    "#Create pipeline for SVM  model\n",
    "pipe_svm = Pipeline([('clf', svm.SVC(random_state=123))])\n",
    "\n",
    "#Create pipeline for Decision Tree model      \n",
    "pipe_tree = Pipeline([\n",
    "        ('clf', DecisionTreeClassifier(random_state=123))])\n",
    "\n",
    "#Create pipeline for Random Forest Model analysis\n",
    "pipe_rf = Pipeline([\n",
    "        ('clf', RandomForestClassifier(random_state=123))])\n",
    "\n",
    "#Loop through the pipelines to fit each pipeline to the dataset\n",
    "pipes = [pipe_svm, pipe_tree, pipe_rf]\n",
    "pipeline_names = ['Support Vector Machine','Decision Tree','Random Forest']\n",
    "for pipe in pipes:\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "# Compare model accuracies with default parameters\n",
    "for index, val in enumerate(pipes):\n",
    "    print('{} pipeline test accuracy: {}'.format(pipeline_names[index], val.score(X_test, y_test)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
      "[CV] clf__C=0.1, clf__kernel=linear ..................................\n",
      "[CV] ................... clf__C=0.1, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=0.1, clf__kernel=linear ..................................\n",
      "[CV] ................... clf__C=0.1, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=0.1, clf__kernel=linear ..................................\n",
      "[CV] ................... clf__C=0.1, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=1, clf__kernel=linear ....................................\n",
      "[CV] ..................... clf__C=1, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=1, clf__kernel=linear ....................................\n",
      "[CV] ..................... clf__C=1, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=1, clf__kernel=linear ....................................\n",
      "[CV] ..................... clf__C=1, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=10, clf__kernel=linear ...................................\n",
      "[CV] .................... clf__C=10, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=10, clf__kernel=linear ...................................\n",
      "[CV] .................... clf__C=10, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=10, clf__kernel=linear ...................................\n",
      "[CV] .................... clf__C=10, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=1, clf__gamma=0.001, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=1, clf__gamma=0.001, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=1, clf__gamma=0.001, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=1, clf__gamma=0.001, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=1, clf__gamma=0.001, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=1, clf__gamma=0.001, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=1, clf__gamma=0.01, clf__kernel=rbf ......................\n",
      "[CV] ....... clf__C=1, clf__gamma=0.01, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=1, clf__gamma=0.01, clf__kernel=rbf ......................\n",
      "[CV] ....... clf__C=1, clf__gamma=0.01, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=1, clf__gamma=0.01, clf__kernel=rbf ......................\n",
      "[CV] ....... clf__C=1, clf__gamma=0.01, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=10, clf__gamma=0.001, clf__kernel=rbf ....................\n",
      "[CV] ..... clf__C=10, clf__gamma=0.001, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=10, clf__gamma=0.001, clf__kernel=rbf ....................\n",
      "[CV] ..... clf__C=10, clf__gamma=0.001, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=10, clf__gamma=0.001, clf__kernel=rbf ....................\n",
      "[CV] ..... clf__C=10, clf__gamma=0.001, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=10, clf__gamma=0.01, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=10, clf__gamma=0.01, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=10, clf__gamma=0.01, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=10, clf__gamma=0.01, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=10, clf__gamma=0.01, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=10, clf__gamma=0.01, clf__kernel=rbf, total=   0.0s\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    0.1s finished\n",
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=30, total=   0.0s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=30, total=   0.0s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=30 ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 162 out of 162 | elapsed:   16.6s finished\n",
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=30, total=   0.0s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=50, total=   0.1s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=50, total=   0.1s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=50, total=   0.1s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=70, total=   0.1s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=70, total=   0.1s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=70, total=   0.1s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=30, total=   0.0s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=30, total=   0.0s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=30, total=   0.0s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=50, total=   0.1s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=50, total=   0.1s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=50, total=   0.1s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=70, total=   0.1s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=70, total=   0.1s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=70, total=   0.1s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=30, total=   0.0s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=30, total=   0.0s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=30, total=   0.0s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=50, total=   0.1s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=50, total=   0.1s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=50, total=   0.1s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=70, total=   0.1s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=70, total=   0.1s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=70, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    1.8s finished\n",
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('clf',\n",
       "                                        AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                                           base_estimator=None,\n",
       "                                                           learning_rate=1.0,\n",
       "                                                           n_estimators=50,\n",
       "                                                           random_state=123))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'clf__learning_rate': [1.0, 0.5, 0.1],\n",
       "                         'clf__n_estimators': [30, 50, 70]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid search to find best parameters\n",
    "\n",
    "\n",
    "#SVM\n",
    "\n",
    "\n",
    "#Create SVM pipeline\n",
    "pipe_svm = Pipeline([('clf', svm.SVC(random_state = 123))])\n",
    "\n",
    "# Set grid search parameters for SVM\n",
    "param_grid_svm = [\n",
    "  {'clf__C': [0.1, 1, 10]  , 'clf__kernel': ['linear']},\n",
    "  {'clf__C': [1, 10], 'clf__gamma': [0.001, 0.01], 'clf__kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# Construct grid search using the SVM pipeline and grid search parameters\n",
    "gs_svm = GridSearchCV(estimator=pipe_svm,\n",
    "            param_grid=param_grid_svm,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit SVM model using grid search\n",
    "gs_svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Random Forest\n",
    "\n",
    "#Create Random Forest pipeline\n",
    "pipe_rf = Pipeline([\n",
    "            ('clf', RandomForestClassifier(random_state = 123))])\n",
    "\n",
    "# Set grid search parameters for Random Forest\n",
    "param_grid_forest = [ \n",
    "  {'clf__n_estimators': [120],\n",
    "   'clf__criterion': ['entropy', 'gini'], \n",
    "   'clf__max_depth': [4, 5, 6],  \n",
    "   'clf__min_samples_leaf':[0.05 ,0.1, 0.2],  \n",
    "   'clf__min_samples_split':[0.05 ,0.1, 0.2]\n",
    "  }\n",
    "]\n",
    "\n",
    "# Construct grid search\n",
    "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "            param_grid=param_grid_forest,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit Random Forest model using grid search\n",
    "gs_rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Adaboost\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Construct Adaboost pipeline\n",
    "pipe_ab = Pipeline([\n",
    "            ('clf', AdaBoostClassifier(random_state = 123))])\n",
    "\n",
    "# Set grid search params for Adaboost\n",
    "adaboost_param_grid = {\n",
    "    'clf__n_estimators': [30, 50, 70],\n",
    "    'clf__learning_rate': [1.0, 0.5, 0.1]\n",
    "}\n",
    "\n",
    "# Construct grid search\n",
    "gs_ab = GridSearchCV(estimator=pipe_ab,\n",
    "            param_grid=adaboost_param_grid,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit Adaboost model using grid search\n",
    "gs_ab.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for SVM 0.7225806451612903\n",
      "Best params for SVM {'clf__C': 10, 'clf__kernel': 'linear'}\n",
      "\n",
      "Best accuracy for Random Forest 0.7032258064516129\n",
      "Best params for Random Forest {'clf__criterion': 'gini', 'clf__max_depth': 4, 'clf__min_samples_leaf': 0.1, 'clf__min_samples_split': 0.05, 'clf__n_estimators': 120}\n",
      "\n",
      "Best accuracy for Adaboost 0.6967741935483871\n",
      "Best params for Adaboost {'clf__learning_rate': 0.1, 'clf__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "#Print out the best accuracy scores and parameters for each model\n",
    "\n",
    "# Best accuracy SVM\n",
    "print('Best accuracy for SVM {}'.format(gs_svm.best_score_))\n",
    "# Best params SVM\n",
    "print('Best params for SVM {}'.format(gs_svm.best_params_))\n",
    "\n",
    "print()\n",
    "\n",
    "# Best accuracy Random Forest\n",
    "print('Best accuracy for Random Forest {}'.format(gs_rf.best_score_))\n",
    "# Best params Random Forest\n",
    "print('Best params for Random Forest {}'.format(gs_rf.best_params_))\n",
    "\n",
    "print()\n",
    "\n",
    "# Best accuracy Adaboost\n",
    "print('Best accuracy for Adaboost {}'.format(gs_ab.best_score_))\n",
    "# Best params Adaboost\n",
    "print('Best params for Adaboost {}'.format(gs_ab.best_params_))\n",
    "\n",
    "#Highest accuracy - SVM with C = 10, 'clf__gamma' = .01, and kernel = 'rbf'\n",
    "\n",
    "#Find classifier accuracy for SVM with best parameters\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#create SVM pipeline with best parameters\n",
    "pipe_svm_best = Pipeline([\n",
    "        ('clf', svm.SVC(C= 1, kernel = 'linear', random_state=123))])\n",
    "\n",
    "#Fit model to the dataaset\n",
    "pipe_svm_best.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "preds = pipe_svm_best.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "#Test model accuracy\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for better results with Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages for neural network model\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class labels:\n",
      "['First', 'No_Honors', 'Second', 'Third']\n",
      "\n",
      "\n",
      "New product labels:\n",
      "[3 3 1 0 1 1 1 1 1 0 1 3 1 1 0 1 1 2 0 0 1 0 1 1 1 1 1 1 1 2 3 1 1 1 1 0 1\n",
      " 3 1 2 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 2 1 1 1 1 1 0 1 1 1 0 1 0 1 1\n",
      " 1 2 1 1 0 1 1 3 1 1 2 1 1 1 1 0 1 1 1 1 1 3 1 1 2 3 3 0 1 1 1 1 0 1 1 2 1\n",
      " 2 1 1 1 3 1 1 1 1 1 1 1 1 1 3 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1\n",
      " 1 1 1 0 1 0 0 1 1 1 2 1 3 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 0 1 1 2 1 0 1 0 1\n",
      " 1 2 2 3 1 1 1 1 1]\n",
      "\n",
      "\n",
      "One hot labels; 7 binary columns, one for each of the categories.\n",
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n",
      "\n",
      "\n",
      "One hot labels shape:\n",
      "(194, 4)\n"
     ]
    }
   ],
   "source": [
    "#Change honors columns into a quantitative array\n",
    "\n",
    "product = df_3[\"Honors_Next_Year\"]\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(product)\n",
    "product_cat = le.transform(product)  \n",
    "product_onehot = to_categorical(product_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features_3, product_onehot, random_state = 123, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 6)\n",
      "(155, 4)\n",
      "(39, 6)\n",
      "(39, 4)\n"
     ]
    }
   ],
   "source": [
    "#CHeck shape to match input and output shapes of model to the arrays\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run ininital neural network model\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(25, activation = 'relu', input_shape = (6,)))\n",
    "model.add(layers.Dense(25, activation = 'relu'))\n",
    "model.add(layers.Dense(25, activation = 'relu'))\n",
    "model.add(layers.Dense(25, activation = 'relu'))\n",
    "model.add(layers.Dense(4, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = 'sgd', loss = 'mse', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 256, epochs = 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15736047702450906, 0.696774197009302]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check training results\n",
    "\n",
    "results_train = model.evaluate(X_train, y_train)\n",
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 114us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15355965953606826, 0.7948717964001191]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check testing results\n",
    "\n",
    "results_test = model.evaluate(X_test, y_test)\n",
    "results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graph loss function for training set\n",
    "\n",
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "\n",
    "loss_list = history_dict['loss']\n",
    "epochs = range(1,len(loss_list)+1)\n",
    "\n",
    "plt.plot(epochs, loss_list, label = 'Training Loss')\n",
    "\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graph accuracy function for training set\n",
    "\n",
    "accuracy_list = history_dict['acc']\n",
    "epochs = range(1,len(loss_list)+1)\n",
    "\n",
    "plt.plot(epochs, accuracy_list, label = 'Training Accuracy')\n",
    "\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy with test set increased with neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune neural network to see if results will improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 0.2552 - acc: 0.1806\n",
      "Epoch 2/120\n",
      "155/155 [==============================] - 0s 29us/step - loss: 0.2526 - acc: 0.1871\n",
      "Epoch 3/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.2501 - acc: 0.2194\n",
      "Epoch 4/120\n",
      "155/155 [==============================] - 0s 21us/step - loss: 0.2476 - acc: 0.2258\n",
      "Epoch 5/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.2453 - acc: 0.2516\n",
      "Epoch 6/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.2429 - acc: 0.2710\n",
      "Epoch 7/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.2406 - acc: 0.2903\n",
      "Epoch 8/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.2384 - acc: 0.3290\n",
      "Epoch 9/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.2363 - acc: 0.3677\n",
      "Epoch 10/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.2341 - acc: 0.3871\n",
      "Epoch 11/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.2320 - acc: 0.4000\n",
      "Epoch 12/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.2300 - acc: 0.4065\n",
      "Epoch 13/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.2280 - acc: 0.4258\n",
      "Epoch 14/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.2261 - acc: 0.4516\n",
      "Epoch 15/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.2242 - acc: 0.4581\n",
      "Epoch 16/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.2223 - acc: 0.4710\n",
      "Epoch 17/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.2205 - acc: 0.4968\n",
      "Epoch 18/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.2187 - acc: 0.4968\n",
      "Epoch 19/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.2170 - acc: 0.5032\n",
      "Epoch 20/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.2153 - acc: 0.5161\n",
      "Epoch 21/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.2136 - acc: 0.5419\n",
      "Epoch 22/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.2119 - acc: 0.5419\n",
      "Epoch 23/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.2103 - acc: 0.5484\n",
      "Epoch 24/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.2087 - acc: 0.5548\n",
      "Epoch 25/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.2072 - acc: 0.5677\n",
      "Epoch 26/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.2057 - acc: 0.5806\n",
      "Epoch 27/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.2041 - acc: 0.5742\n",
      "Epoch 28/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.2027 - acc: 0.5871\n",
      "Epoch 29/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.2012 - acc: 0.5935\n",
      "Epoch 30/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.1998 - acc: 0.6000\n",
      "Epoch 31/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.1984 - acc: 0.6129\n",
      "Epoch 32/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1971 - acc: 0.6194\n",
      "Epoch 33/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1958 - acc: 0.6323\n",
      "Epoch 34/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1944 - acc: 0.6323\n",
      "Epoch 35/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.1931 - acc: 0.6323\n",
      "Epoch 36/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.1919 - acc: 0.6387\n",
      "Epoch 37/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.1906 - acc: 0.6387\n",
      "Epoch 38/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.1894 - acc: 0.6516\n",
      "Epoch 39/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.1882 - acc: 0.6516\n",
      "Epoch 40/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.1870 - acc: 0.6516\n",
      "Epoch 41/120\n",
      "155/155 [==============================] - 0s 21us/step - loss: 0.1859 - acc: 0.6581\n",
      "Epoch 42/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1847 - acc: 0.6645\n",
      "Epoch 43/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.1836 - acc: 0.6710\n",
      "Epoch 44/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1825 - acc: 0.6774\n",
      "Epoch 45/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1814 - acc: 0.6774\n",
      "Epoch 46/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1803 - acc: 0.6774\n",
      "Epoch 47/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1793 - acc: 0.6774\n",
      "Epoch 48/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1783 - acc: 0.6774\n",
      "Epoch 49/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.1773 - acc: 0.6774\n",
      "Epoch 50/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1763 - acc: 0.6774\n",
      "Epoch 51/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1753 - acc: 0.6774\n",
      "Epoch 52/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1743 - acc: 0.6774\n",
      "Epoch 53/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1734 - acc: 0.6774\n",
      "Epoch 54/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1724 - acc: 0.6774\n",
      "Epoch 55/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 0.1715 - acc: 0.6774\n",
      "Epoch 56/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.1706 - acc: 0.6774\n",
      "Epoch 57/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.1698 - acc: 0.6774\n",
      "Epoch 58/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.1689 - acc: 0.6710\n",
      "Epoch 59/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1680 - acc: 0.6710\n",
      "Epoch 60/120\n",
      "155/155 [==============================] - 0s 293us/step - loss: 0.1672 - acc: 0.6710\n",
      "Epoch 61/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.1664 - acc: 0.6710\n",
      "Epoch 62/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1656 - acc: 0.6774\n",
      "Epoch 63/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.1648 - acc: 0.6774\n",
      "Epoch 64/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.1640 - acc: 0.6774\n",
      "Epoch 65/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.1632 - acc: 0.6774\n",
      "Epoch 66/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1625 - acc: 0.6774\n",
      "Epoch 67/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1618 - acc: 0.6774\n",
      "Epoch 68/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.1610 - acc: 0.6903\n",
      "Epoch 69/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 0.1603 - acc: 0.6903\n",
      "Epoch 70/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.1596 - acc: 0.6903\n",
      "Epoch 71/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.1589 - acc: 0.6903\n",
      "Epoch 72/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1582 - acc: 0.6903\n",
      "Epoch 73/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.1575 - acc: 0.6903\n",
      "Epoch 74/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.1569 - acc: 0.6903\n",
      "Epoch 75/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1562 - acc: 0.6903\n",
      "Epoch 76/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1556 - acc: 0.6968\n",
      "Epoch 77/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1549 - acc: 0.6968\n",
      "Epoch 78/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.1543 - acc: 0.6968\n",
      "Epoch 79/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1537 - acc: 0.6968\n",
      "Epoch 80/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1531 - acc: 0.6968\n",
      "Epoch 81/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.1525 - acc: 0.6968\n",
      "Epoch 82/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 0.1519 - acc: 0.6903\n",
      "Epoch 83/120\n",
      "155/155 [==============================] - 0s 31us/step - loss: 0.1514 - acc: 0.6903\n",
      "Epoch 84/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.1508 - acc: 0.6903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1503 - acc: 0.6903\n",
      "Epoch 86/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1497 - acc: 0.6903\n",
      "Epoch 87/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.1492 - acc: 0.6903\n",
      "Epoch 88/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.1486 - acc: 0.6903\n",
      "Epoch 89/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.1481 - acc: 0.6903\n",
      "Epoch 90/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1476 - acc: 0.6903\n",
      "Epoch 91/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1471 - acc: 0.6903\n",
      "Epoch 92/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1466 - acc: 0.6903\n",
      "Epoch 93/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1462 - acc: 0.6903\n",
      "Epoch 94/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1457 - acc: 0.6903\n",
      "Epoch 95/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1452 - acc: 0.6903\n",
      "Epoch 96/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1448 - acc: 0.6903\n",
      "Epoch 97/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1443 - acc: 0.6903\n",
      "Epoch 98/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1439 - acc: 0.6903\n",
      "Epoch 99/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1434 - acc: 0.6903\n",
      "Epoch 100/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.1430 - acc: 0.6903\n",
      "Epoch 101/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1426 - acc: 0.6903\n",
      "Epoch 102/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.1422 - acc: 0.6903\n",
      "Epoch 103/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.1418 - acc: 0.6903\n",
      "Epoch 104/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.1414 - acc: 0.6903\n",
      "Epoch 105/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.1410 - acc: 0.6903\n",
      "Epoch 106/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.1406 - acc: 0.6968\n",
      "Epoch 107/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.1402 - acc: 0.6968\n",
      "Epoch 108/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.1398 - acc: 0.6968\n",
      "Epoch 109/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.1395 - acc: 0.6968\n",
      "Epoch 110/120\n",
      "155/155 [==============================] - 0s 31us/step - loss: 0.1391 - acc: 0.6968\n",
      "Epoch 111/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.1387 - acc: 0.6968\n",
      "Epoch 112/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.1384 - acc: 0.6968\n",
      "Epoch 113/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.1380 - acc: 0.6968\n",
      "Epoch 114/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 0.1377 - acc: 0.6968\n",
      "Epoch 115/120\n",
      "155/155 [==============================] - 0s 34us/step - loss: 0.1374 - acc: 0.6968\n",
      "Epoch 116/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.1370 - acc: 0.6968\n",
      "Epoch 117/120\n",
      "155/155 [==============================] - 0s 29us/step - loss: 0.1367 - acc: 0.6968\n",
      "Epoch 118/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.1364 - acc: 0.7032\n",
      "Epoch 119/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.1361 - acc: 0.7032\n",
      "Epoch 120/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.1358 - acc: 0.7032\n",
      "155/155 [==============================] - 0s 2ms/step\n",
      "[0.13546743133375722, 0.7032258099125278]\n",
      "39/39 [==============================] - 0s 99us/step\n",
      "[0.11527430227933785, 0.7948717964001191]\n"
     ]
    }
   ],
   "source": [
    "#linear in last layer\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(25, activation = 'relu', input_shape = (6,)))\n",
    "model.add(layers.Dense(25, activation = 'relu'))\n",
    "model.add(layers.Dense(25, activation = 'relu'))\n",
    "model.add(layers.Dense(25, activation = 'relu'))\n",
    "model.add(layers.Dense(4, activation = 'linear'))\n",
    "\n",
    "model.compile(optimizer = 'sgd', loss = 'mse', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 256, epochs = 120)\n",
    "\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "results_train = model.evaluate(X_train, y_train)\n",
    "print(results_train)\n",
    "\n",
    "results_test = model.evaluate(X_test, y_test)\n",
    "print(results_test)\n",
    "\n",
    "#improvements in both training and test sets\n",
    "#keep linear in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "155/155 [==============================] - 1s 8ms/step - loss: 1.8870 - acc: 0.4774\n",
      "Epoch 2/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.8837 - acc: 0.5484\n",
      "Epoch 3/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 1.8804 - acc: 0.6000\n",
      "Epoch 4/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.8772 - acc: 0.6452\n",
      "Epoch 5/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 1.8740 - acc: 0.6710\n",
      "Epoch 6/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.8709 - acc: 0.6774\n",
      "Epoch 7/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 1.8678 - acc: 0.6839\n",
      "Epoch 8/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.8648 - acc: 0.6903\n",
      "Epoch 9/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 1.8619 - acc: 0.6903\n",
      "Epoch 10/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.8590 - acc: 0.6903\n",
      "Epoch 11/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 1.8561 - acc: 0.6903\n",
      "Epoch 12/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.8533 - acc: 0.6968\n",
      "Epoch 13/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.8505 - acc: 0.6968\n",
      "Epoch 14/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 1.8477 - acc: 0.6968\n",
      "Epoch 15/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 1.8450 - acc: 0.6968\n",
      "Epoch 16/120\n",
      "155/155 [==============================] - 0s 29us/step - loss: 1.8424 - acc: 0.6968\n",
      "Epoch 17/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 1.8398 - acc: 0.6968\n",
      "Epoch 18/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.8372 - acc: 0.6968\n",
      "Epoch 19/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 1.8347 - acc: 0.6968\n",
      "Epoch 20/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.8323 - acc: 0.6968\n",
      "Epoch 21/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 1.8298 - acc: 0.6968\n",
      "Epoch 22/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 1.8275 - acc: 0.6968\n",
      "Epoch 23/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 1.8251 - acc: 0.6968\n",
      "Epoch 24/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.8228 - acc: 0.6968\n",
      "Epoch 25/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.8206 - acc: 0.6968\n",
      "Epoch 26/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.8183 - acc: 0.6968\n",
      "Epoch 27/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.8161 - acc: 0.6968\n",
      "Epoch 28/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.8140 - acc: 0.6968\n",
      "Epoch 29/120\n",
      "155/155 [==============================] - 0s 30us/step - loss: 1.8119 - acc: 0.6968\n",
      "Epoch 30/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 1.8098 - acc: 0.6968\n",
      "Epoch 31/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.8077 - acc: 0.6968\n",
      "Epoch 32/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.8057 - acc: 0.6968\n",
      "Epoch 33/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.8037 - acc: 0.6968\n",
      "Epoch 34/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 1.8017 - acc: 0.6968\n",
      "Epoch 35/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 1.7998 - acc: 0.6968\n",
      "Epoch 36/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.7979 - acc: 0.6968\n",
      "Epoch 37/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 1.7960 - acc: 0.6968\n",
      "Epoch 38/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 1.7942 - acc: 0.6968\n",
      "Epoch 39/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 1.7924 - acc: 0.6968\n",
      "Epoch 40/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.7906 - acc: 0.6968\n",
      "Epoch 41/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.7889 - acc: 0.6968\n",
      "Epoch 42/120\n",
      "155/155 [==============================] - 0s 30us/step - loss: 1.7872 - acc: 0.6968\n",
      "Epoch 43/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 1.7855 - acc: 0.6968\n",
      "Epoch 44/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 1.7839 - acc: 0.6968\n",
      "Epoch 45/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.7823 - acc: 0.6968\n",
      "Epoch 46/120\n",
      "155/155 [==============================] - 0s 299us/step - loss: 1.7807 - acc: 0.6968\n",
      "Epoch 47/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.7791 - acc: 0.6968\n",
      "Epoch 48/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.7776 - acc: 0.6968\n",
      "Epoch 49/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 1.7761 - acc: 0.6968\n",
      "Epoch 50/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 1.7746 - acc: 0.6968\n",
      "Epoch 51/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 1.7731 - acc: 0.6968\n",
      "Epoch 52/120\n",
      "155/155 [==============================] - 0s 33us/step - loss: 1.7717 - acc: 0.6968\n",
      "Epoch 53/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.7703 - acc: 0.6968\n",
      "Epoch 54/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 1.7689 - acc: 0.6968\n",
      "Epoch 55/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 1.7675 - acc: 0.6968\n",
      "Epoch 56/120\n",
      "155/155 [==============================] - 0s 32us/step - loss: 1.7662 - acc: 0.6968\n",
      "Epoch 57/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 1.7648 - acc: 0.6968\n",
      "Epoch 58/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.7635 - acc: 0.6968\n",
      "Epoch 59/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.7623 - acc: 0.6968\n",
      "Epoch 60/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 1.7610 - acc: 0.6968\n",
      "Epoch 61/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 1.7598 - acc: 0.6968\n",
      "Epoch 62/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.7585 - acc: 0.6968\n",
      "Epoch 63/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.7573 - acc: 0.6968\n",
      "Epoch 64/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.7562 - acc: 0.6968\n",
      "Epoch 65/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 1.7550 - acc: 0.6968\n",
      "Epoch 66/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 1.7538 - acc: 0.6968\n",
      "Epoch 67/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.7527 - acc: 0.6968\n",
      "Epoch 68/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 1.7516 - acc: 0.6968\n",
      "Epoch 69/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.7505 - acc: 0.6968\n",
      "Epoch 70/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.7494 - acc: 0.6968\n",
      "Epoch 71/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 1.7483 - acc: 0.6968\n",
      "Epoch 72/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.7473 - acc: 0.6968\n",
      "Epoch 73/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 1.7462 - acc: 0.6968\n",
      "Epoch 74/120\n",
      "155/155 [==============================] - 0s 30us/step - loss: 1.7452 - acc: 0.6968\n",
      "Epoch 75/120\n",
      "155/155 [==============================] - 0s 29us/step - loss: 1.7442 - acc: 0.6968\n",
      "Epoch 76/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 1.7432 - acc: 0.6968\n",
      "Epoch 77/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.7422 - acc: 0.6968\n",
      "Epoch 78/120\n",
      "155/155 [==============================] - 0s 31us/step - loss: 1.7412 - acc: 0.6968\n",
      "Epoch 79/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.7402 - acc: 0.6968\n",
      "Epoch 80/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 1.7393 - acc: 0.6968\n",
      "Epoch 81/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.7383 - acc: 0.6968\n",
      "Epoch 82/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 1.7374 - acc: 0.6968\n",
      "Epoch 83/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 1.7365 - acc: 0.6968\n",
      "Epoch 84/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.7356 - acc: 0.6968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.7347 - acc: 0.6968\n",
      "Epoch 86/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 1.7338 - acc: 0.6968\n",
      "Epoch 87/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 1.7329 - acc: 0.6968\n",
      "Epoch 88/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 1.7320 - acc: 0.6968\n",
      "Epoch 89/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 1.7311 - acc: 0.6968\n",
      "Epoch 90/120\n",
      "155/155 [==============================] - 0s 31us/step - loss: 1.7303 - acc: 0.6968\n",
      "Epoch 91/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 1.7294 - acc: 0.6968\n",
      "Epoch 92/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.7286 - acc: 0.6968\n",
      "Epoch 93/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 1.7277 - acc: 0.6968\n",
      "Epoch 94/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.7269 - acc: 0.6968\n",
      "Epoch 95/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 1.7261 - acc: 0.6968\n",
      "Epoch 96/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 1.7253 - acc: 0.6968\n",
      "Epoch 97/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.7245 - acc: 0.6968\n",
      "Epoch 98/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.7237 - acc: 0.6968\n",
      "Epoch 99/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.7229 - acc: 0.6968\n",
      "Epoch 100/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 1.7222 - acc: 0.6968\n",
      "Epoch 101/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 1.7214 - acc: 0.6968\n",
      "Epoch 102/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 1.7206 - acc: 0.6968\n",
      "Epoch 103/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 1.7199 - acc: 0.6968\n",
      "Epoch 104/120\n",
      "155/155 [==============================] - 0s 29us/step - loss: 1.7191 - acc: 0.6968\n",
      "Epoch 105/120\n",
      "155/155 [==============================] - 0s 32us/step - loss: 1.7184 - acc: 0.6968\n",
      "Epoch 106/120\n",
      "155/155 [==============================] - 0s 30us/step - loss: 1.7176 - acc: 0.6968\n",
      "Epoch 107/120\n",
      "155/155 [==============================] - 0s 31us/step - loss: 1.7169 - acc: 0.6968\n",
      "Epoch 108/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 1.7162 - acc: 0.6968\n",
      "Epoch 109/120\n",
      "155/155 [==============================] - 0s 37us/step - loss: 1.7155 - acc: 0.6968\n",
      "Epoch 110/120\n",
      "155/155 [==============================] - 0s 29us/step - loss: 1.7148 - acc: 0.6968\n",
      "Epoch 111/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 1.7141 - acc: 0.6968\n",
      "Epoch 112/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 1.7134 - acc: 0.6968\n",
      "Epoch 113/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.7127 - acc: 0.6968\n",
      "Epoch 114/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 1.7120 - acc: 0.6968\n",
      "Epoch 115/120\n",
      "155/155 [==============================] - 0s 32us/step - loss: 1.7113 - acc: 0.6968\n",
      "Epoch 116/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 1.7106 - acc: 0.6968\n",
      "Epoch 117/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 1.7099 - acc: 0.6968\n",
      "Epoch 118/120\n",
      "155/155 [==============================] - 0s 34us/step - loss: 1.7093 - acc: 0.6968\n",
      "Epoch 119/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 1.7086 - acc: 0.6968\n",
      "Epoch 120/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 1.7079 - acc: 0.6968\n",
      "155/155 [==============================] - 0s 2ms/step\n",
      "[1.7072857364531486, 0.696774197009302]\n",
      "39/39 [==============================] - 0s 72us/step\n",
      "[1.6899871979004297, 0.7948717964001191]\n"
     ]
    }
   ],
   "source": [
    "#l1 regularization\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(25, activation = 'relu', kernel_initializer='normal',input_shape = (6,)))\n",
    "model.add(layers.Dense(25, kernel_regularizer= regularizers.l1(0.005),activation = 'relu'))\n",
    "model.add(layers.Dense(25, kernel_regularizer= regularizers.l1(0.005),activation = 'relu'))\n",
    "model.add(layers.Dense(25, kernel_regularizer= regularizers.l1(0.005),activation = 'relu'))\n",
    "model.add(layers.Dense(4, activation = 'linear'))\n",
    "\n",
    "model.compile(optimizer = 'sgd', loss = 'mse', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 256, epochs = 120)\n",
    "\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "results_train = model.evaluate(X_train, y_train)\n",
    "print(results_train)\n",
    "\n",
    "results_test = model.evaluate(X_test, y_test)\n",
    "print(results_test)\n",
    "\n",
    "#slightly worse in training accuracy, same in testing accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "155/155 [==============================] - 1s 9ms/step - loss: 0.6163 - acc: 0.6129\n",
      "Epoch 2/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.6138 - acc: 0.6258\n",
      "Epoch 3/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 0.6113 - acc: 0.6387\n",
      "Epoch 4/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.6089 - acc: 0.6516\n",
      "Epoch 5/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.6066 - acc: 0.6645\n",
      "Epoch 6/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.6043 - acc: 0.6839\n",
      "Epoch 7/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.6020 - acc: 0.6903\n",
      "Epoch 8/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5998 - acc: 0.6903\n",
      "Epoch 9/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5977 - acc: 0.6903\n",
      "Epoch 10/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5956 - acc: 0.6903\n",
      "Epoch 11/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5935 - acc: 0.6968\n",
      "Epoch 12/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5914 - acc: 0.6968\n",
      "Epoch 13/120\n",
      "155/155 [==============================] - 0s 22us/step - loss: 0.5894 - acc: 0.6968\n",
      "Epoch 14/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5875 - acc: 0.6968\n",
      "Epoch 15/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.5855 - acc: 0.6968\n",
      "Epoch 16/120\n",
      "155/155 [==============================] - 0s 29us/step - loss: 0.5836 - acc: 0.6968\n",
      "Epoch 17/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.5817 - acc: 0.6968\n",
      "Epoch 18/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.5799 - acc: 0.6968\n",
      "Epoch 19/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5781 - acc: 0.6968\n",
      "Epoch 20/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.5763 - acc: 0.6968\n",
      "Epoch 21/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.5746 - acc: 0.6968\n",
      "Epoch 22/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5729 - acc: 0.6968\n",
      "Epoch 23/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5712 - acc: 0.6968\n",
      "Epoch 24/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5695 - acc: 0.6968\n",
      "Epoch 25/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5679 - acc: 0.6968\n",
      "Epoch 26/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5663 - acc: 0.6968\n",
      "Epoch 27/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.5647 - acc: 0.6968\n",
      "Epoch 28/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.5631 - acc: 0.6968\n",
      "Epoch 29/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5616 - acc: 0.6968\n",
      "Epoch 30/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5600 - acc: 0.6968\n",
      "Epoch 31/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5585 - acc: 0.6968\n",
      "Epoch 32/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.5570 - acc: 0.6968\n",
      "Epoch 33/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.5556 - acc: 0.6968\n",
      "Epoch 34/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.5541 - acc: 0.6968\n",
      "Epoch 35/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.5527 - acc: 0.6968\n",
      "Epoch 36/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5513 - acc: 0.6968\n",
      "Epoch 37/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5500 - acc: 0.6968\n",
      "Epoch 38/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5486 - acc: 0.6968\n",
      "Epoch 39/120\n",
      "155/155 [==============================] - 0s 31us/step - loss: 0.5473 - acc: 0.6968\n",
      "Epoch 40/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5460 - acc: 0.6968\n",
      "Epoch 41/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.5447 - acc: 0.6968\n",
      "Epoch 42/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.5435 - acc: 0.6968\n",
      "Epoch 43/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5423 - acc: 0.6968\n",
      "Epoch 44/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5411 - acc: 0.6968\n",
      "Epoch 45/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5399 - acc: 0.6968\n",
      "Epoch 46/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5387 - acc: 0.6968\n",
      "Epoch 47/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5376 - acc: 0.6968\n",
      "Epoch 48/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5364 - acc: 0.6968\n",
      "Epoch 49/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.5353 - acc: 0.6968\n",
      "Epoch 50/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 0.5342 - acc: 0.6968\n",
      "Epoch 51/120\n",
      "155/155 [==============================] - 0s 29us/step - loss: 0.5331 - acc: 0.6968\n",
      "Epoch 52/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.5321 - acc: 0.6968\n",
      "Epoch 53/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5310 - acc: 0.6968\n",
      "Epoch 54/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5300 - acc: 0.6968\n",
      "Epoch 55/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.5290 - acc: 0.6968\n",
      "Epoch 56/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.5280 - acc: 0.6968\n",
      "Epoch 57/120\n",
      "155/155 [==============================] - 0s 29us/step - loss: 0.5271 - acc: 0.6968\n",
      "Epoch 58/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5261 - acc: 0.6968\n",
      "Epoch 59/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5252 - acc: 0.6968\n",
      "Epoch 60/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5243 - acc: 0.6968\n",
      "Epoch 61/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.5234 - acc: 0.6968\n",
      "Epoch 62/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5225 - acc: 0.6968\n",
      "Epoch 63/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.5216 - acc: 0.6968\n",
      "Epoch 64/120\n",
      "155/155 [==============================] - 0s 290us/step - loss: 0.5208 - acc: 0.6968\n",
      "Epoch 65/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 0.5199 - acc: 0.6968\n",
      "Epoch 66/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.5191 - acc: 0.6968\n",
      "Epoch 67/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.5183 - acc: 0.6968\n",
      "Epoch 68/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5174 - acc: 0.6968\n",
      "Epoch 69/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 0.5167 - acc: 0.6968\n",
      "Epoch 70/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.5159 - acc: 0.6968\n",
      "Epoch 71/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.5151 - acc: 0.6968\n",
      "Epoch 72/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5144 - acc: 0.6968\n",
      "Epoch 73/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5136 - acc: 0.6968\n",
      "Epoch 74/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5129 - acc: 0.6968\n",
      "Epoch 75/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5122 - acc: 0.6968\n",
      "Epoch 76/120\n",
      "155/155 [==============================] - 0s 30us/step - loss: 0.5114 - acc: 0.6968\n",
      "Epoch 77/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 0.5107 - acc: 0.6968\n",
      "Epoch 78/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5101 - acc: 0.6968\n",
      "Epoch 79/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5094 - acc: 0.6968\n",
      "Epoch 80/120\n",
      "155/155 [==============================] - 0s 31us/step - loss: 0.5087 - acc: 0.6968\n",
      "Epoch 81/120\n",
      "155/155 [==============================] - 0s 29us/step - loss: 0.5080 - acc: 0.6968\n",
      "Epoch 82/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 0.5074 - acc: 0.6968\n",
      "Epoch 83/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5068 - acc: 0.6968\n",
      "Epoch 84/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5061 - acc: 0.6968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5055 - acc: 0.6968\n",
      "Epoch 86/120\n",
      "155/155 [==============================] - 0s 29us/step - loss: 0.5049 - acc: 0.6968\n",
      "Epoch 87/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5043 - acc: 0.6968\n",
      "Epoch 88/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5037 - acc: 0.6968\n",
      "Epoch 89/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5031 - acc: 0.6968\n",
      "Epoch 90/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5025 - acc: 0.6968\n",
      "Epoch 91/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.5020 - acc: 0.6968\n",
      "Epoch 92/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5014 - acc: 0.6968\n",
      "Epoch 93/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.5009 - acc: 0.6968\n",
      "Epoch 94/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.5003 - acc: 0.6968\n",
      "Epoch 95/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.4998 - acc: 0.6968\n",
      "Epoch 96/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 0.4993 - acc: 0.6968\n",
      "Epoch 97/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 0.4987 - acc: 0.6968\n",
      "Epoch 98/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.4982 - acc: 0.6968\n",
      "Epoch 99/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.4977 - acc: 0.6968\n",
      "Epoch 100/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.4972 - acc: 0.6968\n",
      "Epoch 101/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.4967 - acc: 0.6968\n",
      "Epoch 102/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.4963 - acc: 0.6968\n",
      "Epoch 103/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.4958 - acc: 0.6968\n",
      "Epoch 104/120\n",
      "155/155 [==============================] - 0s 31us/step - loss: 0.4953 - acc: 0.6968\n",
      "Epoch 105/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.4948 - acc: 0.6968\n",
      "Epoch 106/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.4944 - acc: 0.6968\n",
      "Epoch 107/120\n",
      "155/155 [==============================] - 0s 31us/step - loss: 0.4939 - acc: 0.6968\n",
      "Epoch 108/120\n",
      "155/155 [==============================] - 0s 28us/step - loss: 0.4935 - acc: 0.6968\n",
      "Epoch 109/120\n",
      "155/155 [==============================] - 0s 32us/step - loss: 0.4931 - acc: 0.6968\n",
      "Epoch 110/120\n",
      "155/155 [==============================] - 0s 29us/step - loss: 0.4926 - acc: 0.6968\n",
      "Epoch 111/120\n",
      "155/155 [==============================] - 0s 25us/step - loss: 0.4922 - acc: 0.6968\n",
      "Epoch 112/120\n",
      "155/155 [==============================] - 0s 29us/step - loss: 0.4918 - acc: 0.6968\n",
      "Epoch 113/120\n",
      "155/155 [==============================] - 0s 30us/step - loss: 0.4914 - acc: 0.6968\n",
      "Epoch 114/120\n",
      "155/155 [==============================] - 0s 24us/step - loss: 0.4910 - acc: 0.6968\n",
      "Epoch 115/120\n",
      "155/155 [==============================] - 0s 23us/step - loss: 0.4906 - acc: 0.6968\n",
      "Epoch 116/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.4902 - acc: 0.6968\n",
      "Epoch 117/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.4898 - acc: 0.6968\n",
      "Epoch 118/120\n",
      "155/155 [==============================] - 0s 27us/step - loss: 0.4894 - acc: 0.6968\n",
      "Epoch 119/120\n",
      "155/155 [==============================] - 0s 29us/step - loss: 0.4890 - acc: 0.6968\n",
      "Epoch 120/120\n",
      "155/155 [==============================] - 0s 26us/step - loss: 0.4886 - acc: 0.6968\n",
      "155/155 [==============================] - 0s 3ms/step\n",
      "[0.48822962737852527, 0.696774197009302]\n",
      "39/39 [==============================] - 0s 85us/step\n",
      "[0.4676641088265639, 0.7948717964001191]\n"
     ]
    }
   ],
   "source": [
    "#l2 regularization\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(25, activation = 'relu', kernel_initializer='normal',input_shape = (6,)))\n",
    "model.add(layers.Dense(25, kernel_regularizer= regularizers.l2(0.005),activation = 'relu'))\n",
    "model.add(layers.Dense(25, kernel_regularizer= regularizers.l2(0.005),activation = 'relu'))\n",
    "model.add(layers.Dense(25, kernel_regularizer= regularizers.l2(0.005),activation = 'relu'))\n",
    "model.add(layers.Dense(4, activation = 'linear'))\n",
    "\n",
    "model.compile(optimizer = 'sgd', loss = 'mse', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 256, epochs = 120)\n",
    "\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "results_train = model.evaluate(X_train, y_train)\n",
    "print(results_train)\n",
    "\n",
    "results_test = model.evaluate(X_test, y_test)\n",
    "print(results_test)\n",
    "\n",
    "#slightly worse in training accuracy, same in testing accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "155/155 [==============================] - 2s 13ms/step - loss: 0.4163 - acc: 0.2452\n",
      "Epoch 2/200\n",
      "155/155 [==============================] - 0s 207us/step - loss: 0.4133 - acc: 0.4581\n",
      "Epoch 3/200\n",
      "155/155 [==============================] - 0s 203us/step - loss: 0.4082 - acc: 0.5548\n",
      "Epoch 4/200\n",
      "155/155 [==============================] - 0s 181us/step - loss: 0.4027 - acc: 0.6258\n",
      "Epoch 5/200\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.3984 - acc: 0.6839\n",
      "Epoch 6/200\n",
      "155/155 [==============================] - 0s 217us/step - loss: 0.3952 - acc: 0.6774\n",
      "Epoch 7/200\n",
      "155/155 [==============================] - 0s 185us/step - loss: 0.3902 - acc: 0.6839\n",
      "Epoch 8/200\n",
      "155/155 [==============================] - 0s 193us/step - loss: 0.3864 - acc: 0.6839\n",
      "Epoch 9/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.3820 - acc: 0.6968\n",
      "Epoch 10/200\n",
      "155/155 [==============================] - 0s 179us/step - loss: 0.3790 - acc: 0.6903\n",
      "Epoch 11/200\n",
      "155/155 [==============================] - 0s 436us/step - loss: 0.3754 - acc: 0.6968\n",
      "Epoch 12/200\n",
      "155/155 [==============================] - 0s 184us/step - loss: 0.3714 - acc: 0.6968\n",
      "Epoch 13/200\n",
      "155/155 [==============================] - 0s 186us/step - loss: 0.3676 - acc: 0.6968\n",
      "Epoch 14/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.3641 - acc: 0.6968\n",
      "Epoch 15/200\n",
      "155/155 [==============================] - 0s 168us/step - loss: 0.3617 - acc: 0.6968\n",
      "Epoch 16/200\n",
      "155/155 [==============================] - 0s 171us/step - loss: 0.3588 - acc: 0.6968\n",
      "Epoch 17/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.3564 - acc: 0.6968\n",
      "Epoch 18/200\n",
      "155/155 [==============================] - 0s 166us/step - loss: 0.3531 - acc: 0.6968\n",
      "Epoch 19/200\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.3491 - acc: 0.6968\n",
      "Epoch 20/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.3476 - acc: 0.6968\n",
      "Epoch 21/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.3454 - acc: 0.6968\n",
      "Epoch 22/200\n",
      "155/155 [==============================] - 0s 169us/step - loss: 0.3421 - acc: 0.6968\n",
      "Epoch 23/200\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.3395 - acc: 0.6968\n",
      "Epoch 24/200\n",
      "155/155 [==============================] - 0s 172us/step - loss: 0.3382 - acc: 0.6968\n",
      "Epoch 25/200\n",
      "155/155 [==============================] - 0s 167us/step - loss: 0.3345 - acc: 0.6968\n",
      "Epoch 26/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.3335 - acc: 0.6968\n",
      "Epoch 27/200\n",
      "155/155 [==============================] - 0s 409us/step - loss: 0.3313 - acc: 0.6968\n",
      "Epoch 28/200\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.3291 - acc: 0.6968\n",
      "Epoch 29/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.3273 - acc: 0.6968\n",
      "Epoch 30/200\n",
      "155/155 [==============================] - 0s 167us/step - loss: 0.3254 - acc: 0.6968\n",
      "Epoch 31/200\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.3232 - acc: 0.6968\n",
      "Epoch 32/200\n",
      "155/155 [==============================] - 0s 168us/step - loss: 0.3223 - acc: 0.6968\n",
      "Epoch 33/200\n",
      "155/155 [==============================] - 0s 173us/step - loss: 0.3204 - acc: 0.6968\n",
      "Epoch 34/200\n",
      "155/155 [==============================] - 0s 170us/step - loss: 0.3187 - acc: 0.6968\n",
      "Epoch 35/200\n",
      "155/155 [==============================] - 0s 173us/step - loss: 0.3168 - acc: 0.6968\n",
      "Epoch 36/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.3146 - acc: 0.6968\n",
      "Epoch 37/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.3140 - acc: 0.6968\n",
      "Epoch 38/200\n",
      "155/155 [==============================] - 0s 172us/step - loss: 0.3133 - acc: 0.6968\n",
      "Epoch 39/200\n",
      "155/155 [==============================] - 0s 171us/step - loss: 0.3122 - acc: 0.6968\n",
      "Epoch 40/200\n",
      "155/155 [==============================] - 0s 169us/step - loss: 0.3111 - acc: 0.6968\n",
      "Epoch 41/200\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.3092 - acc: 0.6968\n",
      "Epoch 42/200\n",
      "155/155 [==============================] - 0s 443us/step - loss: 0.3070 - acc: 0.6968\n",
      "Epoch 43/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.3071 - acc: 0.6968\n",
      "Epoch 44/200\n",
      "155/155 [==============================] - 0s 168us/step - loss: 0.3064 - acc: 0.6968\n",
      "Epoch 45/200\n",
      "155/155 [==============================] - 0s 173us/step - loss: 0.3045 - acc: 0.6968\n",
      "Epoch 46/200\n",
      "155/155 [==============================] - 0s 173us/step - loss: 0.3041 - acc: 0.6968\n",
      "Epoch 47/200\n",
      "155/155 [==============================] - 0s 181us/step - loss: 0.3025 - acc: 0.6968\n",
      "Epoch 48/200\n",
      "155/155 [==============================] - 0s 170us/step - loss: 0.3024 - acc: 0.6968\n",
      "Epoch 49/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.3009 - acc: 0.6968\n",
      "Epoch 50/200\n",
      "155/155 [==============================] - 0s 166us/step - loss: 0.2995 - acc: 0.6968\n",
      "Epoch 51/200\n",
      "155/155 [==============================] - 0s 172us/step - loss: 0.2992 - acc: 0.6968\n",
      "Epoch 52/200\n",
      "155/155 [==============================] - 0s 169us/step - loss: 0.2988 - acc: 0.6968\n",
      "Epoch 53/200\n",
      "155/155 [==============================] - 0s 179us/step - loss: 0.2975 - acc: 0.6968\n",
      "Epoch 54/200\n",
      "155/155 [==============================] - 0s 167us/step - loss: 0.2977 - acc: 0.6968\n",
      "Epoch 55/200\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.2957 - acc: 0.6968\n",
      "Epoch 56/200\n",
      "155/155 [==============================] - 0s 168us/step - loss: 0.2953 - acc: 0.6968\n",
      "Epoch 57/200\n",
      "155/155 [==============================] - 0s 430us/step - loss: 0.2951 - acc: 0.6968\n",
      "Epoch 58/200\n",
      "155/155 [==============================] - 0s 172us/step - loss: 0.2940 - acc: 0.6968\n",
      "Epoch 59/200\n",
      "155/155 [==============================] - 0s 180us/step - loss: 0.2935 - acc: 0.6968\n",
      "Epoch 60/200\n",
      "155/155 [==============================] - 0s 169us/step - loss: 0.2938 - acc: 0.6968\n",
      "Epoch 61/200\n",
      "155/155 [==============================] - 0s 172us/step - loss: 0.2935 - acc: 0.6968\n",
      "Epoch 62/200\n",
      "155/155 [==============================] - 0s 169us/step - loss: 0.2918 - acc: 0.6968\n",
      "Epoch 63/200\n",
      "155/155 [==============================] - 0s 172us/step - loss: 0.2915 - acc: 0.6968\n",
      "Epoch 64/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.2913 - acc: 0.6968\n",
      "Epoch 65/200\n",
      "155/155 [==============================] - 0s 183us/step - loss: 0.2897 - acc: 0.6968\n",
      "Epoch 66/200\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.2895 - acc: 0.6968\n",
      "Epoch 67/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2891 - acc: 0.6968\n",
      "Epoch 68/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2882 - acc: 0.6968\n",
      "Epoch 69/200\n",
      "155/155 [==============================] - 0s 181us/step - loss: 0.2880 - acc: 0.6968\n",
      "Epoch 70/200\n",
      "155/155 [==============================] - 0s 179us/step - loss: 0.2881 - acc: 0.6968\n",
      "Epoch 71/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.2884 - acc: 0.6968\n",
      "Epoch 72/200\n",
      "155/155 [==============================] - 0s 445us/step - loss: 0.2871 - acc: 0.6968\n",
      "Epoch 73/200\n",
      "155/155 [==============================] - 0s 186us/step - loss: 0.2868 - acc: 0.6968\n",
      "Epoch 74/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2869 - acc: 0.6968\n",
      "Epoch 75/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2864 - acc: 0.6968\n",
      "Epoch 76/200\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.2852 - acc: 0.6968\n",
      "Epoch 77/200\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.2859 - acc: 0.6968\n",
      "Epoch 78/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.2857 - acc: 0.6968\n",
      "Epoch 79/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.2856 - acc: 0.6968\n",
      "Epoch 80/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2854 - acc: 0.6968\n",
      "Epoch 81/200\n",
      "155/155 [==============================] - 0s 181us/step - loss: 0.2848 - acc: 0.6968\n",
      "Epoch 82/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2848 - acc: 0.6968\n",
      "Epoch 83/200\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.2849 - acc: 0.6968\n",
      "Epoch 84/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2843 - acc: 0.6968\n",
      "Epoch 85/200\n",
      "155/155 [==============================] - 0s 181us/step - loss: 0.2836 - acc: 0.6968\n",
      "Epoch 86/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2839 - acc: 0.6968\n",
      "Epoch 87/200\n",
      "155/155 [==============================] - 0s 439us/step - loss: 0.2833 - acc: 0.6968\n",
      "Epoch 88/200\n",
      "155/155 [==============================] - 0s 179us/step - loss: 0.2824 - acc: 0.6968\n",
      "Epoch 89/200\n",
      "155/155 [==============================] - 0s 180us/step - loss: 0.2835 - acc: 0.6968\n",
      "Epoch 90/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2813 - acc: 0.6968\n",
      "Epoch 91/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2833 - acc: 0.6968\n",
      "Epoch 92/200\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.2832 - acc: 0.6968\n",
      "Epoch 93/200\n",
      "155/155 [==============================] - 0s 179us/step - loss: 0.2818 - acc: 0.6968\n",
      "Epoch 94/200\n",
      "155/155 [==============================] - 0s 172us/step - loss: 0.2825 - acc: 0.6968\n",
      "Epoch 95/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2819 - acc: 0.6968\n",
      "Epoch 96/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2819 - acc: 0.6968\n",
      "Epoch 97/200\n",
      "155/155 [==============================] - 0s 173us/step - loss: 0.2821 - acc: 0.6968\n",
      "Epoch 98/200\n",
      "155/155 [==============================] - 0s 180us/step - loss: 0.2809 - acc: 0.6968\n",
      "Epoch 99/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.2809 - acc: 0.6968\n",
      "Epoch 100/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2812 - acc: 0.6968\n",
      "Epoch 101/200\n",
      "155/155 [==============================] - 0s 181us/step - loss: 0.2808 - acc: 0.6968\n",
      "Epoch 102/200\n",
      "155/155 [==============================] - 0s 437us/step - loss: 0.2807 - acc: 0.6968\n",
      "Epoch 103/200\n",
      "155/155 [==============================] - 0s 166us/step - loss: 0.2808 - acc: 0.6968\n",
      "Epoch 104/200\n",
      "155/155 [==============================] - 0s 171us/step - loss: 0.2813 - acc: 0.6968\n",
      "Epoch 105/200\n",
      "155/155 [==============================] - 0s 172us/step - loss: 0.2809 - acc: 0.6968\n",
      "Epoch 106/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2794 - acc: 0.6968\n",
      "Epoch 107/200\n",
      "155/155 [==============================] - 0s 179us/step - loss: 0.2780 - acc: 0.6968\n",
      "Epoch 108/200\n",
      "155/155 [==============================] - 0s 173us/step - loss: 0.2797 - acc: 0.6968\n",
      "Epoch 109/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2796 - acc: 0.6968\n",
      "Epoch 110/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2799 - acc: 0.6968\n",
      "Epoch 111/200\n",
      "155/155 [==============================] - 0s 179us/step - loss: 0.2802 - acc: 0.6968\n",
      "Epoch 112/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2788 - acc: 0.6968\n",
      "Epoch 113/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.2799 - acc: 0.6968\n",
      "Epoch 114/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.2798 - acc: 0.6968\n",
      "Epoch 115/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2798 - acc: 0.6968\n",
      "Epoch 116/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2803 - acc: 0.6968\n",
      "Epoch 117/200\n",
      "155/155 [==============================] - 0s 445us/step - loss: 0.2788 - acc: 0.6968\n",
      "Epoch 118/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2785 - acc: 0.6968\n",
      "Epoch 119/200\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.2780 - acc: 0.6968\n",
      "Epoch 120/200\n",
      "155/155 [==============================] - 0s 180us/step - loss: 0.2778 - acc: 0.6968\n",
      "Epoch 121/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2790 - acc: 0.6968\n",
      "Epoch 122/200\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.2791 - acc: 0.6968\n",
      "Epoch 123/200\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.2801 - acc: 0.6968\n",
      "Epoch 124/200\n",
      "155/155 [==============================] - 0s 181us/step - loss: 0.2779 - acc: 0.6968\n",
      "Epoch 125/200\n",
      "155/155 [==============================] - 0s 179us/step - loss: 0.2785 - acc: 0.6968\n",
      "Epoch 126/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2782 - acc: 0.6968\n",
      "Epoch 127/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2778 - acc: 0.6968\n",
      "Epoch 128/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2777 - acc: 0.6968\n",
      "Epoch 129/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.2774 - acc: 0.6968\n",
      "Epoch 130/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2779 - acc: 0.6968\n",
      "Epoch 131/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2777 - acc: 0.6968\n",
      "Epoch 132/200\n",
      "155/155 [==============================] - 0s 430us/step - loss: 0.2782 - acc: 0.6968\n",
      "Epoch 133/200\n",
      "155/155 [==============================] - 0s 179us/step - loss: 0.2773 - acc: 0.6968\n",
      "Epoch 134/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2778 - acc: 0.6968\n",
      "Epoch 135/200\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.2781 - acc: 0.6968\n",
      "Epoch 136/200\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.2767 - acc: 0.6968\n",
      "Epoch 137/200\n",
      "155/155 [==============================] - 0s 182us/step - loss: 0.2761 - acc: 0.6968\n",
      "Epoch 138/200\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.2772 - acc: 0.6968\n",
      "Epoch 139/200\n",
      "155/155 [==============================] - 0s 173us/step - loss: 0.2762 - acc: 0.6968\n",
      "Epoch 140/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2776 - acc: 0.6968\n",
      "Epoch 141/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.2764 - acc: 0.6968\n",
      "Epoch 142/200\n",
      "155/155 [==============================] - 0s 172us/step - loss: 0.2764 - acc: 0.6968\n",
      "Epoch 143/200\n",
      "155/155 [==============================] - 0s 179us/step - loss: 0.2767 - acc: 0.6968\n",
      "Epoch 144/200\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.2759 - acc: 0.6968\n",
      "Epoch 145/200\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.2757 - acc: 0.6968\n",
      "Epoch 146/200\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.2764 - acc: 0.6968\n",
      "Epoch 147/200\n",
      "155/155 [==============================] - 0s 432us/step - loss: 0.2761 - acc: 0.6968\n",
      "Epoch 148/200\n",
      "155/155 [==============================] - 0s 179us/step - loss: 0.2759 - acc: 0.6968\n",
      "Epoch 149/200\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.2762 - acc: 0.6968\n",
      "Epoch 150/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2756 - acc: 0.6968\n",
      "Epoch 151/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2757 - acc: 0.6968\n",
      "Epoch 152/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2756 - acc: 0.6968\n",
      "Epoch 153/200\n",
      "155/155 [==============================] - 0s 173us/step - loss: 0.2755 - acc: 0.6968\n",
      "Epoch 154/200\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.2752 - acc: 0.6968\n",
      "Epoch 155/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2749 - acc: 0.6968\n",
      "Epoch 156/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2757 - acc: 0.6968\n",
      "Epoch 157/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2749 - acc: 0.6968\n",
      "Epoch 158/200\n",
      "155/155 [==============================] - 0s 173us/step - loss: 0.2753 - acc: 0.6968\n",
      "Epoch 159/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2760 - acc: 0.6968\n",
      "Epoch 160/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2765 - acc: 0.6968\n",
      "Epoch 161/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.2750 - acc: 0.6968\n",
      "Epoch 162/200\n",
      "155/155 [==============================] - 0s 438us/step - loss: 0.2760 - acc: 0.6968\n",
      "Epoch 163/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2748 - acc: 0.6968\n",
      "Epoch 164/200\n",
      "155/155 [==============================] - 0s 171us/step - loss: 0.2752 - acc: 0.6968\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 0s 175us/step - loss: 0.2752 - acc: 0.6968\n",
      "Epoch 166/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2752 - acc: 0.6968\n",
      "Epoch 167/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.2745 - acc: 0.6968\n",
      "Epoch 168/200\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.2743 - acc: 0.6968\n",
      "Epoch 169/200\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.2750 - acc: 0.6968\n",
      "Epoch 170/200\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.2744 - acc: 0.6968\n",
      "Epoch 171/200\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.2739 - acc: 0.6968\n",
      "Epoch 172/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2739 - acc: 0.6968\n",
      "Epoch 173/200\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.2742 - acc: 0.6968\n",
      "Epoch 174/200\n",
      "155/155 [==============================] - 0s 179us/step - loss: 0.2752 - acc: 0.6968\n",
      "Epoch 175/200\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.2740 - acc: 0.6968\n",
      "Epoch 176/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.2744 - acc: 0.6968\n",
      "Epoch 177/200\n",
      "155/155 [==============================] - 0s 435us/step - loss: 0.2749 - acc: 0.6968\n",
      "Epoch 178/200\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.2750 - acc: 0.6968\n",
      "Epoch 179/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2731 - acc: 0.6968\n",
      "Epoch 180/200\n",
      "155/155 [==============================] - 0s 172us/step - loss: 0.2739 - acc: 0.6968\n",
      "Epoch 181/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2735 - acc: 0.6968\n",
      "Epoch 182/200\n",
      "155/155 [==============================] - 0s 182us/step - loss: 0.2738 - acc: 0.6968\n",
      "Epoch 183/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2735 - acc: 0.6968\n",
      "Epoch 184/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.2749 - acc: 0.6968\n",
      "Epoch 185/200\n",
      "155/155 [==============================] - 0s 172us/step - loss: 0.2724 - acc: 0.6968\n",
      "Epoch 186/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.2748 - acc: 0.6968\n",
      "Epoch 187/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2734 - acc: 0.6968\n",
      "Epoch 188/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2751 - acc: 0.6968\n",
      "Epoch 189/200\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.2739 - acc: 0.6968\n",
      "Epoch 190/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2735 - acc: 0.6968\n",
      "Epoch 191/200\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.2719 - acc: 0.6968\n",
      "Epoch 192/200\n",
      "155/155 [==============================] - 0s 443us/step - loss: 0.2735 - acc: 0.6968\n",
      "Epoch 193/200\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2729 - acc: 0.6968\n",
      "Epoch 194/200\n",
      "155/155 [==============================] - 0s 173us/step - loss: 0.2721 - acc: 0.6968\n",
      "Epoch 195/200\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2738 - acc: 0.6968\n",
      "Epoch 196/200\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.2715 - acc: 0.6968\n",
      "Epoch 197/200\n",
      "155/155 [==============================] - 0s 181us/step - loss: 0.2729 - acc: 0.6968\n",
      "Epoch 198/200\n",
      "155/155 [==============================] - 0s 179us/step - loss: 0.2736 - acc: 0.6968\n",
      "Epoch 199/200\n",
      "155/155 [==============================] - 0s 180us/step - loss: 0.2729 - acc: 0.6968\n",
      "Epoch 200/200\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.2729 - acc: 0.6968\n",
      "155/155 [==============================] - 1s 4ms/step\n",
      "[0.27161715876671577, 0.696774197009302]\n",
      "39/39 [==============================] - 0s 161us/step\n",
      "[0.24742105985299134, 0.7948717964001191]\n"
     ]
    }
   ],
   "source": [
    "#Dropout, progressive layers, smaller batches, more epochs\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(25, activation = 'relu', kernel_initializer='normal',input_shape = (6,)))\n",
    "model.add(layers.Dense(50, kernel_regularizer= regularizers.l2(0.005),activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(50,activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(100, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(100, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(150, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(150, activation = 'relu'))\n",
    "model.add(layers.Dense(4, activation = 'linear'))\n",
    "\n",
    "model.compile(optimizer = 'sgd', loss = 'mse', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 100, epochs = 200)\n",
    "\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "results_train = model.evaluate(X_train, y_train)\n",
    "print(results_train)\n",
    "\n",
    "results_test = model.evaluate(X_test, y_test)\n",
    "print(results_test)\n",
    "\n",
    "#Didn't make much of a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "155/155 [==============================] - 3s 18ms/step - loss: 0.3917 - acc: 0.6581\n",
      "Epoch 2/400\n",
      "155/155 [==============================] - 0s 661us/step - loss: 0.3608 - acc: 0.6968\n",
      "Epoch 3/400\n",
      "155/155 [==============================] - 0s 942us/step - loss: 0.3365 - acc: 0.6968\n",
      "Epoch 4/400\n",
      "155/155 [==============================] - 0s 648us/step - loss: 0.3194 - acc: 0.6968\n",
      "Epoch 5/400\n",
      "155/155 [==============================] - 0s 658us/step - loss: 0.3065 - acc: 0.6968\n",
      "Epoch 6/400\n",
      "155/155 [==============================] - 0s 657us/step - loss: 0.2976 - acc: 0.6968\n",
      "Epoch 7/400\n",
      "155/155 [==============================] - 0s 934us/step - loss: 0.2896 - acc: 0.6968\n",
      "Epoch 8/400\n",
      "155/155 [==============================] - 0s 650us/step - loss: 0.2842 - acc: 0.6968\n",
      "Epoch 9/400\n",
      "155/155 [==============================] - 0s 648us/step - loss: 0.2827 - acc: 0.6968\n",
      "Epoch 10/400\n",
      "155/155 [==============================] - 0s 666us/step - loss: 0.2794 - acc: 0.6968\n",
      "Epoch 11/400\n",
      "155/155 [==============================] - 0s 942us/step - loss: 0.2780 - acc: 0.6968\n",
      "Epoch 12/400\n",
      "155/155 [==============================] - 0s 650us/step - loss: 0.2771 - acc: 0.6968\n",
      "Epoch 13/400\n",
      "155/155 [==============================] - 0s 637us/step - loss: 0.2754 - acc: 0.6968\n",
      "Epoch 14/400\n",
      "155/155 [==============================] - 0s 657us/step - loss: 0.2748 - acc: 0.6968\n",
      "Epoch 15/400\n",
      "155/155 [==============================] - 0s 901us/step - loss: 0.2733 - acc: 0.6968\n",
      "Epoch 16/400\n",
      "155/155 [==============================] - 0s 644us/step - loss: 0.2724 - acc: 0.6968\n",
      "Epoch 17/400\n",
      "155/155 [==============================] - 0s 649us/step - loss: 0.2733 - acc: 0.6968\n",
      "Epoch 18/400\n",
      "155/155 [==============================] - 0s 641us/step - loss: 0.2711 - acc: 0.6968\n",
      "Epoch 19/400\n",
      "155/155 [==============================] - 0s 914us/step - loss: 0.2708 - acc: 0.6968\n",
      "Epoch 20/400\n",
      "155/155 [==============================] - 0s 662us/step - loss: 0.2708 - acc: 0.6968\n",
      "Epoch 21/400\n",
      "155/155 [==============================] - 0s 638us/step - loss: 0.2703 - acc: 0.6968\n",
      "Epoch 22/400\n",
      "155/155 [==============================] - 0s 642us/step - loss: 0.2702 - acc: 0.6968\n",
      "Epoch 23/400\n",
      "155/155 [==============================] - 0s 908us/step - loss: 0.2682 - acc: 0.6968\n",
      "Epoch 24/400\n",
      "155/155 [==============================] - 0s 666us/step - loss: 0.2686 - acc: 0.6968\n",
      "Epoch 25/400\n",
      "155/155 [==============================] - 0s 678us/step - loss: 0.2678 - acc: 0.6968\n",
      "Epoch 26/400\n",
      "155/155 [==============================] - 0s 652us/step - loss: 0.2681 - acc: 0.6968\n",
      "Epoch 27/400\n",
      "155/155 [==============================] - 0s 679us/step - loss: 0.2666 - acc: 0.6968\n",
      "Epoch 28/400\n",
      "155/155 [==============================] - 0s 925us/step - loss: 0.2674 - acc: 0.6968\n",
      "Epoch 29/400\n",
      "155/155 [==============================] - 0s 670us/step - loss: 0.2673 - acc: 0.6968\n",
      "Epoch 30/400\n",
      "155/155 [==============================] - 0s 678us/step - loss: 0.2664 - acc: 0.6968\n",
      "Epoch 31/400\n",
      "155/155 [==============================] - 0s 686us/step - loss: 0.2654 - acc: 0.6968\n",
      "Epoch 32/400\n",
      "155/155 [==============================] - 0s 981us/step - loss: 0.2652 - acc: 0.6968\n",
      "Epoch 33/400\n",
      "155/155 [==============================] - 0s 698us/step - loss: 0.2643 - acc: 0.6968\n",
      "Epoch 34/400\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.2647 - acc: 0.6968\n",
      "Epoch 35/400\n",
      "155/155 [==============================] - 0s 841us/step - loss: 0.2630 - acc: 0.6968\n",
      "Epoch 36/400\n",
      "155/155 [==============================] - 0s 705us/step - loss: 0.2629 - acc: 0.6968\n",
      "Epoch 37/400\n",
      "155/155 [==============================] - 0s 703us/step - loss: 0.2626 - acc: 0.6968\n",
      "Epoch 38/400\n",
      "155/155 [==============================] - 0s 939us/step - loss: 0.2617 - acc: 0.6968\n",
      "Epoch 39/400\n",
      "155/155 [==============================] - 0s 613us/step - loss: 0.2615 - acc: 0.6968\n",
      "Epoch 40/400\n",
      "155/155 [==============================] - 0s 610us/step - loss: 0.2600 - acc: 0.6968\n",
      "Epoch 41/400\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2605 - acc: 0.6968\n",
      "Epoch 42/400\n",
      "155/155 [==============================] - 0s 733us/step - loss: 0.2603 - acc: 0.6968\n",
      "Epoch 43/400\n",
      "155/155 [==============================] - 0s 766us/step - loss: 0.2592 - acc: 0.6968\n",
      "Epoch 44/400\n",
      "155/155 [==============================] - 0s 991us/step - loss: 0.2587 - acc: 0.6968\n",
      "Epoch 45/400\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2579 - acc: 0.6968\n",
      "Epoch 46/400\n",
      "155/155 [==============================] - 0s 704us/step - loss: 0.2584 - acc: 0.6968\n",
      "Epoch 47/400\n",
      "155/155 [==============================] - 0s 764us/step - loss: 0.2571 - acc: 0.6968\n",
      "Epoch 48/400\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2578 - acc: 0.6968\n",
      "Epoch 49/400\n",
      "155/155 [==============================] - 0s 745us/step - loss: 0.2569 - acc: 0.6968\n",
      "Epoch 50/400\n",
      "155/155 [==============================] - 0s 704us/step - loss: 0.2568 - acc: 0.6968\n",
      "Epoch 51/400\n",
      "155/155 [==============================] - 0s 678us/step - loss: 0.2557 - acc: 0.6968\n",
      "Epoch 52/400\n",
      "155/155 [==============================] - 0s 945us/step - loss: 0.2561 - acc: 0.6968\n",
      "Epoch 53/400\n",
      "155/155 [==============================] - 0s 661us/step - loss: 0.2549 - acc: 0.6968\n",
      "Epoch 54/400\n",
      "155/155 [==============================] - 0s 676us/step - loss: 0.2544 - acc: 0.6968\n",
      "Epoch 55/400\n",
      "155/155 [==============================] - 0s 650us/step - loss: 0.2549 - acc: 0.6968\n",
      "Epoch 56/400\n",
      "155/155 [==============================] - 0s 932us/step - loss: 0.2527 - acc: 0.6968\n",
      "Epoch 57/400\n",
      "155/155 [==============================] - 0s 648us/step - loss: 0.2534 - acc: 0.6968\n",
      "Epoch 58/400\n",
      "155/155 [==============================] - 0s 661us/step - loss: 0.2526 - acc: 0.6968\n",
      "Epoch 59/400\n",
      "155/155 [==============================] - 0s 655us/step - loss: 0.2518 - acc: 0.6968\n",
      "Epoch 60/400\n",
      "155/155 [==============================] - 0s 940us/step - loss: 0.2504 - acc: 0.6968\n",
      "Epoch 61/400\n",
      "155/155 [==============================] - 0s 658us/step - loss: 0.2513 - acc: 0.6968\n",
      "Epoch 62/400\n",
      "155/155 [==============================] - 0s 677us/step - loss: 0.2509 - acc: 0.6968\n",
      "Epoch 63/400\n",
      "155/155 [==============================] - 0s 672us/step - loss: 0.2505 - acc: 0.6968\n",
      "Epoch 64/400\n",
      "155/155 [==============================] - 0s 971us/step - loss: 0.2502 - acc: 0.6968\n",
      "Epoch 65/400\n",
      "155/155 [==============================] - 0s 758us/step - loss: 0.2490 - acc: 0.6968\n",
      "Epoch 66/400\n",
      "155/155 [==============================] - 0s 766us/step - loss: 0.2494 - acc: 0.6968\n",
      "Epoch 67/400\n",
      "155/155 [==============================] - 0s 862us/step - loss: 0.2487 - acc: 0.6968\n",
      "Epoch 68/400\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2481 - acc: 0.6968\n",
      "Epoch 69/400\n",
      "155/155 [==============================] - 0s 778us/step - loss: 0.2482 - acc: 0.6968\n",
      "Epoch 70/400\n",
      "155/155 [==============================] - 0s 755us/step - loss: 0.2470 - acc: 0.6968\n",
      "Epoch 71/400\n",
      "155/155 [==============================] - 0s 919us/step - loss: 0.2476 - acc: 0.6968\n",
      "Epoch 72/400\n",
      "155/155 [==============================] - 0s 722us/step - loss: 0.2459 - acc: 0.6968\n",
      "Epoch 73/400\n",
      "155/155 [==============================] - 0s 729us/step - loss: 0.2459 - acc: 0.6968\n",
      "Epoch 74/400\n",
      "155/155 [==============================] - 0s 682us/step - loss: 0.2458 - acc: 0.6968\n",
      "Epoch 75/400\n",
      "155/155 [==============================] - 0s 942us/step - loss: 0.2458 - acc: 0.6968\n",
      "Epoch 76/400\n",
      "155/155 [==============================] - 0s 621us/step - loss: 0.2457 - acc: 0.6968\n",
      "Epoch 77/400\n",
      "155/155 [==============================] - 0s 627us/step - loss: 0.2442 - acc: 0.6968\n",
      "Epoch 78/400\n",
      "155/155 [==============================] - 0s 623us/step - loss: 0.2442 - acc: 0.6968\n",
      "Epoch 79/400\n",
      "155/155 [==============================] - 0s 887us/step - loss: 0.2439 - acc: 0.6968\n",
      "Epoch 80/400\n",
      "155/155 [==============================] - 0s 618us/step - loss: 0.2422 - acc: 0.6968\n",
      "Epoch 81/400\n",
      "155/155 [==============================] - 0s 628us/step - loss: 0.2426 - acc: 0.6968\n",
      "Epoch 82/400\n",
      "155/155 [==============================] - 0s 655us/step - loss: 0.2419 - acc: 0.6968\n",
      "Epoch 83/400\n",
      "155/155 [==============================] - 0s 640us/step - loss: 0.2415 - acc: 0.6968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/400\n",
      "155/155 [==============================] - 0s 890us/step - loss: 0.2419 - acc: 0.6968\n",
      "Epoch 85/400\n",
      "155/155 [==============================] - 0s 644us/step - loss: 0.2409 - acc: 0.6968\n",
      "Epoch 86/400\n",
      "155/155 [==============================] - 0s 671us/step - loss: 0.2405 - acc: 0.6968\n",
      "Epoch 87/400\n",
      "155/155 [==============================] - 0s 621us/step - loss: 0.2406 - acc: 0.6968\n",
      "Epoch 88/400\n",
      "155/155 [==============================] - 0s 861us/step - loss: 0.2396 - acc: 0.6968\n",
      "Epoch 89/400\n",
      "155/155 [==============================] - 0s 630us/step - loss: 0.2390 - acc: 0.6968\n",
      "Epoch 90/400\n",
      "155/155 [==============================] - 0s 633us/step - loss: 0.2390 - acc: 0.6968\n",
      "Epoch 91/400\n",
      "155/155 [==============================] - 0s 650us/step - loss: 0.2379 - acc: 0.6968\n",
      "Epoch 92/400\n",
      "155/155 [==============================] - 0s 952us/step - loss: 0.2373 - acc: 0.6968\n",
      "Epoch 93/400\n",
      "155/155 [==============================] - 0s 660us/step - loss: 0.2388 - acc: 0.6968\n",
      "Epoch 94/400\n",
      "155/155 [==============================] - 0s 649us/step - loss: 0.2366 - acc: 0.6968\n",
      "Epoch 95/400\n",
      "155/155 [==============================] - 0s 629us/step - loss: 0.2370 - acc: 0.6968\n",
      "Epoch 96/400\n",
      "155/155 [==============================] - 0s 961us/step - loss: 0.2371 - acc: 0.6968\n",
      "Epoch 97/400\n",
      "155/155 [==============================] - 0s 638us/step - loss: 0.2370 - acc: 0.6968\n",
      "Epoch 98/400\n",
      "155/155 [==============================] - 0s 692us/step - loss: 0.2357 - acc: 0.6968\n",
      "Epoch 99/400\n",
      "155/155 [==============================] - 0s 662us/step - loss: 0.2354 - acc: 0.6968\n",
      "Epoch 100/400\n",
      "155/155 [==============================] - 0s 939us/step - loss: 0.2363 - acc: 0.6968\n",
      "Epoch 101/400\n",
      "155/155 [==============================] - 0s 685us/step - loss: 0.2353 - acc: 0.6968\n",
      "Epoch 102/400\n",
      "155/155 [==============================] - 0s 695us/step - loss: 0.2339 - acc: 0.6968\n",
      "Epoch 103/400\n",
      "155/155 [==============================] - 0s 681us/step - loss: 0.2327 - acc: 0.6968\n",
      "Epoch 104/400\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2333 - acc: 0.6968\n",
      "Epoch 105/400\n",
      "155/155 [==============================] - 0s 718us/step - loss: 0.2327 - acc: 0.6968\n",
      "Epoch 106/400\n",
      "155/155 [==============================] - 0s 723us/step - loss: 0.2327 - acc: 0.6968\n",
      "Epoch 107/400\n",
      "155/155 [==============================] - 0s 702us/step - loss: 0.2315 - acc: 0.6968\n",
      "Epoch 108/400\n",
      "155/155 [==============================] - 0s 978us/step - loss: 0.2313 - acc: 0.6968\n",
      "Epoch 109/400\n",
      "155/155 [==============================] - 0s 740us/step - loss: 0.2321 - acc: 0.6968\n",
      "Epoch 110/400\n",
      "155/155 [==============================] - 0s 697us/step - loss: 0.2315 - acc: 0.6968\n",
      "Epoch 111/400\n",
      "155/155 [==============================] - 0s 675us/step - loss: 0.2307 - acc: 0.6968\n",
      "Epoch 112/400\n",
      "155/155 [==============================] - 0s 960us/step - loss: 0.2307 - acc: 0.6968\n",
      "Epoch 113/400\n",
      "155/155 [==============================] - 0s 723us/step - loss: 0.2290 - acc: 0.6968\n",
      "Epoch 114/400\n",
      "155/155 [==============================] - 0s 720us/step - loss: 0.2294 - acc: 0.6968\n",
      "Epoch 115/400\n",
      "155/155 [==============================] - 0s 697us/step - loss: 0.2282 - acc: 0.6968\n",
      "Epoch 116/400\n",
      "155/155 [==============================] - 0s 948us/step - loss: 0.2278 - acc: 0.6968\n",
      "Epoch 117/400\n",
      "155/155 [==============================] - 0s 709us/step - loss: 0.2275 - acc: 0.6968\n",
      "Epoch 118/400\n",
      "155/155 [==============================] - 0s 693us/step - loss: 0.2272 - acc: 0.6968\n",
      "Epoch 119/400\n",
      "155/155 [==============================] - 0s 967us/step - loss: 0.2269 - acc: 0.6968\n",
      "Epoch 120/400\n",
      "155/155 [==============================] - 0s 697us/step - loss: 0.2260 - acc: 0.6968\n",
      "Epoch 121/400\n",
      "155/155 [==============================] - 0s 726us/step - loss: 0.2256 - acc: 0.6968\n",
      "Epoch 122/400\n",
      "155/155 [==============================] - 0s 749us/step - loss: 0.2262 - acc: 0.6968\n",
      "Epoch 123/400\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2259 - acc: 0.6968\n",
      "Epoch 124/400\n",
      "155/155 [==============================] - 0s 845us/step - loss: 0.2245 - acc: 0.6968\n",
      "Epoch 125/400\n",
      "155/155 [==============================] - 0s 794us/step - loss: 0.2249 - acc: 0.6968\n",
      "Epoch 126/400\n",
      "155/155 [==============================] - 0s 700us/step - loss: 0.2247 - acc: 0.6968\n",
      "Epoch 127/400\n",
      "155/155 [==============================] - 0s 981us/step - loss: 0.2247 - acc: 0.6968\n",
      "Epoch 128/400\n",
      "155/155 [==============================] - 0s 712us/step - loss: 0.2232 - acc: 0.6968\n",
      "Epoch 129/400\n",
      "155/155 [==============================] - 0s 727us/step - loss: 0.2224 - acc: 0.6968\n",
      "Epoch 130/400\n",
      "155/155 [==============================] - 0s 994us/step - loss: 0.2225 - acc: 0.6968\n",
      "Epoch 131/400\n",
      "155/155 [==============================] - 0s 720us/step - loss: 0.2224 - acc: 0.6968\n",
      "Epoch 132/400\n",
      "155/155 [==============================] - 0s 744us/step - loss: 0.2212 - acc: 0.6968\n",
      "Epoch 133/400\n",
      "155/155 [==============================] - 0s 728us/step - loss: 0.2219 - acc: 0.6968\n",
      "Epoch 134/400\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2215 - acc: 0.6968\n",
      "Epoch 135/400\n",
      "155/155 [==============================] - 0s 747us/step - loss: 0.2206 - acc: 0.6968\n",
      "Epoch 136/400\n",
      "155/155 [==============================] - 0s 711us/step - loss: 0.2209 - acc: 0.6968\n",
      "Epoch 137/400\n",
      "155/155 [==============================] - 0s 736us/step - loss: 0.2191 - acc: 0.6968\n",
      "Epoch 138/400\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2199 - acc: 0.6968\n",
      "Epoch 139/400\n",
      "155/155 [==============================] - 0s 777us/step - loss: 0.2187 - acc: 0.6968\n",
      "Epoch 140/400\n",
      "155/155 [==============================] - 0s 768us/step - loss: 0.2194 - acc: 0.6968\n",
      "Epoch 141/400\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2189 - acc: 0.6968\n",
      "Epoch 142/400\n",
      "155/155 [==============================] - 0s 720us/step - loss: 0.2189 - acc: 0.6968\n",
      "Epoch 143/400\n",
      "155/155 [==============================] - 0s 725us/step - loss: 0.2172 - acc: 0.6968\n",
      "Epoch 144/400\n",
      "155/155 [==============================] - 0s 742us/step - loss: 0.2160 - acc: 0.6968\n",
      "Epoch 145/400\n",
      "155/155 [==============================] - 0s 988us/step - loss: 0.2176 - acc: 0.6968\n",
      "Epoch 146/400\n",
      "155/155 [==============================] - 0s 937us/step - loss: 0.2171 - acc: 0.6968\n",
      "Epoch 147/400\n",
      "155/155 [==============================] - 0s 735us/step - loss: 0.2170 - acc: 0.6968\n",
      "Epoch 148/400\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2154 - acc: 0.6968\n",
      "Epoch 149/400\n",
      "155/155 [==============================] - 0s 671us/step - loss: 0.2166 - acc: 0.6968\n",
      "Epoch 150/400\n",
      "155/155 [==============================] - 0s 714us/step - loss: 0.2146 - acc: 0.6968\n",
      "Epoch 151/400\n",
      "155/155 [==============================] - 0s 705us/step - loss: 0.2144 - acc: 0.6968\n",
      "Epoch 152/400\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2137 - acc: 0.6968\n",
      "Epoch 153/400\n",
      "155/155 [==============================] - 0s 766us/step - loss: 0.2137 - acc: 0.6968\n",
      "Epoch 154/400\n",
      "155/155 [==============================] - 0s 749us/step - loss: 0.2130 - acc: 0.6968\n",
      "Epoch 155/400\n",
      "155/155 [==============================] - 0s 755us/step - loss: 0.2142 - acc: 0.6968\n",
      "Epoch 156/400\n",
      "155/155 [==============================] - 0s 951us/step - loss: 0.2119 - acc: 0.6968\n",
      "Epoch 157/400\n",
      "155/155 [==============================] - 0s 703us/step - loss: 0.2124 - acc: 0.6968\n",
      "Epoch 158/400\n",
      "155/155 [==============================] - 0s 703us/step - loss: 0.2115 - acc: 0.6968\n",
      "Epoch 159/400\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2118 - acc: 0.6968\n",
      "Epoch 160/400\n",
      "155/155 [==============================] - 0s 739us/step - loss: 0.2106 - acc: 0.6968\n",
      "Epoch 161/400\n",
      "155/155 [==============================] - 0s 724us/step - loss: 0.2111 - acc: 0.6968\n",
      "Epoch 162/400\n",
      "155/155 [==============================] - 0s 745us/step - loss: 0.2089 - acc: 0.6968\n",
      "Epoch 163/400\n",
      "155/155 [==============================] - 0s 994us/step - loss: 0.2099 - acc: 0.6968\n",
      "Epoch 164/400\n",
      "155/155 [==============================] - 0s 716us/step - loss: 0.2091 - acc: 0.6968\n",
      "Epoch 165/400\n",
      "155/155 [==============================] - 0s 727us/step - loss: 0.2081 - acc: 0.6968\n",
      "Epoch 166/400\n",
      "155/155 [==============================] - 0s 751us/step - loss: 0.2081 - acc: 0.6968\n",
      "Epoch 167/400\n",
      "155/155 [==============================] - 0s 967us/step - loss: 0.2079 - acc: 0.6968\n",
      "Epoch 168/400\n",
      "155/155 [==============================] - 0s 690us/step - loss: 0.2085 - acc: 0.6968\n",
      "Epoch 169/400\n",
      "155/155 [==============================] - 0s 695us/step - loss: 0.2071 - acc: 0.6968\n",
      "Epoch 170/400\n",
      "155/155 [==============================] - 0s 695us/step - loss: 0.2061 - acc: 0.6968\n",
      "Epoch 171/400\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2073 - acc: 0.6968\n",
      "Epoch 172/400\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2048 - acc: 0.6968\n",
      "Epoch 173/400\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2044 - acc: 0.6968\n",
      "Epoch 174/400\n",
      "155/155 [==============================] - 0s 800us/step - loss: 0.2027 - acc: 0.6968\n",
      "Epoch 175/400\n",
      "155/155 [==============================] - 0s 790us/step - loss: 0.2045 - acc: 0.6968\n",
      "Epoch 176/400\n",
      "155/155 [==============================] - 0s 831us/step - loss: 0.2042 - acc: 0.6968\n",
      "Epoch 177/400\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2042 - acc: 0.6968\n",
      "Epoch 178/400\n",
      "155/155 [==============================] - 0s 799us/step - loss: 0.2041 - acc: 0.6968\n",
      "Epoch 179/400\n",
      "155/155 [==============================] - 0s 764us/step - loss: 0.2015 - acc: 0.6968\n",
      "Epoch 180/400\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2038 - acc: 0.6968\n",
      "Epoch 181/400\n",
      "155/155 [==============================] - 0s 743us/step - loss: 0.2009 - acc: 0.6968\n",
      "Epoch 182/400\n",
      "155/155 [==============================] - 0s 710us/step - loss: 0.2004 - acc: 0.6968\n",
      "Epoch 183/400\n",
      "155/155 [==============================] - 0s 743us/step - loss: 0.2029 - acc: 0.6968\n",
      "Epoch 184/400\n",
      "155/155 [==============================] - 0s 992us/step - loss: 0.2024 - acc: 0.6968\n",
      "Epoch 185/400\n",
      "155/155 [==============================] - 0s 710us/step - loss: 0.2000 - acc: 0.6968\n",
      "Epoch 186/400\n",
      "155/155 [==============================] - 0s 711us/step - loss: 0.1980 - acc: 0.6968\n",
      "Epoch 187/400\n",
      "155/155 [==============================] - 0s 712us/step - loss: 0.1976 - acc: 0.6968\n",
      "Epoch 188/400\n",
      "155/155 [==============================] - 0s 975us/step - loss: 0.1960 - acc: 0.6968\n",
      "Epoch 189/400\n",
      "155/155 [==============================] - 0s 714us/step - loss: 0.1993 - acc: 0.6968\n",
      "Epoch 190/400\n",
      "155/155 [==============================] - 0s 714us/step - loss: 0.1995 - acc: 0.6968\n",
      "Epoch 191/400\n",
      "155/155 [==============================] - 0s 964us/step - loss: 0.1979 - acc: 0.6968\n",
      "Epoch 192/400\n",
      "155/155 [==============================] - 0s 707us/step - loss: 0.1985 - acc: 0.6968\n",
      "Epoch 193/400\n",
      "155/155 [==============================] - 0s 724us/step - loss: 0.1977 - acc: 0.6968\n",
      "Epoch 194/400\n",
      "155/155 [==============================] - 0s 729us/step - loss: 0.1966 - acc: 0.6968\n",
      "Epoch 195/400\n",
      "155/155 [==============================] - 0s 989us/step - loss: 0.1967 - acc: 0.6968\n",
      "Epoch 196/400\n",
      "155/155 [==============================] - 0s 717us/step - loss: 0.1957 - acc: 0.6968\n",
      "Epoch 197/400\n",
      "155/155 [==============================] - 0s 724us/step - loss: 0.1968 - acc: 0.6968\n",
      "Epoch 198/400\n",
      "155/155 [==============================] - 0s 741us/step - loss: 0.1938 - acc: 0.6968\n",
      "Epoch 199/400\n",
      "155/155 [==============================] - 0s 948us/step - loss: 0.1932 - acc: 0.6968\n",
      "Epoch 200/400\n",
      "155/155 [==============================] - 0s 700us/step - loss: 0.1931 - acc: 0.6968\n",
      "Epoch 201/400\n",
      "155/155 [==============================] - 0s 706us/step - loss: 0.1940 - acc: 0.6968\n",
      "Epoch 202/400\n",
      "155/155 [==============================] - 0s 705us/step - loss: 0.1922 - acc: 0.6968\n",
      "Epoch 203/400\n",
      "155/155 [==============================] - 0s 977us/step - loss: 0.1927 - acc: 0.6968\n",
      "Epoch 204/400\n",
      "155/155 [==============================] - 0s 713us/step - loss: 0.1927 - acc: 0.6968\n",
      "Epoch 205/400\n",
      "155/155 [==============================] - 0s 729us/step - loss: 0.1955 - acc: 0.6968\n",
      "Epoch 206/400\n",
      "155/155 [==============================] - 0s 729us/step - loss: 0.1898 - acc: 0.6968\n",
      "Epoch 207/400\n",
      "155/155 [==============================] - 0s 907us/step - loss: 0.1919 - acc: 0.6968\n",
      "Epoch 208/400\n",
      "155/155 [==============================] - 0s 707us/step - loss: 0.1891 - acc: 0.6968\n",
      "Epoch 209/400\n",
      "155/155 [==============================] - 0s 720us/step - loss: 0.1880 - acc: 0.6968\n",
      "Epoch 210/400\n",
      "155/155 [==============================] - 0s 977us/step - loss: 0.1871 - acc: 0.6968\n",
      "Epoch 211/400\n",
      "155/155 [==============================] - 0s 712us/step - loss: 0.1873 - acc: 0.6968\n",
      "Epoch 212/400\n",
      "155/155 [==============================] - 0s 720us/step - loss: 0.1881 - acc: 0.6968\n",
      "Epoch 213/400\n",
      "155/155 [==============================] - 0s 725us/step - loss: 0.1895 - acc: 0.6968\n",
      "Epoch 214/400\n",
      "155/155 [==============================] - 0s 964us/step - loss: 0.1858 - acc: 0.6968\n",
      "Epoch 215/400\n",
      "155/155 [==============================] - 0s 716us/step - loss: 0.1855 - acc: 0.6968\n",
      "Epoch 216/400\n",
      "155/155 [==============================] - 0s 710us/step - loss: 0.1869 - acc: 0.6968\n",
      "Epoch 217/400\n",
      "155/155 [==============================] - 0s 714us/step - loss: 0.1875 - acc: 0.6968\n",
      "Epoch 218/400\n",
      "155/155 [==============================] - 0s 968us/step - loss: 0.1917 - acc: 0.6968\n",
      "Epoch 219/400\n",
      "155/155 [==============================] - 0s 714us/step - loss: 0.1857 - acc: 0.6968\n",
      "Epoch 220/400\n",
      "155/155 [==============================] - 0s 722us/step - loss: 0.1854 - acc: 0.6968\n",
      "Epoch 221/400\n",
      "155/155 [==============================] - 0s 715us/step - loss: 0.1816 - acc: 0.6968\n",
      "Epoch 222/400\n",
      "155/155 [==============================] - 0s 978us/step - loss: 0.1838 - acc: 0.6968\n",
      "Epoch 223/400\n",
      "155/155 [==============================] - 0s 705us/step - loss: 0.1829 - acc: 0.6968\n",
      "Epoch 224/400\n",
      "155/155 [==============================] - 0s 712us/step - loss: 0.1850 - acc: 0.6968\n",
      "Epoch 225/400\n",
      "155/155 [==============================] - 0s 993us/step - loss: 0.1845 - acc: 0.6968\n",
      "Epoch 226/400\n",
      "155/155 [==============================] - 0s 715us/step - loss: 0.1849 - acc: 0.6968\n",
      "Epoch 227/400\n",
      "155/155 [==============================] - 0s 715us/step - loss: 0.1815 - acc: 0.6968\n",
      "Epoch 228/400\n",
      "155/155 [==============================] - 0s 735us/step - loss: 0.1835 - acc: 0.6968\n",
      "Epoch 229/400\n",
      "155/155 [==============================] - 0s 979us/step - loss: 0.1840 - acc: 0.6968\n",
      "Epoch 230/400\n",
      "155/155 [==============================] - 0s 704us/step - loss: 0.1799 - acc: 0.6968\n",
      "Epoch 231/400\n",
      "155/155 [==============================] - 0s 745us/step - loss: 0.1799 - acc: 0.6968\n",
      "Epoch 232/400\n",
      "155/155 [==============================] - 0s 711us/step - loss: 0.1824 - acc: 0.6968\n",
      "Epoch 233/400\n",
      "155/155 [==============================] - 0s 973us/step - loss: 0.1813 - acc: 0.6968\n",
      "Epoch 234/400\n",
      "155/155 [==============================] - 0s 701us/step - loss: 0.1820 - acc: 0.6968\n",
      "Epoch 235/400\n",
      "155/155 [==============================] - 0s 743us/step - loss: 0.1781 - acc: 0.6968\n",
      "Epoch 236/400\n",
      "155/155 [==============================] - 0s 722us/step - loss: 0.1762 - acc: 0.7032\n",
      "Epoch 237/400\n",
      "155/155 [==============================] - 0s 987us/step - loss: 0.1806 - acc: 0.7032\n",
      "Epoch 238/400\n",
      "155/155 [==============================] - 0s 711us/step - loss: 0.1785 - acc: 0.7032\n",
      "Epoch 239/400\n",
      "155/155 [==============================] - 0s 708us/step - loss: 0.1785 - acc: 0.6968\n",
      "Epoch 240/400\n",
      "155/155 [==============================] - 0s 715us/step - loss: 0.1797 - acc: 0.6968\n",
      "Epoch 241/400\n",
      "155/155 [==============================] - 0s 949us/step - loss: 0.1785 - acc: 0.6968\n",
      "Epoch 242/400\n",
      "155/155 [==============================] - 0s 721us/step - loss: 0.1767 - acc: 0.7032\n",
      "Epoch 243/400\n",
      "155/155 [==============================] - 0s 716us/step - loss: 0.1729 - acc: 0.6968\n",
      "Epoch 244/400\n",
      "155/155 [==============================] - 0s 973us/step - loss: 0.1758 - acc: 0.6968\n",
      "Epoch 245/400\n",
      "155/155 [==============================] - 0s 702us/step - loss: 0.1790 - acc: 0.6968\n",
      "Epoch 246/400\n",
      "155/155 [==============================] - 0s 725us/step - loss: 0.1775 - acc: 0.7097\n",
      "Epoch 247/400\n",
      "155/155 [==============================] - 0s 720us/step - loss: 0.1744 - acc: 0.6968\n",
      "Epoch 248/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 0s 954us/step - loss: 0.1741 - acc: 0.6903\n",
      "Epoch 249/400\n",
      "155/155 [==============================] - 0s 706us/step - loss: 0.1756 - acc: 0.7032\n",
      "Epoch 250/400\n",
      "155/155 [==============================] - 0s 707us/step - loss: 0.1736 - acc: 0.7032\n",
      "Epoch 251/400\n",
      "155/155 [==============================] - 0s 714us/step - loss: 0.1738 - acc: 0.6968\n",
      "Epoch 252/400\n",
      "155/155 [==============================] - 0s 962us/step - loss: 0.1718 - acc: 0.6968\n",
      "Epoch 253/400\n",
      "155/155 [==============================] - 0s 717us/step - loss: 0.1700 - acc: 0.6968\n",
      "Epoch 254/400\n",
      "155/155 [==============================] - 0s 711us/step - loss: 0.1726 - acc: 0.6903\n",
      "Epoch 255/400\n",
      "155/155 [==============================] - 0s 704us/step - loss: 0.1724 - acc: 0.6968\n",
      "Epoch 256/400\n",
      "155/155 [==============================] - 0s 966us/step - loss: 0.1696 - acc: 0.6968\n",
      "Epoch 257/400\n",
      "155/155 [==============================] - 0s 708us/step - loss: 0.1718 - acc: 0.6968\n",
      "Epoch 258/400\n",
      "155/155 [==============================] - 0s 717us/step - loss: 0.1719 - acc: 0.7097\n",
      "Epoch 259/400\n",
      "155/155 [==============================] - 0s 715us/step - loss: 0.1700 - acc: 0.7032\n",
      "Epoch 260/400\n",
      "155/155 [==============================] - 0s 962us/step - loss: 0.1727 - acc: 0.6903\n",
      "Epoch 261/400\n",
      "155/155 [==============================] - 0s 710us/step - loss: 0.1728 - acc: 0.7032\n",
      "Epoch 262/400\n",
      "155/155 [==============================] - 0s 701us/step - loss: 0.1710 - acc: 0.7097\n",
      "Epoch 263/400\n",
      "155/155 [==============================] - 0s 986us/step - loss: 0.1677 - acc: 0.6839\n",
      "Epoch 264/400\n",
      "155/155 [==============================] - 0s 704us/step - loss: 0.1679 - acc: 0.7097\n",
      "Epoch 265/400\n",
      "155/155 [==============================] - 0s 686us/step - loss: 0.1720 - acc: 0.7032\n",
      "Epoch 266/400\n",
      "155/155 [==============================] - 0s 693us/step - loss: 0.1673 - acc: 0.6968\n",
      "Epoch 267/400\n",
      "155/155 [==============================] - 0s 937us/step - loss: 0.1657 - acc: 0.7032\n",
      "Epoch 268/400\n",
      "155/155 [==============================] - 0s 684us/step - loss: 0.1697 - acc: 0.7097\n",
      "Epoch 269/400\n",
      "155/155 [==============================] - 0s 686us/step - loss: 0.1681 - acc: 0.7097\n",
      "Epoch 270/400\n",
      "155/155 [==============================] - 0s 689us/step - loss: 0.1661 - acc: 0.7161\n",
      "Epoch 271/400\n",
      "155/155 [==============================] - 0s 953us/step - loss: 0.1667 - acc: 0.7032\n",
      "Epoch 272/400\n",
      "155/155 [==============================] - 0s 688us/step - loss: 0.1706 - acc: 0.6968\n",
      "Epoch 273/400\n",
      "155/155 [==============================] - 0s 690us/step - loss: 0.1650 - acc: 0.7097\n",
      "Epoch 274/400\n",
      "155/155 [==============================] - 0s 687us/step - loss: 0.1628 - acc: 0.7097\n",
      "Epoch 275/400\n",
      "155/155 [==============================] - 0s 933us/step - loss: 0.1661 - acc: 0.7097\n",
      "Epoch 276/400\n",
      "155/155 [==============================] - 0s 685us/step - loss: 0.1670 - acc: 0.7032\n",
      "Epoch 277/400\n",
      "155/155 [==============================] - 0s 681us/step - loss: 0.1671 - acc: 0.7032\n",
      "Epoch 278/400\n",
      "155/155 [==============================] - 0s 683us/step - loss: 0.1628 - acc: 0.6968\n",
      "Epoch 279/400\n",
      "155/155 [==============================] - 0s 951us/step - loss: 0.1614 - acc: 0.7161\n",
      "Epoch 280/400\n",
      "155/155 [==============================] - 0s 682us/step - loss: 0.1635 - acc: 0.7161\n",
      "Epoch 281/400\n",
      "155/155 [==============================] - 0s 689us/step - loss: 0.1631 - acc: 0.7161\n",
      "Epoch 282/400\n",
      "155/155 [==============================] - 0s 679us/step - loss: 0.1605 - acc: 0.7290\n",
      "Epoch 283/400\n",
      "155/155 [==============================] - 0s 956us/step - loss: 0.1649 - acc: 0.7161\n",
      "Epoch 284/400\n",
      "155/155 [==============================] - 0s 674us/step - loss: 0.1610 - acc: 0.7226\n",
      "Epoch 285/400\n",
      "155/155 [==============================] - 0s 690us/step - loss: 0.1622 - acc: 0.6903\n",
      "Epoch 286/400\n",
      "155/155 [==============================] - 0s 687us/step - loss: 0.1628 - acc: 0.7161\n",
      "Epoch 287/400\n",
      "155/155 [==============================] - 0s 954us/step - loss: 0.1584 - acc: 0.7161\n",
      "Epoch 288/400\n",
      "155/155 [==============================] - 0s 697us/step - loss: 0.1612 - acc: 0.7097\n",
      "Epoch 289/400\n",
      "155/155 [==============================] - 0s 683us/step - loss: 0.1613 - acc: 0.7226\n",
      "Epoch 290/400\n",
      "155/155 [==============================] - 0s 727us/step - loss: 0.1616 - acc: 0.7097\n",
      "Epoch 291/400\n",
      "155/155 [==============================] - 0s 987us/step - loss: 0.1603 - acc: 0.7161\n",
      "Epoch 292/400\n",
      "155/155 [==============================] - 0s 699us/step - loss: 0.1617 - acc: 0.7161\n",
      "Epoch 293/400\n",
      "155/155 [==============================] - 0s 732us/step - loss: 0.1583 - acc: 0.7355\n",
      "Epoch 294/400\n",
      "155/155 [==============================] - 0s 690us/step - loss: 0.1603 - acc: 0.7290\n",
      "Epoch 295/400\n",
      "155/155 [==============================] - 0s 944us/step - loss: 0.1583 - acc: 0.6903\n",
      "Epoch 296/400\n",
      "155/155 [==============================] - 0s 681us/step - loss: 0.1622 - acc: 0.7161\n",
      "Epoch 297/400\n",
      "155/155 [==============================] - 0s 698us/step - loss: 0.1568 - acc: 0.7355\n",
      "Epoch 298/400\n",
      "155/155 [==============================] - 0s 709us/step - loss: 0.1557 - acc: 0.7484\n",
      "Epoch 299/400\n",
      "155/155 [==============================] - 0s 966us/step - loss: 0.1565 - acc: 0.7226\n",
      "Epoch 300/400\n",
      "155/155 [==============================] - 0s 684us/step - loss: 0.1579 - acc: 0.7355\n",
      "Epoch 301/400\n",
      "155/155 [==============================] - 0s 693us/step - loss: 0.1592 - acc: 0.7290\n",
      "Epoch 302/400\n",
      "155/155 [==============================] - 0s 684us/step - loss: 0.1568 - acc: 0.7613\n",
      "Epoch 303/400\n",
      "155/155 [==============================] - 0s 937us/step - loss: 0.1585 - acc: 0.7097\n",
      "Epoch 304/400\n",
      "155/155 [==============================] - 0s 699us/step - loss: 0.1586 - acc: 0.7290\n",
      "Epoch 305/400\n",
      "155/155 [==============================] - 0s 690us/step - loss: 0.1572 - acc: 0.7419\n",
      "Epoch 306/400\n",
      "155/155 [==============================] - 0s 946us/step - loss: 0.1591 - acc: 0.7290\n",
      "Epoch 307/400\n",
      "155/155 [==============================] - 0s 671us/step - loss: 0.1518 - acc: 0.7226\n",
      "Epoch 308/400\n",
      "155/155 [==============================] - 0s 691us/step - loss: 0.1571 - acc: 0.7290\n",
      "Epoch 309/400\n",
      "155/155 [==============================] - 0s 687us/step - loss: 0.1550 - acc: 0.7419\n",
      "Epoch 310/400\n",
      "155/155 [==============================] - 0s 946us/step - loss: 0.1612 - acc: 0.7419\n",
      "Epoch 311/400\n",
      "155/155 [==============================] - 0s 677us/step - loss: 0.1562 - acc: 0.7097\n",
      "Epoch 312/400\n",
      "155/155 [==============================] - 0s 701us/step - loss: 0.1550 - acc: 0.7419\n",
      "Epoch 313/400\n",
      "155/155 [==============================] - 0s 687us/step - loss: 0.1530 - acc: 0.7355\n",
      "Epoch 314/400\n",
      "155/155 [==============================] - 0s 958us/step - loss: 0.1507 - acc: 0.7419\n",
      "Epoch 315/400\n",
      "155/155 [==============================] - 0s 684us/step - loss: 0.1553 - acc: 0.7355\n",
      "Epoch 316/400\n",
      "155/155 [==============================] - 0s 693us/step - loss: 0.1533 - acc: 0.7161\n",
      "Epoch 317/400\n",
      "155/155 [==============================] - 0s 693us/step - loss: 0.1524 - acc: 0.7161\n",
      "Epoch 318/400\n",
      "155/155 [==============================] - 0s 964us/step - loss: 0.1540 - acc: 0.7290\n",
      "Epoch 319/400\n",
      "155/155 [==============================] - 0s 690us/step - loss: 0.1552 - acc: 0.7226\n",
      "Epoch 320/400\n",
      "155/155 [==============================] - 0s 695us/step - loss: 0.1488 - acc: 0.7419\n",
      "Epoch 321/400\n",
      "155/155 [==============================] - 0s 707us/step - loss: 0.1509 - acc: 0.7419\n",
      "Epoch 322/400\n",
      "155/155 [==============================] - 0s 980us/step - loss: 0.1493 - acc: 0.7290\n",
      "Epoch 323/400\n",
      "155/155 [==============================] - 0s 751us/step - loss: 0.1518 - acc: 0.7419\n",
      "Epoch 324/400\n",
      "155/155 [==============================] - 0s 734us/step - loss: 0.1519 - acc: 0.7484\n",
      "Epoch 325/400\n",
      "155/155 [==============================] - 0s 699us/step - loss: 0.1530 - acc: 0.7290\n",
      "Epoch 326/400\n",
      "155/155 [==============================] - 0s 937us/step - loss: 0.1538 - acc: 0.7226\n",
      "Epoch 327/400\n",
      "155/155 [==============================] - 0s 682us/step - loss: 0.1497 - acc: 0.7548\n",
      "Epoch 328/400\n",
      "155/155 [==============================] - 0s 699us/step - loss: 0.1493 - acc: 0.7548\n",
      "Epoch 329/400\n",
      "155/155 [==============================] - 0s 825us/step - loss: 0.1523 - acc: 0.7355\n",
      "Epoch 330/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 0s 946us/step - loss: 0.1530 - acc: 0.7161\n",
      "Epoch 331/400\n",
      "155/155 [==============================] - 0s 688us/step - loss: 0.1518 - acc: 0.7226\n",
      "Epoch 332/400\n",
      "155/155 [==============================] - 0s 687us/step - loss: 0.1488 - acc: 0.7097\n",
      "Epoch 333/400\n",
      "155/155 [==============================] - 0s 699us/step - loss: 0.1517 - acc: 0.7419\n",
      "Epoch 334/400\n",
      "155/155 [==============================] - 0s 928us/step - loss: 0.1485 - acc: 0.7290\n",
      "Epoch 335/400\n",
      "155/155 [==============================] - 0s 719us/step - loss: 0.1474 - acc: 0.7226\n",
      "Epoch 336/400\n",
      "155/155 [==============================] - 0s 696us/step - loss: 0.1464 - acc: 0.7613\n",
      "Epoch 337/400\n",
      "155/155 [==============================] - 0s 968us/step - loss: 0.1497 - acc: 0.7226\n",
      "Epoch 338/400\n",
      "155/155 [==============================] - 0s 713us/step - loss: 0.1426 - acc: 0.7548\n",
      "Epoch 339/400\n",
      "155/155 [==============================] - 0s 706us/step - loss: 0.1475 - acc: 0.7419\n",
      "Epoch 340/400\n",
      "155/155 [==============================] - 0s 693us/step - loss: 0.1507 - acc: 0.7290\n",
      "Epoch 341/400\n",
      "155/155 [==============================] - 0s 936us/step - loss: 0.1446 - acc: 0.7742\n",
      "Epoch 342/400\n",
      "155/155 [==============================] - 0s 685us/step - loss: 0.1458 - acc: 0.7613\n",
      "Epoch 343/400\n",
      "155/155 [==============================] - 0s 695us/step - loss: 0.1479 - acc: 0.7613\n",
      "Epoch 344/400\n",
      "155/155 [==============================] - 0s 701us/step - loss: 0.1470 - acc: 0.7484\n",
      "Epoch 345/400\n",
      "155/155 [==============================] - 0s 946us/step - loss: 0.1427 - acc: 0.7613\n",
      "Epoch 346/400\n",
      "155/155 [==============================] - 0s 693us/step - loss: 0.1441 - acc: 0.7548\n",
      "Epoch 347/400\n",
      "155/155 [==============================] - 0s 686us/step - loss: 0.1491 - acc: 0.7355\n",
      "Epoch 348/400\n",
      "155/155 [==============================] - 0s 684us/step - loss: 0.1449 - acc: 0.7355\n",
      "Epoch 349/400\n",
      "155/155 [==============================] - 0s 963us/step - loss: 0.1480 - acc: 0.7419\n",
      "Epoch 350/400\n",
      "155/155 [==============================] - 0s 689us/step - loss: 0.1461 - acc: 0.7613\n",
      "Epoch 351/400\n",
      "155/155 [==============================] - 0s 693us/step - loss: 0.1466 - acc: 0.7548\n",
      "Epoch 352/400\n",
      "155/155 [==============================] - 0s 692us/step - loss: 0.1416 - acc: 0.7484\n",
      "Epoch 353/400\n",
      "155/155 [==============================] - 0s 936us/step - loss: 0.1440 - acc: 0.7161\n",
      "Epoch 354/400\n",
      "155/155 [==============================] - 0s 691us/step - loss: 0.1486 - acc: 0.7032\n",
      "Epoch 355/400\n",
      "155/155 [==============================] - 0s 698us/step - loss: 0.1449 - acc: 0.7419\n",
      "Epoch 356/400\n",
      "155/155 [==============================] - 0s 688us/step - loss: 0.1433 - acc: 0.7419\n",
      "Epoch 357/400\n",
      "155/155 [==============================] - 0s 918us/step - loss: 0.1426 - acc: 0.7484\n",
      "Epoch 358/400\n",
      "155/155 [==============================] - 0s 682us/step - loss: 0.1466 - acc: 0.7419\n",
      "Epoch 359/400\n",
      "155/155 [==============================] - 0s 685us/step - loss: 0.1381 - acc: 0.7677\n",
      "Epoch 360/400\n",
      "155/155 [==============================] - 0s 691us/step - loss: 0.1444 - acc: 0.7355\n",
      "Epoch 361/400\n",
      "155/155 [==============================] - 0s 953us/step - loss: 0.1430 - acc: 0.7419\n",
      "Epoch 362/400\n",
      "155/155 [==============================] - 0s 687us/step - loss: 0.1483 - acc: 0.7484\n",
      "Epoch 363/400\n",
      "155/155 [==============================] - 0s 683us/step - loss: 0.1444 - acc: 0.7548\n",
      "Epoch 364/400\n",
      "155/155 [==============================] - 0s 689us/step - loss: 0.1450 - acc: 0.7677\n",
      "Epoch 365/400\n",
      "155/155 [==============================] - 0s 947us/step - loss: 0.1474 - acc: 0.7484\n",
      "Epoch 366/400\n",
      "155/155 [==============================] - 0s 683us/step - loss: 0.1403 - acc: 0.7548\n",
      "Epoch 367/400\n",
      "155/155 [==============================] - 0s 687us/step - loss: 0.1416 - acc: 0.7226\n",
      "Epoch 368/400\n",
      "155/155 [==============================] - 0s 725us/step - loss: 0.1379 - acc: 0.7419\n",
      "Epoch 369/400\n",
      "155/155 [==============================] - 0s 970us/step - loss: 0.1439 - acc: 0.7484\n",
      "Epoch 370/400\n",
      "155/155 [==============================] - 0s 697us/step - loss: 0.1395 - acc: 0.7548\n",
      "Epoch 371/400\n",
      "155/155 [==============================] - 0s 705us/step - loss: 0.1416 - acc: 0.7355\n",
      "Epoch 372/400\n",
      "155/155 [==============================] - 0s 691us/step - loss: 0.1428 - acc: 0.7226\n",
      "Epoch 373/400\n",
      "155/155 [==============================] - 0s 937us/step - loss: 0.1403 - acc: 0.7419\n",
      "Epoch 374/400\n",
      "155/155 [==============================] - 0s 693us/step - loss: 0.1432 - acc: 0.7484\n",
      "Epoch 375/400\n",
      "155/155 [==============================] - 0s 704us/step - loss: 0.1410 - acc: 0.7613\n",
      "Epoch 376/400\n",
      "155/155 [==============================] - 0s 685us/step - loss: 0.1399 - acc: 0.7548\n",
      "Epoch 377/400\n",
      "155/155 [==============================] - 0s 952us/step - loss: 0.1409 - acc: 0.7548\n",
      "Epoch 378/400\n",
      "155/155 [==============================] - 0s 684us/step - loss: 0.1428 - acc: 0.7355\n",
      "Epoch 379/400\n",
      "155/155 [==============================] - 0s 693us/step - loss: 0.1366 - acc: 0.7677\n",
      "Epoch 380/400\n",
      "155/155 [==============================] - 0s 957us/step - loss: 0.1363 - acc: 0.7484\n",
      "Epoch 381/400\n",
      "155/155 [==============================] - 0s 696us/step - loss: 0.1394 - acc: 0.7419\n",
      "Epoch 382/400\n",
      "155/155 [==============================] - 0s 689us/step - loss: 0.1372 - acc: 0.7613\n",
      "Epoch 383/400\n",
      "155/155 [==============================] - 0s 692us/step - loss: 0.1389 - acc: 0.7548\n",
      "Epoch 384/400\n",
      "155/155 [==============================] - 0s 957us/step - loss: 0.1375 - acc: 0.7548\n",
      "Epoch 385/400\n",
      "155/155 [==============================] - 0s 685us/step - loss: 0.1395 - acc: 0.7484\n",
      "Epoch 386/400\n",
      "155/155 [==============================] - 0s 689us/step - loss: 0.1383 - acc: 0.7419\n",
      "Epoch 387/400\n",
      "155/155 [==============================] - 0s 692us/step - loss: 0.1344 - acc: 0.7677\n",
      "Epoch 388/400\n",
      "155/155 [==============================] - 0s 980us/step - loss: 0.1402 - acc: 0.7355\n",
      "Epoch 389/400\n",
      "155/155 [==============================] - 0s 690us/step - loss: 0.1350 - acc: 0.7677\n",
      "Epoch 390/400\n",
      "155/155 [==============================] - 0s 709us/step - loss: 0.1370 - acc: 0.7355\n",
      "Epoch 391/400\n",
      "155/155 [==============================] - 0s 690us/step - loss: 0.1376 - acc: 0.7548\n",
      "Epoch 392/400\n",
      "155/155 [==============================] - 0s 947us/step - loss: 0.1376 - acc: 0.7419\n",
      "Epoch 393/400\n",
      "155/155 [==============================] - 0s 685us/step - loss: 0.1359 - acc: 0.7548\n",
      "Epoch 394/400\n",
      "155/155 [==============================] - 0s 687us/step - loss: 0.1378 - acc: 0.7290\n",
      "Epoch 395/400\n",
      "155/155 [==============================] - 0s 702us/step - loss: 0.1385 - acc: 0.7419\n",
      "Epoch 396/400\n",
      "155/155 [==============================] - 0s 957us/step - loss: 0.1368 - acc: 0.7419\n",
      "Epoch 397/400\n",
      "155/155 [==============================] - 0s 721us/step - loss: 0.1324 - acc: 0.7548\n",
      "Epoch 398/400\n",
      "155/155 [==============================] - 0s 714us/step - loss: 0.1357 - acc: 0.7355\n",
      "Epoch 399/400\n",
      "155/155 [==============================] - 0s 708us/step - loss: 0.1428 - acc: 0.7226\n",
      "Epoch 400/400\n",
      "155/155 [==============================] - 0s 965us/step - loss: 0.1358 - acc: 0.7742\n",
      "155/155 [==============================] - 1s 5ms/step\n",
      "[0.12560532294934795, 0.7870967699635414]\n",
      "39/39 [==============================] - 0s 145us/step\n",
      "[0.14293244595711047, 0.7435897451180679]\n"
     ]
    }
   ],
   "source": [
    "#Greatly larger number of epochs, smaller batch size\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(25, activation = 'relu', kernel_initializer='normal',input_shape = (6,)))\n",
    "model.add(layers.Dense(50, kernel_regularizer= regularizers.l2(0.005),activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(50,activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(100, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(100, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(150, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(150, activation = 'relu'))\n",
    "model.add(layers.Dense(4, activation = 'linear'))\n",
    "\n",
    "model.compile(optimizer = 'sgd', loss = 'mse', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 10, epochs = 400)\n",
    "\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "results_train = model.evaluate(X_train, y_train)\n",
    "print(results_train)\n",
    "\n",
    "results_test = model.evaluate(X_test, y_test)\n",
    "print(results_test)\n",
    "\n",
    "#Training accuracy went up but testing accuracy went down\n",
    "#Try again with fewer epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "155/155 [==============================] - 3s 18ms/step - loss: 0.3996 - acc: 0.5484\n",
      "Epoch 2/300\n",
      "155/155 [==============================] - 0s 672us/step - loss: 0.3716 - acc: 0.6968\n",
      "Epoch 3/300\n",
      "155/155 [==============================] - 0s 925us/step - loss: 0.3477 - acc: 0.6968\n",
      "Epoch 4/300\n",
      "155/155 [==============================] - 0s 628us/step - loss: 0.3291 - acc: 0.6968\n",
      "Epoch 5/300\n",
      "155/155 [==============================] - 0s 645us/step - loss: 0.3151 - acc: 0.6968\n",
      "Epoch 6/300\n",
      "155/155 [==============================] - 0s 654us/step - loss: 0.3041 - acc: 0.6968\n",
      "Epoch 7/300\n",
      "155/155 [==============================] - 0s 916us/step - loss: 0.2949 - acc: 0.6968\n",
      "Epoch 8/300\n",
      "155/155 [==============================] - 0s 652us/step - loss: 0.2904 - acc: 0.6968\n",
      "Epoch 9/300\n",
      "155/155 [==============================] - 0s 650us/step - loss: 0.2861 - acc: 0.6968\n",
      "Epoch 10/300\n",
      "155/155 [==============================] - 0s 656us/step - loss: 0.2818 - acc: 0.6968\n",
      "Epoch 11/300\n",
      "155/155 [==============================] - 0s 658us/step - loss: 0.2807 - acc: 0.6968\n",
      "Epoch 12/300\n",
      "155/155 [==============================] - 0s 926us/step - loss: 0.2790 - acc: 0.6968\n",
      "Epoch 13/300\n",
      "155/155 [==============================] - 0s 673us/step - loss: 0.2761 - acc: 0.6968\n",
      "Epoch 14/300\n",
      "155/155 [==============================] - 0s 656us/step - loss: 0.2751 - acc: 0.6968\n",
      "Epoch 15/300\n",
      "155/155 [==============================] - 0s 653us/step - loss: 0.2740 - acc: 0.6968\n",
      "Epoch 16/300\n",
      "155/155 [==============================] - 0s 932us/step - loss: 0.2737 - acc: 0.6968\n",
      "Epoch 17/300\n",
      "155/155 [==============================] - 0s 660us/step - loss: 0.2728 - acc: 0.6968\n",
      "Epoch 18/300\n",
      "155/155 [==============================] - 0s 654us/step - loss: 0.2724 - acc: 0.6968\n",
      "Epoch 19/300\n",
      "155/155 [==============================] - 0s 649us/step - loss: 0.2711 - acc: 0.6968\n",
      "Epoch 20/300\n",
      "155/155 [==============================] - 0s 938us/step - loss: 0.2721 - acc: 0.6968\n",
      "Epoch 21/300\n",
      "155/155 [==============================] - 0s 647us/step - loss: 0.2682 - acc: 0.6968\n",
      "Epoch 22/300\n",
      "155/155 [==============================] - 0s 655us/step - loss: 0.2689 - acc: 0.6968\n",
      "Epoch 23/300\n",
      "155/155 [==============================] - 0s 660us/step - loss: 0.2690 - acc: 0.6968\n",
      "Epoch 24/300\n",
      "155/155 [==============================] - 0s 919us/step - loss: 0.2685 - acc: 0.6968\n",
      "Epoch 25/300\n",
      "155/155 [==============================] - 0s 674us/step - loss: 0.2703 - acc: 0.6968\n",
      "Epoch 26/300\n",
      "155/155 [==============================] - 0s 648us/step - loss: 0.2678 - acc: 0.6968\n",
      "Epoch 27/300\n",
      "155/155 [==============================] - 0s 648us/step - loss: 0.2677 - acc: 0.6968\n",
      "Epoch 28/300\n",
      "155/155 [==============================] - 0s 914us/step - loss: 0.2663 - acc: 0.6968\n",
      "Epoch 29/300\n",
      "155/155 [==============================] - 0s 660us/step - loss: 0.2663 - acc: 0.6968\n",
      "Epoch 30/300\n",
      "155/155 [==============================] - 0s 658us/step - loss: 0.2670 - acc: 0.6968\n",
      "Epoch 31/300\n",
      "155/155 [==============================] - 0s 644us/step - loss: 0.2643 - acc: 0.6968\n",
      "Epoch 32/300\n",
      "155/155 [==============================] - 0s 924us/step - loss: 0.2641 - acc: 0.6968\n",
      "Epoch 33/300\n",
      "155/155 [==============================] - 0s 659us/step - loss: 0.2647 - acc: 0.6968\n",
      "Epoch 34/300\n",
      "155/155 [==============================] - 0s 669us/step - loss: 0.2628 - acc: 0.6968\n",
      "Epoch 35/300\n",
      "155/155 [==============================] - 0s 649us/step - loss: 0.2643 - acc: 0.6968\n",
      "Epoch 36/300\n",
      "155/155 [==============================] - 0s 915us/step - loss: 0.2628 - acc: 0.6968\n",
      "Epoch 37/300\n",
      "155/155 [==============================] - 0s 645us/step - loss: 0.2619 - acc: 0.6968\n",
      "Epoch 38/300\n",
      "155/155 [==============================] - 0s 650us/step - loss: 0.2610 - acc: 0.6968\n",
      "Epoch 39/300\n",
      "155/155 [==============================] - 0s 654us/step - loss: 0.2612 - acc: 0.6968\n",
      "Epoch 40/300\n",
      "155/155 [==============================] - 0s 903us/step - loss: 0.2615 - acc: 0.6968\n",
      "Epoch 41/300\n",
      "155/155 [==============================] - 0s 652us/step - loss: 0.2606 - acc: 0.6968\n",
      "Epoch 42/300\n",
      "155/155 [==============================] - 0s 657us/step - loss: 0.2602 - acc: 0.6968\n",
      "Epoch 43/300\n",
      "155/155 [==============================] - 0s 651us/step - loss: 0.2588 - acc: 0.6968\n",
      "Epoch 44/300\n",
      "155/155 [==============================] - 0s 653us/step - loss: 0.2589 - acc: 0.6968\n",
      "Epoch 45/300\n",
      "155/155 [==============================] - 0s 922us/step - loss: 0.2594 - acc: 0.6968\n",
      "Epoch 46/300\n",
      "155/155 [==============================] - 0s 653us/step - loss: 0.2586 - acc: 0.6968\n",
      "Epoch 47/300\n",
      "155/155 [==============================] - 0s 663us/step - loss: 0.2573 - acc: 0.6968\n",
      "Epoch 48/300\n",
      "155/155 [==============================] - 0s 655us/step - loss: 0.2573 - acc: 0.6968\n",
      "Epoch 49/300\n",
      "155/155 [==============================] - 0s 921us/step - loss: 0.2561 - acc: 0.6968\n",
      "Epoch 50/300\n",
      "155/155 [==============================] - 0s 653us/step - loss: 0.2548 - acc: 0.6968\n",
      "Epoch 51/300\n",
      "155/155 [==============================] - 0s 657us/step - loss: 0.2546 - acc: 0.6968\n",
      "Epoch 52/300\n",
      "155/155 [==============================] - 0s 660us/step - loss: 0.2551 - acc: 0.6968\n",
      "Epoch 53/300\n",
      "155/155 [==============================] - 0s 976us/step - loss: 0.2556 - acc: 0.6968\n",
      "Epoch 54/300\n",
      "155/155 [==============================] - 0s 660us/step - loss: 0.2534 - acc: 0.6968\n",
      "Epoch 55/300\n",
      "155/155 [==============================] - 0s 657us/step - loss: 0.2531 - acc: 0.6968\n",
      "Epoch 56/300\n",
      "155/155 [==============================] - 0s 663us/step - loss: 0.2535 - acc: 0.6968\n",
      "Epoch 57/300\n",
      "155/155 [==============================] - 0s 921us/step - loss: 0.2527 - acc: 0.6968\n",
      "Epoch 58/300\n",
      "155/155 [==============================] - 0s 667us/step - loss: 0.2540 - acc: 0.6968\n",
      "Epoch 59/300\n",
      "155/155 [==============================] - 0s 652us/step - loss: 0.2511 - acc: 0.6968\n",
      "Epoch 60/300\n",
      "155/155 [==============================] - 0s 655us/step - loss: 0.2508 - acc: 0.6968\n",
      "Epoch 61/300\n",
      "155/155 [==============================] - 0s 933us/step - loss: 0.2509 - acc: 0.6968\n",
      "Epoch 62/300\n",
      "155/155 [==============================] - 0s 644us/step - loss: 0.2515 - acc: 0.6968\n",
      "Epoch 63/300\n",
      "155/155 [==============================] - 0s 635us/step - loss: 0.2506 - acc: 0.6968\n",
      "Epoch 64/300\n",
      "155/155 [==============================] - 0s 666us/step - loss: 0.2498 - acc: 0.6968\n",
      "Epoch 65/300\n",
      "155/155 [==============================] - 0s 955us/step - loss: 0.2496 - acc: 0.6968\n",
      "Epoch 66/300\n",
      "155/155 [==============================] - 0s 681us/step - loss: 0.2489 - acc: 0.6968\n",
      "Epoch 67/300\n",
      "155/155 [==============================] - 0s 643us/step - loss: 0.2485 - acc: 0.6968\n",
      "Epoch 68/300\n",
      "155/155 [==============================] - 0s 653us/step - loss: 0.2479 - acc: 0.6968\n",
      "Epoch 69/300\n",
      "155/155 [==============================] - 0s 910us/step - loss: 0.2466 - acc: 0.6968\n",
      "Epoch 70/300\n",
      "155/155 [==============================] - 0s 644us/step - loss: 0.2473 - acc: 0.6968\n",
      "Epoch 71/300\n",
      "155/155 [==============================] - 0s 672us/step - loss: 0.2473 - acc: 0.6968\n",
      "Epoch 72/300\n",
      "155/155 [==============================] - 0s 654us/step - loss: 0.2471 - acc: 0.6968\n",
      "Epoch 73/300\n",
      "155/155 [==============================] - 0s 915us/step - loss: 0.2452 - acc: 0.6968\n",
      "Epoch 74/300\n",
      "155/155 [==============================] - 0s 650us/step - loss: 0.2453 - acc: 0.6968\n",
      "Epoch 75/300\n",
      "155/155 [==============================] - 0s 686us/step - loss: 0.2454 - acc: 0.6968\n",
      "Epoch 76/300\n",
      "155/155 [==============================] - 0s 698us/step - loss: 0.2446 - acc: 0.6968\n",
      "Epoch 77/300\n",
      "155/155 [==============================] - 0s 944us/step - loss: 0.2450 - acc: 0.6968\n",
      "Epoch 78/300\n",
      "155/155 [==============================] - 0s 660us/step - loss: 0.2447 - acc: 0.6968\n",
      "Epoch 79/300\n",
      "155/155 [==============================] - 0s 703us/step - loss: 0.2436 - acc: 0.6968\n",
      "Epoch 80/300\n",
      "155/155 [==============================] - 0s 966us/step - loss: 0.2431 - acc: 0.6968\n",
      "Epoch 81/300\n",
      "155/155 [==============================] - 0s 949us/step - loss: 0.2423 - acc: 0.6968\n",
      "Epoch 82/300\n",
      "155/155 [==============================] - 0s 686us/step - loss: 0.2416 - acc: 0.6968\n",
      "Epoch 83/300\n",
      "155/155 [==============================] - 0s 622us/step - loss: 0.2422 - acc: 0.6968\n",
      "Epoch 84/300\n",
      "155/155 [==============================] - 0s 643us/step - loss: 0.2406 - acc: 0.6968\n",
      "Epoch 85/300\n",
      "155/155 [==============================] - 0s 956us/step - loss: 0.2404 - acc: 0.6968\n",
      "Epoch 86/300\n",
      "155/155 [==============================] - 0s 667us/step - loss: 0.2401 - acc: 0.6968\n",
      "Epoch 87/300\n",
      "155/155 [==============================] - 0s 693us/step - loss: 0.2400 - acc: 0.6968\n",
      "Epoch 88/300\n",
      "155/155 [==============================] - 0s 681us/step - loss: 0.2381 - acc: 0.6968\n",
      "Epoch 89/300\n",
      "155/155 [==============================] - 0s 916us/step - loss: 0.2375 - acc: 0.6968\n",
      "Epoch 90/300\n",
      "155/155 [==============================] - 0s 658us/step - loss: 0.2390 - acc: 0.6968\n",
      "Epoch 91/300\n",
      "155/155 [==============================] - 0s 650us/step - loss: 0.2372 - acc: 0.6968\n",
      "Epoch 92/300\n",
      "155/155 [==============================] - 0s 669us/step - loss: 0.2370 - acc: 0.6968\n",
      "Epoch 93/300\n",
      "155/155 [==============================] - 0s 922us/step - loss: 0.2367 - acc: 0.6968\n",
      "Epoch 94/300\n",
      "155/155 [==============================] - 0s 640us/step - loss: 0.2366 - acc: 0.6968\n",
      "Epoch 95/300\n",
      "155/155 [==============================] - 0s 701us/step - loss: 0.2364 - acc: 0.6968\n",
      "Epoch 96/300\n",
      "155/155 [==============================] - 0s 670us/step - loss: 0.2365 - acc: 0.6968\n",
      "Epoch 97/300\n",
      "155/155 [==============================] - 0s 890us/step - loss: 0.2363 - acc: 0.6968\n",
      "Epoch 98/300\n",
      "155/155 [==============================] - 0s 664us/step - loss: 0.2335 - acc: 0.6968\n",
      "Epoch 99/300\n",
      "155/155 [==============================] - 0s 655us/step - loss: 0.2339 - acc: 0.6968\n",
      "Epoch 100/300\n",
      "155/155 [==============================] - 0s 636us/step - loss: 0.2337 - acc: 0.6968\n",
      "Epoch 101/300\n",
      "155/155 [==============================] - 0s 899us/step - loss: 0.2332 - acc: 0.6968\n",
      "Epoch 102/300\n",
      "155/155 [==============================] - 0s 695us/step - loss: 0.2342 - acc: 0.6968\n",
      "Epoch 103/300\n",
      "155/155 [==============================] - 0s 742us/step - loss: 0.2328 - acc: 0.6968\n",
      "Epoch 104/300\n",
      "155/155 [==============================] - 0s 684us/step - loss: 0.2329 - acc: 0.6968\n",
      "Epoch 105/300\n",
      "155/155 [==============================] - 0s 919us/step - loss: 0.2313 - acc: 0.6968\n",
      "Epoch 106/300\n",
      "155/155 [==============================] - 0s 692us/step - loss: 0.2286 - acc: 0.6968\n",
      "Epoch 107/300\n",
      "155/155 [==============================] - 0s 670us/step - loss: 0.2308 - acc: 0.6968\n",
      "Epoch 108/300\n",
      "155/155 [==============================] - 0s 652us/step - loss: 0.2317 - acc: 0.6968\n",
      "Epoch 109/300\n",
      "155/155 [==============================] - 0s 917us/step - loss: 0.2312 - acc: 0.6968\n",
      "Epoch 110/300\n",
      "155/155 [==============================] - 0s 648us/step - loss: 0.2301 - acc: 0.6968\n",
      "Epoch 111/300\n",
      "155/155 [==============================] - 0s 670us/step - loss: 0.2284 - acc: 0.6968\n",
      "Epoch 112/300\n",
      "155/155 [==============================] - 0s 660us/step - loss: 0.2307 - acc: 0.6968\n",
      "Epoch 113/300\n",
      "155/155 [==============================] - 0s 880us/step - loss: 0.2278 - acc: 0.6968\n",
      "Epoch 114/300\n",
      "155/155 [==============================] - 0s 645us/step - loss: 0.2280 - acc: 0.6968\n",
      "Epoch 115/300\n",
      "155/155 [==============================] - 0s 653us/step - loss: 0.2277 - acc: 0.6968\n",
      "Epoch 116/300\n",
      "155/155 [==============================] - 0s 656us/step - loss: 0.2263 - acc: 0.6968\n",
      "Epoch 117/300\n",
      "155/155 [==============================] - 0s 917us/step - loss: 0.2265 - acc: 0.6968\n",
      "Epoch 118/300\n",
      "155/155 [==============================] - 0s 636us/step - loss: 0.2265 - acc: 0.6968\n",
      "Epoch 119/300\n",
      "155/155 [==============================] - 0s 651us/step - loss: 0.2248 - acc: 0.6968\n",
      "Epoch 120/300\n",
      "155/155 [==============================] - 0s 668us/step - loss: 0.2252 - acc: 0.6968\n",
      "Epoch 121/300\n",
      "155/155 [==============================] - 0s 650us/step - loss: 0.2245 - acc: 0.6968\n",
      "Epoch 122/300\n",
      "155/155 [==============================] - 0s 926us/step - loss: 0.2240 - acc: 0.6968\n",
      "Epoch 123/300\n",
      "155/155 [==============================] - 0s 656us/step - loss: 0.2245 - acc: 0.6968\n",
      "Epoch 124/300\n",
      "155/155 [==============================] - 0s 679us/step - loss: 0.2251 - acc: 0.6968\n",
      "Epoch 125/300\n",
      "155/155 [==============================] - 0s 666us/step - loss: 0.2223 - acc: 0.6968\n",
      "Epoch 126/300\n",
      "155/155 [==============================] - 0s 898us/step - loss: 0.2238 - acc: 0.6968\n",
      "Epoch 127/300\n",
      "155/155 [==============================] - 0s 700us/step - loss: 0.2233 - acc: 0.6968\n",
      "Epoch 128/300\n",
      "155/155 [==============================] - 0s 699us/step - loss: 0.2233 - acc: 0.6968\n",
      "Epoch 129/300\n",
      "155/155 [==============================] - 0s 700us/step - loss: 0.2214 - acc: 0.6968\n",
      "Epoch 130/300\n",
      "155/155 [==============================] - 0s 964us/step - loss: 0.2227 - acc: 0.6968\n",
      "Epoch 131/300\n",
      "155/155 [==============================] - 0s 680us/step - loss: 0.2209 - acc: 0.6968\n",
      "Epoch 132/300\n",
      "155/155 [==============================] - 0s 675us/step - loss: 0.2232 - acc: 0.6968\n",
      "Epoch 133/300\n",
      "155/155 [==============================] - 0s 682us/step - loss: 0.2215 - acc: 0.6968\n",
      "Epoch 134/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2194 - acc: 0.6968\n",
      "Epoch 135/300\n",
      "155/155 [==============================] - 0s 683us/step - loss: 0.2195 - acc: 0.6968\n",
      "Epoch 136/300\n",
      "155/155 [==============================] - 0s 692us/step - loss: 0.2184 - acc: 0.6968\n",
      "Epoch 137/300\n",
      "155/155 [==============================] - 0s 969us/step - loss: 0.2176 - acc: 0.6968\n",
      "Epoch 138/300\n",
      "155/155 [==============================] - 0s 688us/step - loss: 0.2192 - acc: 0.6968\n",
      "Epoch 139/300\n",
      "155/155 [==============================] - 0s 693us/step - loss: 0.2167 - acc: 0.6968\n",
      "Epoch 140/300\n",
      "155/155 [==============================] - 0s 696us/step - loss: 0.2178 - acc: 0.6968\n",
      "Epoch 141/300\n",
      "155/155 [==============================] - 0s 936us/step - loss: 0.2168 - acc: 0.6968\n",
      "Epoch 142/300\n",
      "155/155 [==============================] - 0s 706us/step - loss: 0.2162 - acc: 0.6968\n",
      "Epoch 143/300\n",
      "155/155 [==============================] - 0s 692us/step - loss: 0.2158 - acc: 0.6968\n",
      "Epoch 144/300\n",
      "155/155 [==============================] - 0s 713us/step - loss: 0.2164 - acc: 0.6968\n",
      "Epoch 145/300\n",
      "155/155 [==============================] - 0s 949us/step - loss: 0.2174 - acc: 0.6968\n",
      "Epoch 146/300\n",
      "155/155 [==============================] - 0s 671us/step - loss: 0.2140 - acc: 0.6968\n",
      "Epoch 147/300\n",
      "155/155 [==============================] - 0s 704us/step - loss: 0.2146 - acc: 0.6968\n",
      "Epoch 148/300\n",
      "155/155 [==============================] - 0s 707us/step - loss: 0.2136 - acc: 0.6968\n",
      "Epoch 149/300\n",
      "155/155 [==============================] - 0s 932us/step - loss: 0.2140 - acc: 0.6968\n",
      "Epoch 150/300\n",
      "155/155 [==============================] - 0s 702us/step - loss: 0.2128 - acc: 0.6968\n",
      "Epoch 151/300\n",
      "155/155 [==============================] - 0s 703us/step - loss: 0.2124 - acc: 0.6968\n",
      "Epoch 152/300\n",
      "155/155 [==============================] - 0s 735us/step - loss: 0.2125 - acc: 0.6968\n",
      "Epoch 153/300\n",
      "155/155 [==============================] - 0s 916us/step - loss: 0.2128 - acc: 0.6968\n",
      "Epoch 154/300\n",
      "155/155 [==============================] - 0s 700us/step - loss: 0.2139 - acc: 0.6968\n",
      "Epoch 155/300\n",
      "155/155 [==============================] - 0s 692us/step - loss: 0.2113 - acc: 0.6968\n",
      "Epoch 156/300\n",
      "155/155 [==============================] - 0s 696us/step - loss: 0.2111 - acc: 0.6968\n",
      "Epoch 157/300\n",
      "155/155 [==============================] - 0s 973us/step - loss: 0.2107 - acc: 0.6968\n",
      "Epoch 158/300\n",
      "155/155 [==============================] - 0s 833us/step - loss: 0.2092 - acc: 0.6968\n",
      "Epoch 159/300\n",
      "155/155 [==============================] - 0s 891us/step - loss: 0.2095 - acc: 0.6968\n",
      "Epoch 160/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2124 - acc: 0.6968\n",
      "Epoch 161/300\n",
      "155/155 [==============================] - 0s 788us/step - loss: 0.2079 - acc: 0.6968\n",
      "Epoch 162/300\n",
      "155/155 [==============================] - 0s 728us/step - loss: 0.2092 - acc: 0.6968\n",
      "Epoch 163/300\n",
      "155/155 [==============================] - 0s 693us/step - loss: 0.2074 - acc: 0.6968\n",
      "Epoch 164/300\n",
      "155/155 [==============================] - 0s 948us/step - loss: 0.2072 - acc: 0.6968\n",
      "Epoch 165/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 0s 731us/step - loss: 0.2066 - acc: 0.6968\n",
      "Epoch 166/300\n",
      "155/155 [==============================] - 0s 729us/step - loss: 0.2072 - acc: 0.6968\n",
      "Epoch 167/300\n",
      "155/155 [==============================] - 0s 704us/step - loss: 0.2056 - acc: 0.6968\n",
      "Epoch 168/300\n",
      "155/155 [==============================] - 0s 989us/step - loss: 0.2047 - acc: 0.6968\n",
      "Epoch 169/300\n",
      "155/155 [==============================] - 0s 716us/step - loss: 0.2039 - acc: 0.6968\n",
      "Epoch 170/300\n",
      "155/155 [==============================] - 0s 725us/step - loss: 0.2043 - acc: 0.6968\n",
      "Epoch 171/300\n",
      "155/155 [==============================] - 0s 968us/step - loss: 0.2049 - acc: 0.6968\n",
      "Epoch 172/300\n",
      "155/155 [==============================] - 0s 734us/step - loss: 0.2044 - acc: 0.6968\n",
      "Epoch 173/300\n",
      "155/155 [==============================] - 0s 720us/step - loss: 0.2030 - acc: 0.6968\n",
      "Epoch 174/300\n",
      "155/155 [==============================] - 0s 768us/step - loss: 0.2023 - acc: 0.6968\n",
      "Epoch 175/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2011 - acc: 0.6968\n",
      "Epoch 176/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2030 - acc: 0.7032\n",
      "Epoch 177/300\n",
      "155/155 [==============================] - 0s 822us/step - loss: 0.2008 - acc: 0.6968\n",
      "Epoch 178/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2024 - acc: 0.6968\n",
      "Epoch 179/300\n",
      "155/155 [==============================] - 0s 763us/step - loss: 0.2002 - acc: 0.6968\n",
      "Epoch 180/300\n",
      "155/155 [==============================] - 0s 724us/step - loss: 0.1994 - acc: 0.6968\n",
      "Epoch 181/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1993 - acc: 0.6968\n",
      "Epoch 182/300\n",
      "155/155 [==============================] - 0s 715us/step - loss: 0.1988 - acc: 0.6968\n",
      "Epoch 183/300\n",
      "155/155 [==============================] - 0s 913us/step - loss: 0.1988 - acc: 0.6968\n",
      "Epoch 184/300\n",
      "155/155 [==============================] - 0s 869us/step - loss: 0.1976 - acc: 0.6968\n",
      "Epoch 185/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1970 - acc: 0.6968\n",
      "Epoch 186/300\n",
      "155/155 [==============================] - 0s 790us/step - loss: 0.1988 - acc: 0.6968\n",
      "Epoch 187/300\n",
      "155/155 [==============================] - 0s 849us/step - loss: 0.1974 - acc: 0.6968\n",
      "Epoch 188/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1982 - acc: 0.6968\n",
      "Epoch 189/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1947 - acc: 0.6903\n",
      "Epoch 190/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1953 - acc: 0.6968\n",
      "Epoch 191/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1951 - acc: 0.6968\n",
      "Epoch 192/300\n",
      "155/155 [==============================] - 0s 796us/step - loss: 0.1960 - acc: 0.6968\n",
      "Epoch 193/300\n",
      "155/155 [==============================] - 0s 819us/step - loss: 0.1949 - acc: 0.6903\n",
      "Epoch 194/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1961 - acc: 0.7032\n",
      "Epoch 195/300\n",
      "155/155 [==============================] - 0s 790us/step - loss: 0.1935 - acc: 0.6968\n",
      "Epoch 196/300\n",
      "155/155 [==============================] - 0s 781us/step - loss: 0.1938 - acc: 0.6968\n",
      "Epoch 197/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1922 - acc: 0.7032\n",
      "Epoch 198/300\n",
      "155/155 [==============================] - 0s 746us/step - loss: 0.1939 - acc: 0.6968\n",
      "Epoch 199/300\n",
      "155/155 [==============================] - 0s 763us/step - loss: 0.1930 - acc: 0.6968\n",
      "Epoch 200/300\n",
      "155/155 [==============================] - 0s 763us/step - loss: 0.1935 - acc: 0.6968\n",
      "Epoch 201/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1888 - acc: 0.6968\n",
      "Epoch 202/300\n",
      "155/155 [==============================] - 0s 770us/step - loss: 0.1914 - acc: 0.7032\n",
      "Epoch 203/300\n",
      "155/155 [==============================] - 0s 757us/step - loss: 0.1890 - acc: 0.6968\n",
      "Epoch 204/300\n",
      "155/155 [==============================] - 0s 685us/step - loss: 0.1919 - acc: 0.6968\n",
      "Epoch 205/300\n",
      "155/155 [==============================] - 0s 946us/step - loss: 0.1880 - acc: 0.6968\n",
      "Epoch 206/300\n",
      "155/155 [==============================] - 0s 708us/step - loss: 0.1897 - acc: 0.7032\n",
      "Epoch 207/300\n",
      "155/155 [==============================] - 0s 702us/step - loss: 0.1899 - acc: 0.6968\n",
      "Epoch 208/300\n",
      "155/155 [==============================] - 0s 968us/step - loss: 0.1895 - acc: 0.7097\n",
      "Epoch 209/300\n",
      "155/155 [==============================] - 0s 694us/step - loss: 0.1898 - acc: 0.6968\n",
      "Epoch 210/300\n",
      "155/155 [==============================] - 0s 716us/step - loss: 0.1857 - acc: 0.7032\n",
      "Epoch 211/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1860 - acc: 0.6968\n",
      "Epoch 212/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1877 - acc: 0.7032\n",
      "Epoch 213/300\n",
      "155/155 [==============================] - 0s 809us/step - loss: 0.1846 - acc: 0.6968\n",
      "Epoch 214/300\n",
      "155/155 [==============================] - 0s 773us/step - loss: 0.1893 - acc: 0.6968\n",
      "Epoch 215/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1852 - acc: 0.7032\n",
      "Epoch 216/300\n",
      "155/155 [==============================] - 0s 751us/step - loss: 0.1877 - acc: 0.7032\n",
      "Epoch 217/300\n",
      "155/155 [==============================] - 0s 739us/step - loss: 0.1835 - acc: 0.6968\n",
      "Epoch 218/300\n",
      "155/155 [==============================] - 0s 730us/step - loss: 0.1831 - acc: 0.7032\n",
      "Epoch 219/300\n",
      "155/155 [==============================] - 0s 962us/step - loss: 0.1863 - acc: 0.6968\n",
      "Epoch 220/300\n",
      "155/155 [==============================] - 0s 698us/step - loss: 0.1843 - acc: 0.7097\n",
      "Epoch 221/300\n",
      "155/155 [==============================] - 0s 705us/step - loss: 0.1833 - acc: 0.7097\n",
      "Epoch 222/300\n",
      "155/155 [==============================] - 0s 706us/step - loss: 0.1798 - acc: 0.6968\n",
      "Epoch 223/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1809 - acc: 0.7097\n",
      "Epoch 224/300\n",
      "155/155 [==============================] - 0s 726us/step - loss: 0.1818 - acc: 0.6968\n",
      "Epoch 225/300\n",
      "155/155 [==============================] - 0s 713us/step - loss: 0.1851 - acc: 0.6903\n",
      "Epoch 226/300\n",
      "155/155 [==============================] - 0s 995us/step - loss: 0.1806 - acc: 0.6968\n",
      "Epoch 227/300\n",
      "155/155 [==============================] - 0s 704us/step - loss: 0.1806 - acc: 0.7032\n",
      "Epoch 228/300\n",
      "155/155 [==============================] - 0s 766us/step - loss: 0.1786 - acc: 0.7032\n",
      "Epoch 229/300\n",
      "155/155 [==============================] - 0s 723us/step - loss: 0.1824 - acc: 0.7032\n",
      "Epoch 230/300\n",
      "155/155 [==============================] - 0s 995us/step - loss: 0.1829 - acc: 0.6968\n",
      "Epoch 231/300\n",
      "155/155 [==============================] - 0s 769us/step - loss: 0.1822 - acc: 0.7032\n",
      "Epoch 232/300\n",
      "155/155 [==============================] - 0s 768us/step - loss: 0.1814 - acc: 0.6968\n",
      "Epoch 233/300\n",
      "155/155 [==============================] - 0s 733us/step - loss: 0.1810 - acc: 0.6903\n",
      "Epoch 234/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1799 - acc: 0.6903\n",
      "Epoch 235/300\n",
      "155/155 [==============================] - 0s 725us/step - loss: 0.1780 - acc: 0.6968\n",
      "Epoch 236/300\n",
      "155/155 [==============================] - 0s 706us/step - loss: 0.1743 - acc: 0.7032\n",
      "Epoch 237/300\n",
      "155/155 [==============================] - 0s 969us/step - loss: 0.1761 - acc: 0.7032\n",
      "Epoch 238/300\n",
      "155/155 [==============================] - 0s 696us/step - loss: 0.1749 - acc: 0.6968\n",
      "Epoch 239/300\n",
      "155/155 [==============================] - 0s 731us/step - loss: 0.1761 - acc: 0.7161\n",
      "Epoch 240/300\n",
      "155/155 [==============================] - 0s 707us/step - loss: 0.1770 - acc: 0.7032\n",
      "Epoch 241/300\n",
      "155/155 [==============================] - 0s 972us/step - loss: 0.1755 - acc: 0.7097\n",
      "Epoch 242/300\n",
      "155/155 [==============================] - 0s 710us/step - loss: 0.1726 - acc: 0.7161\n",
      "Epoch 243/300\n",
      "155/155 [==============================] - 0s 771us/step - loss: 0.1747 - acc: 0.7032\n",
      "Epoch 244/300\n",
      "155/155 [==============================] - 0s 789us/step - loss: 0.1763 - acc: 0.6839\n",
      "Epoch 245/300\n",
      "155/155 [==============================] - 0s 989us/step - loss: 0.1722 - acc: 0.7032\n",
      "Epoch 246/300\n",
      "155/155 [==============================] - 0s 728us/step - loss: 0.1748 - acc: 0.6774\n",
      "Epoch 247/300\n",
      "155/155 [==============================] - 0s 737us/step - loss: 0.1766 - acc: 0.6903\n",
      "Epoch 248/300\n",
      "155/155 [==============================] - 0s 979us/step - loss: 0.1749 - acc: 0.6903\n",
      "Epoch 249/300\n",
      "155/155 [==============================] - 0s 681us/step - loss: 0.1714 - acc: 0.7226\n",
      "Epoch 250/300\n",
      "155/155 [==============================] - 0s 698us/step - loss: 0.1721 - acc: 0.6968\n",
      "Epoch 251/300\n",
      "155/155 [==============================] - 0s 689us/step - loss: 0.1705 - acc: 0.7097\n",
      "Epoch 252/300\n",
      "155/155 [==============================] - 0s 997us/step - loss: 0.1735 - acc: 0.7032\n",
      "Epoch 253/300\n",
      "155/155 [==============================] - 0s 752us/step - loss: 0.1712 - acc: 0.7097\n",
      "Epoch 254/300\n",
      "155/155 [==============================] - 0s 740us/step - loss: 0.1730 - acc: 0.7226\n",
      "Epoch 255/300\n",
      "155/155 [==============================] - 0s 718us/step - loss: 0.1703 - acc: 0.6903\n",
      "Epoch 256/300\n",
      "155/155 [==============================] - 0s 962us/step - loss: 0.1703 - acc: 0.7097\n",
      "Epoch 257/300\n",
      "155/155 [==============================] - 0s 774us/step - loss: 0.1711 - acc: 0.7161\n",
      "Epoch 258/300\n",
      "155/155 [==============================] - 0s 696us/step - loss: 0.1695 - acc: 0.6968\n",
      "Epoch 259/300\n",
      "155/155 [==============================] - 0s 694us/step - loss: 0.1676 - acc: 0.7032\n",
      "Epoch 260/300\n",
      "155/155 [==============================] - 0s 959us/step - loss: 0.1731 - acc: 0.6903\n",
      "Epoch 261/300\n",
      "155/155 [==============================] - 0s 725us/step - loss: 0.1705 - acc: 0.7032\n",
      "Epoch 262/300\n",
      "155/155 [==============================] - 0s 756us/step - loss: 0.1686 - acc: 0.6903\n",
      "Epoch 263/300\n",
      "155/155 [==============================] - 0s 703us/step - loss: 0.1637 - acc: 0.7226\n",
      "Epoch 264/300\n",
      "155/155 [==============================] - 0s 926us/step - loss: 0.1694 - acc: 0.6968\n",
      "Epoch 265/300\n",
      "155/155 [==============================] - 0s 722us/step - loss: 0.1653 - acc: 0.7161\n",
      "Epoch 266/300\n",
      "155/155 [==============================] - 0s 726us/step - loss: 0.1654 - acc: 0.7097\n",
      "Epoch 267/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1668 - acc: 0.6968\n",
      "Epoch 268/300\n",
      "155/155 [==============================] - 0s 758us/step - loss: 0.1628 - acc: 0.7226\n",
      "Epoch 269/300\n",
      "155/155 [==============================] - 0s 722us/step - loss: 0.1659 - acc: 0.7097\n",
      "Epoch 270/300\n",
      "155/155 [==============================] - 0s 713us/step - loss: 0.1667 - acc: 0.7032\n",
      "Epoch 271/300\n",
      "155/155 [==============================] - 0s 955us/step - loss: 0.1661 - acc: 0.7161\n",
      "Epoch 272/300\n",
      "155/155 [==============================] - 0s 705us/step - loss: 0.1669 - acc: 0.7097\n",
      "Epoch 273/300\n",
      "155/155 [==============================] - 0s 704us/step - loss: 0.1658 - acc: 0.7161\n",
      "Epoch 274/300\n",
      "155/155 [==============================] - 0s 802us/step - loss: 0.1626 - acc: 0.7226\n",
      "Epoch 275/300\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1642 - acc: 0.7097\n",
      "Epoch 276/300\n",
      "155/155 [==============================] - 0s 727us/step - loss: 0.1665 - acc: 0.6968\n",
      "Epoch 277/300\n",
      "155/155 [==============================] - 0s 742us/step - loss: 0.1608 - acc: 0.7355\n",
      "Epoch 278/300\n",
      "155/155 [==============================] - 0s 694us/step - loss: 0.1652 - acc: 0.7032\n",
      "Epoch 279/300\n",
      "155/155 [==============================] - 0s 929us/step - loss: 0.1624 - acc: 0.7226\n",
      "Epoch 280/300\n",
      "155/155 [==============================] - 0s 693us/step - loss: 0.1658 - acc: 0.7032\n",
      "Epoch 281/300\n",
      "155/155 [==============================] - 0s 755us/step - loss: 0.1619 - acc: 0.7161\n",
      "Epoch 282/300\n",
      "155/155 [==============================] - 0s 974us/step - loss: 0.1649 - acc: 0.7097\n",
      "Epoch 283/300\n",
      "155/155 [==============================] - 0s 699us/step - loss: 0.1637 - acc: 0.7226\n",
      "Epoch 284/300\n",
      "155/155 [==============================] - 0s 718us/step - loss: 0.1622 - acc: 0.7161\n",
      "Epoch 285/300\n",
      "155/155 [==============================] - 0s 697us/step - loss: 0.1608 - acc: 0.7355\n",
      "Epoch 286/300\n",
      "155/155 [==============================] - 0s 997us/step - loss: 0.1634 - acc: 0.7290\n",
      "Epoch 287/300\n",
      "155/155 [==============================] - 0s 754us/step - loss: 0.1597 - acc: 0.7226\n",
      "Epoch 288/300\n",
      "155/155 [==============================] - 0s 763us/step - loss: 0.1589 - acc: 0.7226\n",
      "Epoch 289/300\n",
      "155/155 [==============================] - 0s 769us/step - loss: 0.1612 - acc: 0.7355\n",
      "Epoch 290/300\n",
      "155/155 [==============================] - 0s 992us/step - loss: 0.1598 - acc: 0.7226\n",
      "Epoch 291/300\n",
      "155/155 [==============================] - 0s 702us/step - loss: 0.1627 - acc: 0.7032\n",
      "Epoch 292/300\n",
      "155/155 [==============================] - 0s 705us/step - loss: 0.1578 - acc: 0.7290\n",
      "Epoch 293/300\n",
      "155/155 [==============================] - 0s 715us/step - loss: 0.1631 - acc: 0.7226\n",
      "Epoch 294/300\n",
      "155/155 [==============================] - 0s 910us/step - loss: 0.1561 - acc: 0.7484\n",
      "Epoch 295/300\n",
      "155/155 [==============================] - 0s 704us/step - loss: 0.1578 - acc: 0.7355\n",
      "Epoch 296/300\n",
      "155/155 [==============================] - 0s 711us/step - loss: 0.1618 - acc: 0.7290\n",
      "Epoch 297/300\n",
      "155/155 [==============================] - 0s 998us/step - loss: 0.1539 - acc: 0.7419\n",
      "Epoch 298/300\n",
      "155/155 [==============================] - 0s 737us/step - loss: 0.1561 - acc: 0.7290\n",
      "Epoch 299/300\n",
      "155/155 [==============================] - 0s 717us/step - loss: 0.1578 - acc: 0.7290\n",
      "Epoch 300/300\n",
      "155/155 [==============================] - 0s 713us/step - loss: 0.1545 - acc: 0.6968\n",
      "155/155 [==============================] - 1s 6ms/step\n",
      "[0.15068099767931045, 0.7548387054474123]\n",
      "39/39 [==============================] - 0s 134us/step\n",
      "[0.15361733581775275, 0.7692307707590934]\n"
     ]
    }
   ],
   "source": [
    "#Greatly larger number of epochs, smaller batch size\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(25, activation = 'relu', kernel_initializer='normal',input_shape = (6,)))\n",
    "model.add(layers.Dense(50, kernel_regularizer= regularizers.l2(0.005),activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(50,activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(100, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(100, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(150, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(150, activation = 'relu'))\n",
    "model.add(layers.Dense(4, activation = 'linear'))\n",
    "\n",
    "model.compile(optimizer = 'sgd', loss = 'mse', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 10, epochs = 300)\n",
    "\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "results_train = model.evaluate(X_train, y_train)\n",
    "print(results_train)\n",
    "\n",
    "results_test = model.evaluate(X_test, y_test)\n",
    "print(results_test)\n",
    "\n",
    "#Training accuracy went up but testing accuracy went down\n",
    "#Try again with fewer epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/225\n",
      "155/155 [==============================] - 4s 23ms/step - loss: 0.3885 - acc: 0.6129\n",
      "Epoch 2/225\n",
      "155/155 [==============================] - 0s 791us/step - loss: 0.3582 - acc: 0.6968\n",
      "Epoch 3/225\n",
      "155/155 [==============================] - 0s 782us/step - loss: 0.3338 - acc: 0.6968\n",
      "Epoch 4/225\n",
      "155/155 [==============================] - 0s 788us/step - loss: 0.3156 - acc: 0.6968\n",
      "Epoch 5/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.3041 - acc: 0.6968\n",
      "Epoch 6/225\n",
      "155/155 [==============================] - 0s 784us/step - loss: 0.2945 - acc: 0.6968\n",
      "Epoch 7/225\n",
      "155/155 [==============================] - 0s 777us/step - loss: 0.2875 - acc: 0.6968\n",
      "Epoch 8/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2844 - acc: 0.6968\n",
      "Epoch 9/225\n",
      "155/155 [==============================] - 0s 785us/step - loss: 0.2805 - acc: 0.6968\n",
      "Epoch 10/225\n",
      "155/155 [==============================] - 0s 791us/step - loss: 0.2778 - acc: 0.6968\n",
      "Epoch 11/225\n",
      "155/155 [==============================] - 0s 789us/step - loss: 0.2759 - acc: 0.6968\n",
      "Epoch 12/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2754 - acc: 0.6968\n",
      "Epoch 13/225\n",
      "155/155 [==============================] - 0s 777us/step - loss: 0.2752 - acc: 0.6968\n",
      "Epoch 14/225\n",
      "155/155 [==============================] - 0s 775us/step - loss: 0.2744 - acc: 0.6968\n",
      "Epoch 15/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2725 - acc: 0.6968\n",
      "Epoch 16/225\n",
      "155/155 [==============================] - 0s 777us/step - loss: 0.2738 - acc: 0.6968\n",
      "Epoch 17/225\n",
      "155/155 [==============================] - 0s 782us/step - loss: 0.2730 - acc: 0.6968\n",
      "Epoch 18/225\n",
      "155/155 [==============================] - 0s 794us/step - loss: 0.2712 - acc: 0.6968\n",
      "Epoch 19/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2722 - acc: 0.6968\n",
      "Epoch 20/225\n",
      "155/155 [==============================] - 0s 777us/step - loss: 0.2712 - acc: 0.6968\n",
      "Epoch 21/225\n",
      "155/155 [==============================] - 0s 775us/step - loss: 0.2703 - acc: 0.6968\n",
      "Epoch 22/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2698 - acc: 0.6968\n",
      "Epoch 23/225\n",
      "155/155 [==============================] - 0s 779us/step - loss: 0.2700 - acc: 0.6968\n",
      "Epoch 24/225\n",
      "155/155 [==============================] - 0s 785us/step - loss: 0.2691 - acc: 0.6968\n",
      "Epoch 25/225\n",
      "155/155 [==============================] - 0s 789us/step - loss: 0.2687 - acc: 0.6968\n",
      "Epoch 26/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2674 - acc: 0.6968\n",
      "Epoch 27/225\n",
      "155/155 [==============================] - 0s 780us/step - loss: 0.2668 - acc: 0.6968\n",
      "Epoch 28/225\n",
      "155/155 [==============================] - 0s 799us/step - loss: 0.2657 - acc: 0.6968\n",
      "Epoch 29/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2658 - acc: 0.6968\n",
      "Epoch 30/225\n",
      "155/155 [==============================] - 0s 794us/step - loss: 0.2655 - acc: 0.6968\n",
      "Epoch 31/225\n",
      "155/155 [==============================] - 0s 787us/step - loss: 0.2647 - acc: 0.6968\n",
      "Epoch 32/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2641 - acc: 0.6968\n",
      "Epoch 33/225\n",
      "155/155 [==============================] - 0s 794us/step - loss: 0.2648 - acc: 0.6968\n",
      "Epoch 34/225\n",
      "155/155 [==============================] - 0s 793us/step - loss: 0.2640 - acc: 0.6968\n",
      "Epoch 35/225\n",
      "155/155 [==============================] - 0s 804us/step - loss: 0.2636 - acc: 0.6968\n",
      "Epoch 36/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2628 - acc: 0.6968\n",
      "Epoch 37/225\n",
      "155/155 [==============================] - 0s 803us/step - loss: 0.2613 - acc: 0.6968\n",
      "Epoch 38/225\n",
      "155/155 [==============================] - 0s 815us/step - loss: 0.2607 - acc: 0.6968\n",
      "Epoch 39/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2619 - acc: 0.6968\n",
      "Epoch 40/225\n",
      "155/155 [==============================] - 0s 827us/step - loss: 0.2610 - acc: 0.6968\n",
      "Epoch 41/225\n",
      "155/155 [==============================] - 0s 806us/step - loss: 0.2607 - acc: 0.6968\n",
      "Epoch 42/225\n",
      "155/155 [==============================] - 0s 800us/step - loss: 0.2591 - acc: 0.6968\n",
      "Epoch 43/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2602 - acc: 0.6968\n",
      "Epoch 44/225\n",
      "155/155 [==============================] - 0s 832us/step - loss: 0.2594 - acc: 0.6968\n",
      "Epoch 45/225\n",
      "155/155 [==============================] - 0s 797us/step - loss: 0.2585 - acc: 0.6968\n",
      "Epoch 46/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2575 - acc: 0.6968\n",
      "Epoch 47/225\n",
      "155/155 [==============================] - 0s 810us/step - loss: 0.2572 - acc: 0.6968\n",
      "Epoch 48/225\n",
      "155/155 [==============================] - 0s 826us/step - loss: 0.2571 - acc: 0.6968\n",
      "Epoch 49/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2548 - acc: 0.6968\n",
      "Epoch 50/225\n",
      "155/155 [==============================] - 0s 837us/step - loss: 0.2556 - acc: 0.6968\n",
      "Epoch 51/225\n",
      "155/155 [==============================] - 0s 823us/step - loss: 0.2569 - acc: 0.6968\n",
      "Epoch 52/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2553 - acc: 0.6968\n",
      "Epoch 53/225\n",
      "155/155 [==============================] - 0s 854us/step - loss: 0.2547 - acc: 0.6968\n",
      "Epoch 54/225\n",
      "155/155 [==============================] - 0s 823us/step - loss: 0.2547 - acc: 0.6968\n",
      "Epoch 55/225\n",
      "155/155 [==============================] - 0s 824us/step - loss: 0.2530 - acc: 0.6968\n",
      "Epoch 56/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2531 - acc: 0.6968\n",
      "Epoch 57/225\n",
      "155/155 [==============================] - 0s 855us/step - loss: 0.2524 - acc: 0.6968\n",
      "Epoch 58/225\n",
      "155/155 [==============================] - 0s 875us/step - loss: 0.2519 - acc: 0.6968\n",
      "Epoch 59/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2507 - acc: 0.6968\n",
      "Epoch 60/225\n",
      "155/155 [==============================] - 0s 855us/step - loss: 0.2515 - acc: 0.6968\n",
      "Epoch 61/225\n",
      "155/155 [==============================] - 0s 851us/step - loss: 0.2514 - acc: 0.6968\n",
      "Epoch 62/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2513 - acc: 0.6968\n",
      "Epoch 63/225\n",
      "155/155 [==============================] - 0s 823us/step - loss: 0.2501 - acc: 0.6968\n",
      "Epoch 64/225\n",
      "155/155 [==============================] - 0s 838us/step - loss: 0.2491 - acc: 0.6968\n",
      "Epoch 65/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2493 - acc: 0.6968\n",
      "Epoch 66/225\n",
      "155/155 [==============================] - 0s 838us/step - loss: 0.2495 - acc: 0.6968\n",
      "Epoch 67/225\n",
      "155/155 [==============================] - 0s 843us/step - loss: 0.2476 - acc: 0.6968\n",
      "Epoch 68/225\n",
      "155/155 [==============================] - 0s 854us/step - loss: 0.2467 - acc: 0.6968\n",
      "Epoch 69/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2472 - acc: 0.6968\n",
      "Epoch 70/225\n",
      "155/155 [==============================] - 0s 846us/step - loss: 0.2471 - acc: 0.6968\n",
      "Epoch 71/225\n",
      "155/155 [==============================] - 0s 838us/step - loss: 0.2464 - acc: 0.6968\n",
      "Epoch 72/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2475 - acc: 0.6968\n",
      "Epoch 73/225\n",
      "155/155 [==============================] - 0s 843us/step - loss: 0.2459 - acc: 0.6968\n",
      "Epoch 74/225\n",
      "155/155 [==============================] - 0s 835us/step - loss: 0.2456 - acc: 0.6968\n",
      "Epoch 75/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2439 - acc: 0.6968\n",
      "Epoch 76/225\n",
      "155/155 [==============================] - 0s 848us/step - loss: 0.2442 - acc: 0.6968\n",
      "Epoch 77/225\n",
      "155/155 [==============================] - 0s 860us/step - loss: 0.2437 - acc: 0.6968\n",
      "Epoch 78/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2417 - acc: 0.6968\n",
      "Epoch 79/225\n",
      "155/155 [==============================] - 0s 827us/step - loss: 0.2421 - acc: 0.6968\n",
      "Epoch 80/225\n",
      "155/155 [==============================] - 0s 833us/step - loss: 0.2411 - acc: 0.6968\n",
      "Epoch 81/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2412 - acc: 0.6968\n",
      "Epoch 82/225\n",
      "155/155 [==============================] - 0s 837us/step - loss: 0.2408 - acc: 0.6968\n",
      "Epoch 83/225\n",
      "155/155 [==============================] - 0s 847us/step - loss: 0.2412 - acc: 0.6968\n",
      "Epoch 84/225\n",
      "155/155 [==============================] - 0s 848us/step - loss: 0.2415 - acc: 0.6968\n",
      "Epoch 85/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.6968\n",
      "Epoch 86/225\n",
      "155/155 [==============================] - 0s 845us/step - loss: 0.2387 - acc: 0.6968\n",
      "Epoch 87/225\n",
      "155/155 [==============================] - 0s 845us/step - loss: 0.2391 - acc: 0.6968\n",
      "Epoch 88/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2381 - acc: 0.6968\n",
      "Epoch 89/225\n",
      "155/155 [==============================] - 0s 848us/step - loss: 0.2360 - acc: 0.6968\n",
      "Epoch 90/225\n",
      "155/155 [==============================] - 0s 852us/step - loss: 0.2381 - acc: 0.6968\n",
      "Epoch 91/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2371 - acc: 0.6968\n",
      "Epoch 92/225\n",
      "155/155 [==============================] - 0s 837us/step - loss: 0.2366 - acc: 0.6968\n",
      "Epoch 93/225\n",
      "155/155 [==============================] - 0s 864us/step - loss: 0.2361 - acc: 0.6968\n",
      "Epoch 94/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2363 - acc: 0.6968\n",
      "Epoch 95/225\n",
      "155/155 [==============================] - 0s 850us/step - loss: 0.2347 - acc: 0.6968\n",
      "Epoch 96/225\n",
      "155/155 [==============================] - 0s 841us/step - loss: 0.2350 - acc: 0.6968\n",
      "Epoch 97/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2339 - acc: 0.6968\n",
      "Epoch 98/225\n",
      "155/155 [==============================] - 0s 855us/step - loss: 0.2344 - acc: 0.6968\n",
      "Epoch 99/225\n",
      "155/155 [==============================] - 0s 865us/step - loss: 0.2341 - acc: 0.6968\n",
      "Epoch 100/225\n",
      "155/155 [==============================] - 0s 852us/step - loss: 0.2332 - acc: 0.6968\n",
      "Epoch 101/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2323 - acc: 0.6968\n",
      "Epoch 102/225\n",
      "155/155 [==============================] - 0s 867us/step - loss: 0.2320 - acc: 0.6968\n",
      "Epoch 103/225\n",
      "155/155 [==============================] - 0s 881us/step - loss: 0.2316 - acc: 0.6968\n",
      "Epoch 104/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2300 - acc: 0.6968\n",
      "Epoch 105/225\n",
      "155/155 [==============================] - 0s 869us/step - loss: 0.2288 - acc: 0.6968\n",
      "Epoch 106/225\n",
      "155/155 [==============================] - 0s 853us/step - loss: 0.2306 - acc: 0.6968\n",
      "Epoch 107/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2294 - acc: 0.6968\n",
      "Epoch 108/225\n",
      "155/155 [==============================] - 0s 865us/step - loss: 0.2307 - acc: 0.6968\n",
      "Epoch 109/225\n",
      "155/155 [==============================] - 0s 872us/step - loss: 0.2276 - acc: 0.6968\n",
      "Epoch 110/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2287 - acc: 0.6968\n",
      "Epoch 111/225\n",
      "155/155 [==============================] - 0s 870us/step - loss: 0.2275 - acc: 0.6968\n",
      "Epoch 112/225\n",
      "155/155 [==============================] - 0s 874us/step - loss: 0.2266 - acc: 0.6968\n",
      "Epoch 113/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2271 - acc: 0.6968\n",
      "Epoch 114/225\n",
      "155/155 [==============================] - 0s 844us/step - loss: 0.2258 - acc: 0.6968\n",
      "Epoch 115/225\n",
      "155/155 [==============================] - 0s 885us/step - loss: 0.2267 - acc: 0.6968\n",
      "Epoch 116/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2269 - acc: 0.6968\n",
      "Epoch 117/225\n",
      "155/155 [==============================] - 0s 875us/step - loss: 0.2266 - acc: 0.6968\n",
      "Epoch 118/225\n",
      "155/155 [==============================] - 0s 931us/step - loss: 0.2260 - acc: 0.6968\n",
      "Epoch 119/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2247 - acc: 0.6968\n",
      "Epoch 120/225\n",
      "155/155 [==============================] - 0s 892us/step - loss: 0.2236 - acc: 0.6968\n",
      "Epoch 121/225\n",
      "155/155 [==============================] - 0s 891us/step - loss: 0.2229 - acc: 0.6968\n",
      "Epoch 122/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2227 - acc: 0.6968\n",
      "Epoch 123/225\n",
      "155/155 [==============================] - 0s 917us/step - loss: 0.2236 - acc: 0.6968\n",
      "Epoch 124/225\n",
      "155/155 [==============================] - 0s 901us/step - loss: 0.2222 - acc: 0.6968\n",
      "Epoch 125/225\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.2205 - acc: 0.6968\n",
      "Epoch 126/225\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.2218 - acc: 0.6968\n",
      "Epoch 127/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2199 - acc: 0.6968\n",
      "Epoch 128/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2191 - acc: 0.6968\n",
      "Epoch 129/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2211 - acc: 0.6968\n",
      "Epoch 130/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2203 - acc: 0.6968\n",
      "Epoch 131/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2178 - acc: 0.6968\n",
      "Epoch 132/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2177 - acc: 0.6968\n",
      "Epoch 133/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2177 - acc: 0.6968\n",
      "Epoch 134/225\n",
      "155/155 [==============================] - 0s 890us/step - loss: 0.2169 - acc: 0.6968\n",
      "Epoch 135/225\n",
      "155/155 [==============================] - 0s 895us/step - loss: 0.2162 - acc: 0.6968\n",
      "Epoch 136/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2161 - acc: 0.6968\n",
      "Epoch 137/225\n",
      "155/155 [==============================] - 0s 923us/step - loss: 0.2163 - acc: 0.6968\n",
      "Epoch 138/225\n",
      "155/155 [==============================] - 0s 860us/step - loss: 0.2135 - acc: 0.6968\n",
      "Epoch 139/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2141 - acc: 0.6968\n",
      "Epoch 140/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2148 - acc: 0.6968\n",
      "Epoch 141/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2134 - acc: 0.6968\n",
      "Epoch 142/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2135 - acc: 0.6968\n",
      "Epoch 143/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2138 - acc: 0.6968\n",
      "Epoch 144/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2107 - acc: 0.6968\n",
      "Epoch 145/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2113 - acc: 0.6968\n",
      "Epoch 146/225\n",
      "155/155 [==============================] - 0s 941us/step - loss: 0.2104 - acc: 0.6968\n",
      "Epoch 147/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2103 - acc: 0.6968\n",
      "Epoch 148/225\n",
      "155/155 [==============================] - 0s 910us/step - loss: 0.2107 - acc: 0.6968\n",
      "Epoch 149/225\n",
      "155/155 [==============================] - 0s 938us/step - loss: 0.2095 - acc: 0.6968\n",
      "Epoch 150/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2086 - acc: 0.6968\n",
      "Epoch 151/225\n",
      "155/155 [==============================] - 0s 931us/step - loss: 0.2079 - acc: 0.6968\n",
      "Epoch 152/225\n",
      "155/155 [==============================] - 0s 900us/step - loss: 0.2084 - acc: 0.6968\n",
      "Epoch 153/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2062 - acc: 0.6968\n",
      "Epoch 154/225\n",
      "155/155 [==============================] - 0s 885us/step - loss: 0.2081 - acc: 0.6968\n",
      "Epoch 155/225\n",
      "155/155 [==============================] - 0s 902us/step - loss: 0.2076 - acc: 0.6968\n",
      "Epoch 156/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2067 - acc: 0.6968\n",
      "Epoch 157/225\n",
      "155/155 [==============================] - 0s 906us/step - loss: 0.2068 - acc: 0.6968\n",
      "Epoch 158/225\n",
      "155/155 [==============================] - 0s 899us/step - loss: 0.2043 - acc: 0.6968\n",
      "Epoch 159/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2041 - acc: 0.6968\n",
      "Epoch 160/225\n",
      "155/155 [==============================] - 0s 893us/step - loss: 0.2048 - acc: 0.6968\n",
      "Epoch 161/225\n",
      "155/155 [==============================] - 0s 897us/step - loss: 0.2047 - acc: 0.6968\n",
      "Epoch 162/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2031 - acc: 0.6968\n",
      "Epoch 163/225\n",
      "155/155 [==============================] - 0s 975us/step - loss: 0.2035 - acc: 0.6968\n",
      "Epoch 164/225\n",
      "155/155 [==============================] - 0s 900us/step - loss: 0.2043 - acc: 0.6968\n",
      "Epoch 165/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2014 - acc: 0.6968\n",
      "Epoch 166/225\n",
      "155/155 [==============================] - 0s 886us/step - loss: 0.2016 - acc: 0.6968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/225\n",
      "155/155 [==============================] - 0s 898us/step - loss: 0.1998 - acc: 0.6968\n",
      "Epoch 168/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2012 - acc: 0.6968\n",
      "Epoch 169/225\n",
      "155/155 [==============================] - 0s 889us/step - loss: 0.2005 - acc: 0.6968\n",
      "Epoch 170/225\n",
      "155/155 [==============================] - 0s 897us/step - loss: 0.2010 - acc: 0.6968\n",
      "Epoch 171/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2014 - acc: 0.6968\n",
      "Epoch 172/225\n",
      "155/155 [==============================] - 0s 885us/step - loss: 0.1994 - acc: 0.6968\n",
      "Epoch 173/225\n",
      "155/155 [==============================] - 0s 898us/step - loss: 0.1939 - acc: 0.6968\n",
      "Epoch 174/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1984 - acc: 0.6968\n",
      "Epoch 175/225\n",
      "155/155 [==============================] - 0s 884us/step - loss: 0.1982 - acc: 0.6968\n",
      "Epoch 176/225\n",
      "155/155 [==============================] - 0s 924us/step - loss: 0.1976 - acc: 0.6968\n",
      "Epoch 177/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1975 - acc: 0.6968\n",
      "Epoch 178/225\n",
      "155/155 [==============================] - 0s 861us/step - loss: 0.1947 - acc: 0.6968\n",
      "Epoch 179/225\n",
      "155/155 [==============================] - 0s 880us/step - loss: 0.1976 - acc: 0.6968\n",
      "Epoch 180/225\n",
      "155/155 [==============================] - 0s 884us/step - loss: 0.1924 - acc: 0.6968\n",
      "Epoch 181/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1924 - acc: 0.6968\n",
      "Epoch 182/225\n",
      "155/155 [==============================] - 0s 887us/step - loss: 0.1920 - acc: 0.6968\n",
      "Epoch 183/225\n",
      "155/155 [==============================] - 0s 881us/step - loss: 0.1917 - acc: 0.6968\n",
      "Epoch 184/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1900 - acc: 0.6968\n",
      "Epoch 185/225\n",
      "155/155 [==============================] - 0s 942us/step - loss: 0.1916 - acc: 0.6968\n",
      "Epoch 186/225\n",
      "155/155 [==============================] - 0s 902us/step - loss: 0.1903 - acc: 0.6968\n",
      "Epoch 187/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1922 - acc: 0.6968\n",
      "Epoch 188/225\n",
      "155/155 [==============================] - 0s 885us/step - loss: 0.1877 - acc: 0.6968\n",
      "Epoch 189/225\n",
      "155/155 [==============================] - 0s 958us/step - loss: 0.1902 - acc: 0.6968\n",
      "Epoch 190/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1926 - acc: 0.6968\n",
      "Epoch 191/225\n",
      "155/155 [==============================] - 0s 874us/step - loss: 0.1893 - acc: 0.6968\n",
      "Epoch 192/225\n",
      "155/155 [==============================] - 0s 916us/step - loss: 0.1882 - acc: 0.6903\n",
      "Epoch 193/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1903 - acc: 0.6968\n",
      "Epoch 194/225\n",
      "155/155 [==============================] - 0s 893us/step - loss: 0.1886 - acc: 0.6968\n",
      "Epoch 195/225\n",
      "155/155 [==============================] - 0s 877us/step - loss: 0.1898 - acc: 0.7032\n",
      "Epoch 196/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1870 - acc: 0.6968\n",
      "Epoch 197/225\n",
      "155/155 [==============================] - 0s 882us/step - loss: 0.1842 - acc: 0.6968\n",
      "Epoch 198/225\n",
      "155/155 [==============================] - 0s 889us/step - loss: 0.1852 - acc: 0.6968\n",
      "Epoch 199/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1869 - acc: 0.7097\n",
      "Epoch 200/225\n",
      "155/155 [==============================] - 0s 906us/step - loss: 0.1837 - acc: 0.6968\n",
      "Epoch 201/225\n",
      "155/155 [==============================] - 0s 903us/step - loss: 0.1834 - acc: 0.6968\n",
      "Epoch 202/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1835 - acc: 0.7097\n",
      "Epoch 203/225\n",
      "155/155 [==============================] - 0s 889us/step - loss: 0.1827 - acc: 0.7032\n",
      "Epoch 204/225\n",
      "155/155 [==============================] - 0s 891us/step - loss: 0.1849 - acc: 0.7032\n",
      "Epoch 205/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1831 - acc: 0.6903\n",
      "Epoch 206/225\n",
      "155/155 [==============================] - 0s 885us/step - loss: 0.1799 - acc: 0.6968\n",
      "Epoch 207/225\n",
      "155/155 [==============================] - 0s 892us/step - loss: 0.1795 - acc: 0.7032\n",
      "Epoch 208/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1822 - acc: 0.6903\n",
      "Epoch 209/225\n",
      "155/155 [==============================] - 0s 885us/step - loss: 0.1833 - acc: 0.6903\n",
      "Epoch 210/225\n",
      "155/155 [==============================] - 0s 885us/step - loss: 0.1849 - acc: 0.6839\n",
      "Epoch 211/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1807 - acc: 0.7032\n",
      "Epoch 212/225\n",
      "155/155 [==============================] - 0s 888us/step - loss: 0.1786 - acc: 0.7161\n",
      "Epoch 213/225\n",
      "155/155 [==============================] - 0s 885us/step - loss: 0.1802 - acc: 0.7161\n",
      "Epoch 214/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1764 - acc: 0.7032\n",
      "Epoch 215/225\n",
      "155/155 [==============================] - 0s 887us/step - loss: 0.1781 - acc: 0.7226\n",
      "Epoch 216/225\n",
      "155/155 [==============================] - 0s 902us/step - loss: 0.1772 - acc: 0.7226\n",
      "Epoch 217/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1766 - acc: 0.6968\n",
      "Epoch 218/225\n",
      "155/155 [==============================] - 0s 899us/step - loss: 0.1779 - acc: 0.7097\n",
      "Epoch 219/225\n",
      "155/155 [==============================] - 0s 883us/step - loss: 0.1781 - acc: 0.7032\n",
      "Epoch 220/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1777 - acc: 0.7226\n",
      "Epoch 221/225\n",
      "155/155 [==============================] - 0s 889us/step - loss: 0.1748 - acc: 0.7161\n",
      "Epoch 222/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1748 - acc: 0.7097\n",
      "Epoch 223/225\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1783 - acc: 0.6903\n",
      "Epoch 224/225\n",
      "155/155 [==============================] - 0s 915us/step - loss: 0.1745 - acc: 0.7226\n",
      "Epoch 225/225\n",
      "155/155 [==============================] - 0s 887us/step - loss: 0.1752 - acc: 0.7226\n",
      "155/155 [==============================] - 1s 8ms/step\n",
      "[0.16872756702284658, 0.7419354796409607]\n",
      "39/39 [==============================] - 0s 170us/step\n",
      "[0.17031877774458665, 0.7692307707590934]\n"
     ]
    }
   ],
   "source": [
    "#Greatly larger number of epochs, smaller batch size\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(25, activation = 'relu', kernel_initializer='normal',input_shape = (6,)))\n",
    "model.add(layers.Dense(50, kernel_regularizer= regularizers.l2(0.005),activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(100,activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(150, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(200, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(250, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(300, activation = 'relu'))\n",
    "model.add(layers.Dense(4, activation = 'linear'))\n",
    "\n",
    "model.compile(optimizer = 'sgd', loss = 'mse', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 10, epochs = 225)\n",
    "\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "results_train = model.evaluate(X_train, y_train)\n",
    "print(results_train)\n",
    "\n",
    "results_test = model.evaluate(X_test, y_test)\n",
    "print(results_test)\n",
    "\n",
    "#Training accuracy went up but testing accuracy went down\n",
    "#Try again with fewer epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot loss\n",
    "\n",
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "\n",
    "loss_list = history_dict['loss']\n",
    "epochs = range(1,len(loss_list)+1)\n",
    "\n",
    "plt.plot(epochs, loss_list, label = 'Training Loss')\n",
    "\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot accuracy\n",
    "\n",
    "accuracy_list = history_dict['acc']\n",
    "epochs = range(1,len(loss_list)+1)\n",
    "\n",
    "plt.plot(epochs, accuracy_list, label = 'Training Accuracy')\n",
    "\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.21175361e-01,  2.87041157e-01,  1.59928456e-01,\n",
       "         1.38865203e-01],\n",
       "       [ 3.86215866e-01,  3.11481535e-01,  1.57116920e-01,\n",
       "         1.32445037e-01],\n",
       "       [-2.78395042e-02,  1.00770664e+00,  3.96271013e-02,\n",
       "        -2.87350640e-03],\n",
       "       [ 3.87904733e-01,  3.31381142e-01,  1.46952167e-01,\n",
       "         1.22254878e-01],\n",
       "       [-2.65444517e-02,  1.00441253e+00,  4.18694355e-02,\n",
       "        -2.68775597e-03],\n",
       "       [ 4.07140195e-01,  3.02749455e-01,  1.55129462e-01,\n",
       "         1.31247327e-01],\n",
       "       [ 2.26684213e-02,  9.22868073e-01,  5.36954887e-02,\n",
       "        -5.70251420e-03],\n",
       "       [ 8.65375102e-02,  8.26621950e-01,  6.96631819e-02,\n",
       "         8.32524896e-03],\n",
       "       [-3.74584347e-02,  1.02471828e+00,  3.70412208e-02,\n",
       "        -2.12218612e-04],\n",
       "       [ 4.43865567e-01,  2.73696929e-01,  1.68919742e-01,\n",
       "         1.51896760e-01],\n",
       "       [ 2.54167616e-03,  9.54104722e-01,  5.06151766e-02,\n",
       "        -8.09600577e-03],\n",
       "       [-3.12288329e-02,  1.01965070e+00,  3.51829119e-02,\n",
       "         2.54870579e-03],\n",
       "       [ 8.94081369e-02,  8.08941901e-01,  7.18836784e-02,\n",
       "         9.37303156e-03],\n",
       "       [-1.36404112e-02,  9.78595078e-01,  4.74500805e-02,\n",
       "        -5.46500459e-03],\n",
       "       [ 3.90489519e-01,  3.24134707e-01,  1.48730293e-01,\n",
       "         1.23862416e-01],\n",
       "       [ 3.76573317e-02,  9.01896656e-01,  5.65210469e-02,\n",
       "        -3.38807330e-03],\n",
       "       [ 3.74326915e-01,  3.37123543e-01,  1.48193583e-01,\n",
       "         1.21033460e-01],\n",
       "       [ 1.78063184e-01,  6.46055102e-01,  1.02204457e-01,\n",
       "         4.87480722e-02],\n",
       "       [ 3.92120957e-01,  3.25427055e-01,  1.49584845e-01,\n",
       "         1.23942435e-01],\n",
       "       [-7.95535743e-04,  9.64676678e-01,  5.00160865e-02,\n",
       "        -5.44901937e-03],\n",
       "       [ 9.03761610e-02,  8.23404610e-01,  7.12894201e-02,\n",
       "         8.27701949e-03],\n",
       "       [ 4.02697325e-01,  3.02166760e-01,  1.50312275e-01,\n",
       "         1.32161677e-01],\n",
       "       [-2.62157619e-03,  9.62326407e-01,  5.01217395e-02,\n",
       "        -7.93571398e-03],\n",
       "       [ 9.17768478e-03,  9.43244755e-01,  5.33447228e-02,\n",
       "        -7.37741590e-03],\n",
       "       [ 2.40857482e-01,  5.78763843e-01,  1.09778628e-01,\n",
       "         5.77774793e-02],\n",
       "       [-1.30365863e-02,  9.79008734e-01,  4.74166423e-02,\n",
       "        -6.49578497e-03],\n",
       "       [ 3.49421889e-01,  3.67798865e-01,  1.44081786e-01,\n",
       "         1.12409025e-01],\n",
       "       [ 2.84989774e-01,  4.65596288e-01,  1.18715867e-01,\n",
       "         8.52305889e-02],\n",
       "       [-2.18317732e-02,  9.97522175e-01,  4.28542681e-02,\n",
       "        -7.70885497e-04],\n",
       "       [ 3.80354822e-01,  3.44248295e-01,  1.50003955e-01,\n",
       "         1.15763903e-01],\n",
       "       [ 7.38115460e-02,  8.12503755e-01,  7.46489316e-02,\n",
       "         1.80805475e-02],\n",
       "       [ 4.08010811e-01,  2.95582294e-01,  1.53567791e-01,\n",
       "         1.35475785e-01],\n",
       "       [ 6.59880042e-03,  9.47194338e-01,  5.24994619e-02,\n",
       "        -6.81898370e-03],\n",
       "       [-2.35640779e-02,  9.95114207e-01,  4.36853729e-02,\n",
       "        -3.75741720e-03],\n",
       "       [ 1.21083364e-01,  7.75835454e-01,  7.46541768e-02,\n",
       "         1.76177584e-02],\n",
       "       [ 4.16392148e-01,  2.96041399e-01,  1.57378539e-01,\n",
       "         1.36232734e-01],\n",
       "       [ 2.60132179e-02,  9.08260286e-01,  5.97847886e-02,\n",
       "        -6.99948519e-04],\n",
       "       [-2.24882811e-02,  1.00041008e+00,  4.14355360e-02,\n",
       "        -1.44520774e-03],\n",
       "       [-3.29111889e-02,  1.01820946e+00,  3.81946675e-02,\n",
       "         8.04103911e-05],\n",
       "       [ 2.32154846e-01,  5.97864747e-01,  1.12050131e-01,\n",
       "         5.42667024e-02],\n",
       "       [ 2.41418034e-01,  5.93261898e-01,  1.07510582e-01,\n",
       "         6.13799430e-02],\n",
       "       [ 1.40233263e-02,  9.36934829e-01,  5.50037585e-02,\n",
       "        -7.23093748e-03],\n",
       "       [-2.63742656e-02,  1.00698519e+00,  3.98143418e-02,\n",
       "        -4.79214266e-03],\n",
       "       [-3.44839692e-02,  1.02831745e+00,  3.26272584e-02,\n",
       "         3.53648514e-03],\n",
       "       [ 4.01775151e-01,  3.12073290e-01,  1.50686666e-01,\n",
       "         1.28322169e-01],\n",
       "       [ 3.29346389e-01,  4.23483759e-01,  1.30772218e-01,\n",
       "         9.47754085e-02],\n",
       "       [-3.83935645e-02,  1.03433120e+00,  3.12272795e-02,\n",
       "         5.53799793e-03],\n",
       "       [ 1.48239106e-01,  7.32992768e-01,  8.32332820e-02,\n",
       "         2.43738089e-02],\n",
       "       [ 9.44831967e-02,  8.16487908e-01,  6.84291795e-02,\n",
       "         1.15784891e-02],\n",
       "       [ 8.01419169e-02,  8.34264696e-01,  6.78286478e-02,\n",
       "         8.09374452e-03],\n",
       "       [ 4.57048088e-01,  2.45364428e-01,  1.71675026e-01,\n",
       "         1.67454779e-01],\n",
       "       [ 2.06808627e-01,  6.37990415e-01,  9.88213271e-02,\n",
       "         4.27449457e-02],\n",
       "       [ 4.14285734e-02,  9.02910709e-01,  5.77283837e-02,\n",
       "        -7.05532730e-05],\n",
       "       [ 3.89554799e-01,  3.25790763e-01,  1.49458393e-01,\n",
       "         1.24005154e-01],\n",
       "       [ 3.39205116e-02,  8.95134270e-01,  6.44916594e-02,\n",
       "         3.82973254e-03],\n",
       "       [-2.23769024e-02,  1.00314021e+00,  4.28603552e-02,\n",
       "        -4.36753035e-04],\n",
       "       [-2.76463851e-02,  1.01107502e+00,  3.84805426e-02,\n",
       "         1.01133063e-03],\n",
       "       [ 1.51226431e-01,  7.26320088e-01,  8.53654891e-02,\n",
       "         2.72189490e-02],\n",
       "       [-5.35555929e-03,  9.75416243e-01,  4.69820835e-02,\n",
       "        -3.57662514e-03],\n",
       "       [ 9.31672007e-02,  8.29116166e-01,  6.74577951e-02,\n",
       "         1.75838508e-02],\n",
       "       [ 1.22026168e-01,  7.75474131e-01,  7.86241889e-02,\n",
       "         1.60255991e-02],\n",
       "       [ 8.24143738e-03,  9.46035862e-01,  5.33710457e-02,\n",
       "        -6.11871853e-03],\n",
       "       [ 5.14961183e-02,  8.84231567e-01,  6.01898171e-02,\n",
       "         5.37838414e-03],\n",
       "       [-2.22221091e-02,  9.95125234e-01,  4.39256988e-02,\n",
       "        -2.57234275e-03],\n",
       "       [ 3.98738354e-01,  3.04071665e-01,  1.48565844e-01,\n",
       "         1.30491078e-01],\n",
       "       [ 1.80793285e-01,  6.79762840e-01,  9.11221802e-02,\n",
       "         3.71425822e-02],\n",
       "       [-5.02150506e-03,  9.67363536e-01,  4.89635356e-02,\n",
       "        -5.53826243e-03],\n",
       "       [-1.32349357e-02,  9.82378244e-01,  4.65748608e-02,\n",
       "        -3.13040987e-03],\n",
       "       [ 1.02130249e-01,  7.94906855e-01,  7.38625899e-02,\n",
       "         1.37202293e-02],\n",
       "       [ 4.29257780e-01,  2.68029481e-01,  1.64826795e-01,\n",
       "         1.51246682e-01],\n",
       "       [ 2.38297462e-01,  5.84901631e-01,  1.07960209e-01,\n",
       "         5.49448170e-02],\n",
       "       [ 2.73480475e-01,  5.22440434e-01,  1.18477255e-01,\n",
       "         6.97226301e-02],\n",
       "       [ 4.38904464e-01,  2.66831934e-01,  1.65156484e-01,\n",
       "         1.49820372e-01],\n",
       "       [-2.12153569e-02,  9.96035039e-01,  4.33673188e-02,\n",
       "        -2.77135149e-03],\n",
       "       [ 3.39621939e-02,  9.08563554e-01,  5.74401543e-02,\n",
       "        -1.15612149e-03],\n",
       "       [ 1.60954803e-01,  7.20929921e-01,  8.45333040e-02,\n",
       "         2.72688270e-02],\n",
       "       [-2.86424682e-02,  1.01395297e+00,  3.64149883e-02,\n",
       "         1.86320022e-03],\n",
       "       [ 4.25345957e-01,  2.80655384e-01,  1.58153847e-01,\n",
       "         1.42058343e-01],\n",
       "       [ 1.20080978e-01,  7.76517689e-01,  7.65534863e-02,\n",
       "         1.54995061e-02],\n",
       "       [-3.32482606e-02,  1.01830316e+00,  3.77413556e-02,\n",
       "        -8.01198184e-05],\n",
       "       [ 3.67962986e-01,  3.57265234e-01,  1.46228746e-01,\n",
       "         1.12886101e-01],\n",
       "       [ 3.64725530e-01,  3.40023696e-01,  1.51656777e-01,\n",
       "         1.22497499e-01],\n",
       "       [ 1.66398317e-01,  7.01900482e-01,  8.80378485e-02,\n",
       "         3.28354090e-02],\n",
       "       [-9.51133668e-04,  9.67754900e-01,  4.85873297e-02,\n",
       "        -4.28374484e-03],\n",
       "       [ 3.37487102e-01,  4.10168231e-01,  1.35005295e-01,\n",
       "         9.79546458e-02],\n",
       "       [-7.90932029e-03,  9.67464626e-01,  5.45097440e-02,\n",
       "        -7.79497996e-03],\n",
       "       [ 5.55965975e-02,  8.72579157e-01,  6.18532337e-02,\n",
       "         4.49623913e-04],\n",
       "       [-2.19381675e-02,  9.99461234e-01,  4.19044383e-02,\n",
       "        -4.44564968e-04],\n",
       "       [ 4.29919362e-01,  2.72778690e-01,  1.61520213e-01,\n",
       "         1.46813542e-01],\n",
       "       [ 4.02882695e-01,  3.10563892e-01,  1.54261276e-01,\n",
       "         1.29583761e-01],\n",
       "       [ 2.09637910e-01,  6.28201902e-01,  1.02744773e-01,\n",
       "         4.41033095e-02],\n",
       "       [-5.97333163e-03,  9.68804181e-01,  4.84110005e-02,\n",
       "        -5.75970858e-03],\n",
       "       [ 2.43929088e-01,  5.71467519e-01,  1.10176936e-01,\n",
       "         5.90701587e-02],\n",
       "       [-1.65800452e-02,  9.89805877e-01,  4.61198315e-02,\n",
       "        -2.41184980e-03],\n",
       "       [-2.35457048e-02,  1.00292897e+00,  4.09002192e-02,\n",
       "         1.86439604e-04],\n",
       "       [ 6.96272179e-02,  8.56926024e-01,  6.52478337e-02,\n",
       "         4.42069396e-03],\n",
       "       [ 2.07417272e-02,  9.28240716e-01,  5.36631681e-02,\n",
       "        -3.54187563e-03],\n",
       "       [ 2.50503451e-01,  5.38642883e-01,  1.12786248e-01,\n",
       "         6.87175840e-02],\n",
       "       [ 3.23549271e-01,  4.04544890e-01,  1.28417298e-01,\n",
       "         1.01525337e-01],\n",
       "       [ 4.37943369e-01,  2.70675749e-01,  1.66939676e-01,\n",
       "         1.49240166e-01],\n",
       "       [ 2.78230011e-02,  9.14259493e-01,  5.44675551e-02,\n",
       "        -4.79044393e-03],\n",
       "       [ 3.27294707e-01,  4.26619530e-01,  1.31265417e-01,\n",
       "         9.29956585e-02],\n",
       "       [-1.33476183e-02,  9.83607709e-01,  4.62712534e-02,\n",
       "        -3.49788740e-03],\n",
       "       [ 1.05053186e-02,  9.48066115e-01,  5.29617481e-02,\n",
       "        -2.62780860e-03],\n",
       "       [ 4.18847293e-01,  2.85446614e-01,  1.58073485e-01,\n",
       "         1.40787110e-01],\n",
       "       [ 1.13833316e-01,  7.86524832e-01,  7.76601434e-02,\n",
       "         1.60189308e-02],\n",
       "       [ 4.39832807e-01,  2.75103450e-01,  1.66095614e-01,\n",
       "         1.47647083e-01],\n",
       "       [ 2.01247633e-04,  9.57457602e-01,  5.05804755e-02,\n",
       "        -8.04001465e-03],\n",
       "       [-1.03037208e-02,  9.75229323e-01,  4.90257889e-02,\n",
       "        -7.13645294e-03],\n",
       "       [ 4.52756643e-01,  2.61620075e-01,  1.71369821e-01,\n",
       "         1.59076780e-01],\n",
       "       [-1.41682699e-02,  9.80979621e-01,  4.88718301e-02,\n",
       "        -6.27368316e-03],\n",
       "       [-1.49287358e-02,  9.80557978e-01,  4.77195568e-02,\n",
       "        -6.13860413e-03],\n",
       "       [ 1.75037459e-02,  9.28647578e-01,  5.39808422e-02,\n",
       "        -4.88125905e-03],\n",
       "       [-3.88845205e-02,  1.02789438e+00,  3.47352438e-02,\n",
       "        -1.31346285e-04],\n",
       "       [-1.54870674e-02,  9.90467846e-01,  4.37863134e-02,\n",
       "        -2.45824829e-03],\n",
       "       [ 3.43890280e-01,  3.93505454e-01,  1.35128453e-01,\n",
       "         1.07626379e-01],\n",
       "       [-1.92611367e-02,  9.88194287e-01,  4.54835854e-02,\n",
       "        -3.83497402e-03],\n",
       "       [ 1.51276231e-01,  7.17736661e-01,  9.25093591e-02,\n",
       "         3.54640856e-02],\n",
       "       [ 3.93985659e-02,  8.99097025e-01,  6.05467185e-02,\n",
       "        -2.47464329e-03],\n",
       "       [ 4.61409241e-03,  9.38250959e-01,  5.88666759e-02,\n",
       "        -2.99656764e-03],\n",
       "       [-2.26629004e-02,  1.00013447e+00,  4.16262336e-02,\n",
       "        -9.48380679e-04],\n",
       "       [-4.17558923e-02,  1.03518772e+00,  3.26192565e-02,\n",
       "         2.10186467e-03],\n",
       "       [ 2.29837239e-01,  5.88199437e-01,  1.05612978e-01,\n",
       "         5.71320988e-02],\n",
       "       [-2.84772664e-02,  1.01327658e+00,  3.79196443e-02,\n",
       "        -1.30437315e-04],\n",
       "       [-1.14747658e-02,  9.76303041e-01,  4.72012907e-02,\n",
       "        -5.30493632e-03],\n",
       "       [ 3.85084301e-01,  3.31211895e-01,  1.54285297e-01,\n",
       "         1.30502313e-01],\n",
       "       [ 7.50968903e-02,  8.33127558e-01,  6.93394989e-02,\n",
       "         8.71849060e-03],\n",
       "       [ 3.40067029e-01,  4.05550778e-01,  1.34111971e-01,\n",
       "         9.86257046e-02],\n",
       "       [-2.91832313e-02,  1.00790000e+00,  4.02469561e-02,\n",
       "        -4.29965183e-03],\n",
       "       [ 4.55893964e-01,  2.63412744e-01,  1.67800725e-01,\n",
       "         1.56724811e-01],\n",
       "       [ 4.35656905e-02,  8.92770052e-01,  5.77901304e-02,\n",
       "        -5.52721322e-04],\n",
       "       [ 4.30376142e-01,  2.81171948e-01,  1.64561152e-01,\n",
       "         1.42602175e-01],\n",
       "       [-4.11333963e-02,  1.04124427e+00,  3.07699516e-02,\n",
       "         4.19087335e-03],\n",
       "       [ 4.47826087e-03,  9.51958895e-01,  5.14380075e-02,\n",
       "        -9.09934565e-03],\n",
       "       [-1.03379712e-02,  9.76679265e-01,  5.04860952e-02,\n",
       "        -7.89120421e-03],\n",
       "       [-2.72711366e-03,  9.63445663e-01,  5.22095859e-02,\n",
       "        -5.82746416e-03],\n",
       "       [-7.26633519e-03,  9.70220447e-01,  5.11265695e-02,\n",
       "        -6.85971975e-03],\n",
       "       [-2.53059492e-02,  1.00657952e+00,  3.95392925e-02,\n",
       "         6.67098910e-04],\n",
       "       [ 3.74108225e-01,  3.44902515e-01,  1.44328028e-01,\n",
       "         1.19568601e-01],\n",
       "       [-2.88553610e-02,  1.01061749e+00,  4.13394347e-02,\n",
       "        -3.73036787e-03],\n",
       "       [-2.46212184e-02,  1.00000203e+00,  4.24988791e-02,\n",
       "        -2.23627314e-03],\n",
       "       [ 4.28910494e-01,  2.83103138e-01,  1.62881434e-01,\n",
       "         1.42743811e-01],\n",
       "       [ 4.16445732e-03,  9.54406202e-01,  5.11171632e-02,\n",
       "        -4.27182764e-03],\n",
       "       [ 2.26753235e-01,  6.04714274e-01,  1.04699910e-01,\n",
       "         5.44174761e-02],\n",
       "       [-4.46063802e-02,  1.04236436e+00,  3.16019692e-02,\n",
       "         2.31615826e-03],\n",
       "       [ 1.36462077e-02,  9.44030583e-01,  5.33538200e-02,\n",
       "        -3.41009721e-03],\n",
       "       [ 1.86814740e-02,  9.33435202e-01,  5.35394065e-02,\n",
       "        -3.65997478e-03],\n",
       "       [-2.75419727e-02,  1.00508356e+00,  4.27351967e-02,\n",
       "        -5.93629852e-03],\n",
       "       [ 3.21775705e-01,  4.45247054e-01,  1.33550078e-01,\n",
       "         9.54604000e-02],\n",
       "       [-4.39710170e-03,  9.67315912e-01,  5.03613763e-02,\n",
       "        -6.33873045e-03],\n",
       "       [ 3.32573950e-01,  3.84964257e-01,  1.38335764e-01,\n",
       "         1.11654282e-01],\n",
       "       [ 4.97297309e-02,  8.84860218e-01,  5.94944134e-02,\n",
       "         6.83084130e-04],\n",
       "       [ 4.90392148e-02,  8.86868179e-01,  5.84929921e-02,\n",
       "        -1.48361921e-03],\n",
       "       [ 4.38934684e-01,  2.70102501e-01,  1.65064707e-01,\n",
       "         1.48703679e-01],\n",
       "       [ 3.96436453e-01,  3.08484495e-01,  1.54244199e-01,\n",
       "         1.29357323e-01],\n",
       "       [ 3.71631920e-01,  3.41279536e-01,  1.43472552e-01,\n",
       "         1.20050758e-01],\n",
       "       [-2.03544274e-02,  9.94359791e-01,  4.66793887e-02,\n",
       "        -6.26963750e-03],\n",
       "       [ 1.35135859e-01,  7.56753683e-01,  8.31707194e-02,\n",
       "         2.04765853e-02],\n",
       "       [ 1.94596022e-01,  6.50689662e-01,  9.67446417e-02,\n",
       "         4.46409099e-02],\n",
       "       [ 3.23928177e-01,  4.32929814e-01,  1.32123768e-01,\n",
       "         9.53685790e-02],\n",
       "       [-3.77592444e-02,  1.03467131e+00,  3.07162069e-02,\n",
       "         5.66809997e-03],\n",
       "       [ 3.17938030e-01,  4.36203420e-01,  1.31378964e-01,\n",
       "         9.83482897e-02],\n",
       "       [ 3.62161137e-02,  8.99331391e-01,  5.85930422e-02,\n",
       "        -2.33545899e-03],\n",
       "       [-4.16969582e-02,  1.04649949e+00,  2.22819038e-02,\n",
       "         9.83707979e-03],\n",
       "       [ 5.45512959e-02,  8.78631532e-01,  6.04247749e-02,\n",
       "         3.69964540e-03],\n",
       "       [-2.11932883e-02,  9.94341493e-01,  4.34118360e-02,\n",
       "        -3.79109755e-03],\n",
       "       [ 3.26340050e-02,  9.08226311e-01,  5.70618436e-02,\n",
       "        -4.36898321e-04],\n",
       "       [ 3.99879456e-01,  3.11926842e-01,  1.51123211e-01,\n",
       "         1.28242150e-01],\n",
       "       [-2.40637586e-02,  1.00013351e+00,  4.41340543e-02,\n",
       "        -4.15945426e-03],\n",
       "       [-4.38919887e-02,  1.04007602e+00,  3.06483693e-02,\n",
       "         3.50895897e-03],\n",
       "       [-1.74359381e-02,  9.95085537e-01,  4.54922318e-02,\n",
       "        -2.14288011e-03],\n",
       "       [-3.07169557e-03,  9.59878445e-01,  5.56363948e-02,\n",
       "        -6.44288585e-03],\n",
       "       [ 2.02680051e-01,  6.24683976e-01,  1.00190878e-01,\n",
       "         4.98410426e-02],\n",
       "       [ 1.15919426e-01,  7.86303997e-01,  7.58618265e-02,\n",
       "         1.70240607e-02],\n",
       "       [-1.87500492e-02,  9.94299412e-01,  4.27657887e-02,\n",
       "        -1.94476172e-03],\n",
       "       [ 8.57048854e-02,  8.32135141e-01,  6.70602843e-02,\n",
       "         5.88748790e-03],\n",
       "       [ 4.21636283e-01,  2.84765542e-01,  1.58981368e-01,\n",
       "         1.40651509e-01],\n",
       "       [-2.10179090e-02,  9.92748797e-01,  4.34012525e-02,\n",
       "        -2.68901139e-03],\n",
       "       [ 1.12514324e-01,  7.86410868e-01,  7.30106831e-02,\n",
       "         1.61756314e-02],\n",
       "       [ 4.05282408e-01,  3.00075859e-01,  1.54484272e-01,\n",
       "         1.33158416e-01],\n",
       "       [-1.67740583e-02,  9.85758126e-01,  5.07817790e-02,\n",
       "        -6.74942508e-03],\n",
       "       [ 1.70163333e-01,  6.94635391e-01,  9.00056064e-02,\n",
       "         3.33346911e-02],\n",
       "       [ 3.70666832e-02,  8.89308393e-01,  6.26023710e-02,\n",
       "        -1.21578574e-04],\n",
       "       [ 2.53689557e-01,  5.46642005e-01,  1.12006903e-01,\n",
       "         6.63471371e-02],\n",
       "       [-1.69887915e-02,  9.90281284e-01,  4.37129177e-02,\n",
       "        -1.14593282e-03],\n",
       "       [-2.22284719e-02,  9.93606329e-01,  4.35455367e-02,\n",
       "        -5.20275906e-03],\n",
       "       [ 4.23298001e-01,  2.81816512e-01,  1.59797832e-01,\n",
       "         1.40815601e-01],\n",
       "       [ 9.91854817e-03,  9.44888592e-01,  5.30195609e-02,\n",
       "        -4.26502898e-03],\n",
       "       [ 3.66154552e-01,  3.62639070e-01,  1.41772896e-01,\n",
       "         1.11629441e-01],\n",
       "       [-3.18254530e-02,  1.01366234e+00,  3.86675783e-02,\n",
       "        -3.15384194e-03],\n",
       "       [-2.97712013e-02,  1.00899148e+00,  3.96674573e-02,\n",
       "        -1.59852579e-03],\n",
       "       [-2.96083018e-02,  1.01087093e+00,  3.89510058e-02,\n",
       "         1.66721642e-03],\n",
       "       [ 4.83748764e-02,  8.79462183e-01,  6.49188161e-02,\n",
       "         3.30077484e-03],\n",
       "       [-2.42428109e-02,  1.00084913e+00,  4.05344218e-02,\n",
       "        -8.20305198e-04]], dtype=float32)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(scaled_features_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_indices = []\n",
    "\n",
    "for item in model.predict(scaled_features_3):\n",
    "    highest_prob = item[0]\n",
    "    highest_prob_index = 0\n",
    "    for i in range(1,len(item)):\n",
    "        if item[i] > highest_prob:\n",
    "            highest_prob = item[i]\n",
    "            highest_prob_index = i\n",
    "    prediction_indices.append(highest_prob_index)\n",
    "    \n",
    "pd.Series(prediction_indices).value_counts()\n",
    "\n",
    "#2 of the options were never predicted\n",
    "#Try model that does not discriminate amongst specific all-nba team\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with any all-nba team as a class instead of first, second, and third teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make copy of previous df to edit\n",
    "df_4 = df_3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TSP</th>\n",
       "      <th>a/t_ratio</th>\n",
       "      <th>Honors_Next_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>303</td>\n",
       "      <td>1.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.621176</td>\n",
       "      <td>2.170732</td>\n",
       "      <td>Selected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1193</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.617315</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>Selected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1226</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.534810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1464</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600245</td>\n",
       "      <td>1.651163</td>\n",
       "      <td>Selected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2661</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.532338</td>\n",
       "      <td>1.761905</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10292</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.498532</td>\n",
       "      <td>1.230769</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10293</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.521403</td>\n",
       "      <td>1.243243</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10319</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.532454</td>\n",
       "      <td>1.678571</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10337</td>\n",
       "      <td>1.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.506859</td>\n",
       "      <td>1.468750</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10346</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.508811</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ORB  DRB  STL  BLK       TSP  a/t_ratio Honors_Next_Year\n",
       "303    1.2  7.3  1.4  0.8  0.621176   2.170732         Selected\n",
       "1193   3.5  8.4  0.7  1.2  0.617315   1.040000         Selected\n",
       "1226   1.2  2.7  1.0  0.4  0.534810   1.000000        No_Honors\n",
       "1464   0.7  5.0  1.6  0.6  0.600245   1.651163         Selected\n",
       "2661   0.6  3.5  1.0  0.3  0.532338   1.761905        No_Honors\n",
       "...    ...  ...  ...  ...       ...        ...              ...\n",
       "10292  0.6  3.6  1.3  0.3  0.498532   1.230769        No_Honors\n",
       "10293  1.1  2.4  1.1  0.6  0.521403   1.243243        No_Honors\n",
       "10319  0.5  2.6  1.2  0.1  0.532454   1.678571        No_Honors\n",
       "10337  1.6  6.0  1.5  0.5  0.506859   1.468750        No_Honors\n",
       "10346  0.7  1.9  1.5  0.2  0.508811   2.100000        No_Honors\n",
       "\n",
       "[194 rows x 7 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recategorize any non \"No_Honors\" category as \"Selected\"\n",
    "\n",
    "new_h = []\n",
    "for item in df_4['Honors_Next_Year']:\n",
    "    if item != 'No_Honors':\n",
    "        new_h.append('Selected')\n",
    "    else:\n",
    "        new_h.append('No_Honors')\n",
    "        \n",
    "df_4['Honors_Next_Year'] = new_h\n",
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate features from target and scale the features\n",
    "\n",
    "features_4 = df_4.drop(['Honors_Next_Year'], axis = 1)\n",
    "target_4 = df_4['Honors_Next_Year']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features_4 = pd.DataFrame(scaler.fit_transform(features_4), columns = features_4.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class labels:\n",
      "['No_Honors', 'Selected']\n",
      "\n",
      "\n",
      "New product labels:\n",
      "[1 1 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
      " 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 0 1 1 1 0 0 0 0 0]\n",
      "\n",
      "\n",
      "One hot labels; 7 binary columns, one for each of the categories.\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "\n",
      "\n",
      "One hot labels shape:\n",
      "(194, 2)\n"
     ]
    }
   ],
   "source": [
    "#Repeat process to make honors category a quantiative array\n",
    "\n",
    "\n",
    "product_4 = df_4[\"Honors_Next_Year\"]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(product_4)\n",
    "product_cat_4 = le.transform(product_4)  \n",
    "product_onehot_4 = to_categorical(product_cat_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features_4, \n",
    "                                                    product_onehot_4, \n",
    "                                                    random_state = 123, \n",
    "                                                    test_size = .2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "155/155 [==============================] - 5s 30ms/step - loss: 5.2086 - acc: 0.5323\n",
      "Epoch 2/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 6.0940 - acc: 0.5000\n",
      "Epoch 3/60\n",
      "155/155 [==============================] - 0s 925us/step - loss: 6.0951 - acc: 0.5000\n",
      "Epoch 4/60\n",
      "155/155 [==============================] - 0s 903us/step - loss: 6.0915 - acc: 0.5000\n",
      "Epoch 5/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 6.0926 - acc: 0.5000\n",
      "Epoch 6/60\n",
      "155/155 [==============================] - 0s 921us/step - loss: 6.0903 - acc: 0.5000\n",
      "Epoch 7/60\n",
      "155/155 [==============================] - 0s 898us/step - loss: 6.0937 - acc: 0.5000\n",
      "Epoch 8/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 6.0897 - acc: 0.5000\n",
      "Epoch 9/60\n",
      "155/155 [==============================] - 0s 910us/step - loss: 6.0883 - acc: 0.5000\n",
      "Epoch 10/60\n",
      "155/155 [==============================] - 0s 908us/step - loss: 6.0852 - acc: 0.5000\n",
      "Epoch 11/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 6.0858 - acc: 0.5000\n",
      "Epoch 12/60\n",
      "155/155 [==============================] - 0s 923us/step - loss: 6.0864 - acc: 0.5000\n",
      "Epoch 13/60\n",
      "155/155 [==============================] - 0s 921us/step - loss: 6.0893 - acc: 0.5000\n",
      "Epoch 14/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 6.0834 - acc: 0.5000\n",
      "Epoch 15/60\n",
      "155/155 [==============================] - 0s 909us/step - loss: 6.0798 - acc: 0.5000\n",
      "Epoch 16/60\n",
      "155/155 [==============================] - 0s 927us/step - loss: 6.0811 - acc: 0.5000\n",
      "Epoch 17/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 6.0821 - acc: 0.5000\n",
      "Epoch 18/60\n",
      "155/155 [==============================] - 0s 908us/step - loss: 6.0863 - acc: 0.5000\n",
      "Epoch 19/60\n",
      "155/155 [==============================] - 0s 899us/step - loss: 6.0783 - acc: 0.5000\n",
      "Epoch 20/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 6.0782 - acc: 0.5000\n",
      "Epoch 21/60\n",
      "155/155 [==============================] - 0s 904us/step - loss: 6.0807 - acc: 0.5000\n",
      "Epoch 22/60\n",
      "155/155 [==============================] - 0s 922us/step - loss: 6.0765 - acc: 0.5000\n",
      "Epoch 23/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 6.0727 - acc: 0.5000\n",
      "Epoch 24/60\n",
      "155/155 [==============================] - 0s 901us/step - loss: 6.0707 - acc: 0.5000\n",
      "Epoch 25/60\n",
      "155/155 [==============================] - 0s 903us/step - loss: 6.0684 - acc: 0.5032\n",
      "Epoch 26/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 6.0685 - acc: 0.5000\n",
      "Epoch 27/60\n",
      "155/155 [==============================] - 0s 910us/step - loss: 6.0692 - acc: 0.5000\n",
      "Epoch 28/60\n",
      "155/155 [==============================] - 0s 906us/step - loss: 6.0604 - acc: 0.5000\n",
      "Epoch 29/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 6.0634 - acc: 0.4968\n",
      "Epoch 30/60\n",
      "155/155 [==============================] - 0s 914us/step - loss: 6.0583 - acc: 0.5032\n",
      "Epoch 31/60\n",
      "155/155 [==============================] - 0s 902us/step - loss: 6.0583 - acc: 0.5000\n",
      "Epoch 32/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 6.0528 - acc: 0.5065\n",
      "Epoch 33/60\n",
      "155/155 [==============================] - 0s 927us/step - loss: 6.0580 - acc: 0.4968\n",
      "Epoch 34/60\n",
      "155/155 [==============================] - 0s 909us/step - loss: 6.0443 - acc: 0.5000\n",
      "Epoch 35/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 6.0497 - acc: 0.5000\n",
      "Epoch 36/60\n",
      "155/155 [==============================] - 0s 947us/step - loss: 6.0413 - acc: 0.5032\n",
      "Epoch 37/60\n",
      "155/155 [==============================] - 0s 984us/step - loss: 6.0425 - acc: 0.5032\n",
      "Epoch 38/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 6.0394 - acc: 0.5065\n",
      "Epoch 39/60\n",
      "155/155 [==============================] - 0s 921us/step - loss: 6.0390 - acc: 0.5000\n",
      "Epoch 40/60\n",
      "155/155 [==============================] - 0s 914us/step - loss: 6.0304 - acc: 0.5097\n",
      "Epoch 41/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 6.0266 - acc: 0.5097\n",
      "Epoch 42/60\n",
      "155/155 [==============================] - 0s 904us/step - loss: 6.0373 - acc: 0.5129\n",
      "Epoch 43/60\n",
      "155/155 [==============================] - 0s 925us/step - loss: 6.0224 - acc: 0.5161\n",
      "Epoch 44/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 6.0232 - acc: 0.5226\n",
      "Epoch 45/60\n",
      "155/155 [==============================] - 0s 922us/step - loss: 6.0117 - acc: 0.5258\n",
      "Epoch 46/60\n",
      "155/155 [==============================] - 0s 960us/step - loss: 6.0267 - acc: 0.5194\n",
      "Epoch 47/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 6.0125 - acc: 0.5161\n",
      "Epoch 48/60\n",
      "155/155 [==============================] - 0s 944us/step - loss: 6.0156 - acc: 0.5258\n",
      "Epoch 49/60\n",
      "155/155 [==============================] - 0s 933us/step - loss: 6.0018 - acc: 0.5290\n",
      "Epoch 50/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 5.9980 - acc: 0.5355\n",
      "Epoch 51/60\n",
      "155/155 [==============================] - 0s 934us/step - loss: 6.0399 - acc: 0.5419\n",
      "Epoch 52/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 6.0494 - acc: 0.5355\n",
      "Epoch 53/60\n",
      "155/155 [==============================] - 0s 936us/step - loss: 6.0056 - acc: 0.5452\n",
      "Epoch 54/60\n",
      "155/155 [==============================] - 0s 963us/step - loss: 6.0257 - acc: 0.5065\n",
      "Epoch 55/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 5.9961 - acc: 0.5290\n",
      "Epoch 56/60\n",
      "155/155 [==============================] - 0s 942us/step - loss: 6.0125 - acc: 0.5226\n",
      "Epoch 57/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 5.9992 - acc: 0.5323\n",
      "Epoch 58/60\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 6.0020 - acc: 0.5129\n",
      "Epoch 59/60\n",
      "155/155 [==============================] - 0s 978us/step - loss: 5.9944 - acc: 0.5387\n",
      "Epoch 60/60\n",
      "155/155 [==============================] - 0s 941us/step - loss: 6.0058 - acc: 0.5290\n",
      "155/155 [==============================] - 1s 10ms/step\n",
      "[5.978850416983327, 0.5451612949371338]\n",
      "39/39 [==============================] - 0s 179us/step\n",
      "[6.796660887889373, 0.5]\n"
     ]
    }
   ],
   "source": [
    "#Run model with best version of model from previous attempts\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(25, activation = 'relu', kernel_initializer='normal',input_shape = (6,)))\n",
    "model.add(layers.Dense(50, kernel_regularizer= regularizers.l2(0.005),activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(100,activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(150, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(200, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(250, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(300, activation = 'relu'))\n",
    "model.add(layers.Dense(2, activation = 'linear'))\n",
    "\n",
    "model.compile(optimizer = 'sgd', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 10, epochs = 60)\n",
    "\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "results_train = model.evaluate(X_train, y_train)\n",
    "print(results_train)\n",
    "\n",
    "results_test = model.evaluate(X_test, y_test)\n",
    "print(results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot loss\n",
    "\n",
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "\n",
    "loss_list = history_dict['loss']\n",
    "epochs = range(1,len(loss_list)+1)\n",
    "\n",
    "plt.plot(epochs, loss_list, label = 'Training Loss')\n",
    "\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot accuracy\n",
    "\n",
    "accuracy_list = history_dict['acc']\n",
    "epochs = range(1,len(loss_list)+1)\n",
    "\n",
    "plt.plot(epochs, accuracy_list, label = 'Training Accuracy')\n",
    "\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No_Honors    139\n",
       "Selected      55\n",
       "Name: Honors_Next_Year, dtype: int64"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm that model does not only pick \"No_Honors\"\n",
    "\n",
    "df_4['Honors_Next_Year'].value_counts()\n",
    "print(139/(55+139)) #.71\n",
    "#The model does not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See if machine learning model works better with df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine pipeline test accuracy: 0.8461538461538461\n",
      "Decision Tree pipeline test accuracy: 0.8205128205128205\n",
      "Random Forest pipeline test accuracy: 0.8205128205128205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Create train and test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features_4, target_4, test_size = .2, random_state = 123)\n",
    "\n",
    "#Conduct Simple Classifications\n",
    "\n",
    "\n",
    "#Create pipeline for SVM  model\n",
    "pipe_svm = Pipeline([('clf', svm.SVC(random_state=123))])\n",
    "\n",
    "#Create pipeline for Decision Tree model      \n",
    "pipe_tree = Pipeline([\n",
    "        ('clf', DecisionTreeClassifier(random_state=123))])\n",
    "\n",
    "#Create pipeline for Random Forest Model analysis\n",
    "pipe_rf = Pipeline([\n",
    "        ('clf', RandomForestClassifier(random_state=123))])\n",
    "\n",
    "#Loop through the pipelines to fit each pipeline to the dataset\n",
    "pipes = [pipe_svm, pipe_tree, pipe_rf]\n",
    "pipeline_names = ['Support Vector Machine','Decision Tree','Random Forest']\n",
    "for pipe in pipes:\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "# Compare model accuracies with default parameters\n",
    "for index, val in enumerate(pipes):\n",
    "    print('{} pipeline test accuracy: {}'.format(pipeline_names[index], val.score(X_test, y_test)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
      "[CV] clf__C=0.1, clf__kernel=linear ..................................\n",
      "[CV] ................... clf__C=0.1, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=0.1, clf__kernel=linear ..................................\n",
      "[CV] ................... clf__C=0.1, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=0.1, clf__kernel=linear ..................................\n",
      "[CV] ................... clf__C=0.1, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=1, clf__kernel=linear ....................................\n",
      "[CV] ..................... clf__C=1, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=1, clf__kernel=linear ....................................\n",
      "[CV] ..................... clf__C=1, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=1, clf__kernel=linear ....................................\n",
      "[CV] ..................... clf__C=1, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=10, clf__kernel=linear ...................................\n",
      "[CV] .................... clf__C=10, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=10, clf__kernel=linear ...................................\n",
      "[CV] .................... clf__C=10, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=10, clf__kernel=linear ...................................\n",
      "[CV] .................... clf__C=10, clf__kernel=linear, total=   0.0s\n",
      "[CV] clf__C=1, clf__gamma=0.001, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=1, clf__gamma=0.001, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=1, clf__gamma=0.001, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=1, clf__gamma=0.001, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=1, clf__gamma=0.001, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=1, clf__gamma=0.001, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=1, clf__gamma=0.01, clf__kernel=rbf ......................\n",
      "[CV] ....... clf__C=1, clf__gamma=0.01, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=1, clf__gamma=0.01, clf__kernel=rbf ......................\n",
      "[CV] ....... clf__C=1, clf__gamma=0.01, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=1, clf__gamma=0.01, clf__kernel=rbf ......................\n",
      "[CV] ....... clf__C=1, clf__gamma=0.01, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=10, clf__gamma=0.001, clf__kernel=rbf ....................\n",
      "[CV] ..... clf__C=10, clf__gamma=0.001, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=10, clf__gamma=0.001, clf__kernel=rbf ....................\n",
      "[CV] ..... clf__C=10, clf__gamma=0.001, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=10, clf__gamma=0.001, clf__kernel=rbf ....................\n",
      "[CV] ..... clf__C=10, clf__gamma=0.001, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=10, clf__gamma=0.01, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=10, clf__gamma=0.01, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=10, clf__gamma=0.01, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=10, clf__gamma=0.01, clf__kernel=rbf, total=   0.0s\n",
      "[CV] clf__C=10, clf__gamma=0.01, clf__kernel=rbf .....................\n",
      "[CV] ...... clf__C=10, clf__gamma=0.01, clf__kernel=rbf, total=   0.0s\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    0.1s finished\n",
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=entropy, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=4, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__criterion=gini, clf__max_depth=5, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.05, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.1, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.05, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.1, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n",
      "[CV] clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120 \n",
      "[CV]  clf__criterion=gini, clf__max_depth=6, clf__min_samples_leaf=0.2, clf__min_samples_split=0.2, clf__n_estimators=120, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 162 out of 162 | elapsed:   16.8s finished\n",
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=30, total=   0.0s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=30, total=   0.0s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=30, total=   0.0s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=50, total=   0.1s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=50, total=   0.1s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=50, total=   0.1s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=70, total=   0.1s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=70, total=   0.1s\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=1.0, clf__n_estimators=70, total=   0.1s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=30, total=   0.0s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=30, total=   0.0s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=30, total=   0.0s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=50, total=   0.1s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=50, total=   0.1s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=50, total=   0.1s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=70, total=   0.1s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=70, total=   0.1s\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.5, clf__n_estimators=70, total=   0.2s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=30, total=   0.0s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=30, total=   0.0s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=30 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=30, total=   0.0s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=50, total=   0.1s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=50, total=   0.1s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=50 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=50, total=   0.1s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=70, total=   0.1s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=70, total=   0.1s\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=70 ....................\n",
      "[CV] ..... clf__learning_rate=0.1, clf__n_estimators=70, total=   0.1s\n",
      "Best accuracy for SVM 0.8\n",
      "Best params for SVM {'clf__C': 1, 'clf__kernel': 'linear'}\n",
      "\n",
      "Best accuracy for Random Forest 0.8193548387096774\n",
      "Best params for Random Forest {'clf__criterion': 'gini', 'clf__max_depth': 5, 'clf__min_samples_leaf': 0.05, 'clf__min_samples_split': 0.05, 'clf__n_estimators': 120}\n",
      "\n",
      "Best accuracy for Adaboost 0.7935483870967742\n",
      "Best params for Adaboost {'clf__learning_rate': 0.1, 'clf__n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    2.1s finished\n",
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Grid search to find best parameters\n",
    "\n",
    "\n",
    "#SVM\n",
    "\n",
    "\n",
    "#Create SVM pipeline\n",
    "pipe_svm = Pipeline([('clf', svm.SVC(random_state = 123))])\n",
    "\n",
    "# Set grid search parameters for SVM\n",
    "param_grid_svm = [\n",
    "  {'clf__C': [0.1, 1, 10]  , 'clf__kernel': ['linear']},\n",
    "  {'clf__C': [1, 10], 'clf__gamma': [0.001, 0.01], 'clf__kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# Construct grid search using the SVM pipeline and grid search parameters\n",
    "gs_svm = GridSearchCV(estimator=pipe_svm,\n",
    "            param_grid=param_grid_svm,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit SVM model using grid search\n",
    "gs_svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Random Forest\n",
    "\n",
    "#Create Random Forest pipeline\n",
    "pipe_rf = Pipeline([\n",
    "            ('clf', RandomForestClassifier(random_state = 123))])\n",
    "\n",
    "# Set grid search parameters for Random Forest\n",
    "param_grid_forest = [ \n",
    "  {'clf__n_estimators': [120],\n",
    "   'clf__criterion': ['entropy', 'gini'], \n",
    "   'clf__max_depth': [4, 5, 6],  \n",
    "   'clf__min_samples_leaf':[0.05 ,0.1, 0.2],  \n",
    "   'clf__min_samples_split':[0.05 ,0.1, 0.2]\n",
    "  }\n",
    "]\n",
    "\n",
    "# Construct grid search\n",
    "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "            param_grid=param_grid_forest,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit Random Forest model using grid search\n",
    "gs_rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Adaboost\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Construct Adaboost pipeline\n",
    "pipe_ab = Pipeline([\n",
    "            ('clf', AdaBoostClassifier(random_state = 123))])\n",
    "\n",
    "# Set grid search params for Adaboost\n",
    "adaboost_param_grid = {\n",
    "    'clf__n_estimators': [30, 50, 70],\n",
    "    'clf__learning_rate': [1.0, 0.5, 0.1]\n",
    "}\n",
    "\n",
    "# Construct grid search\n",
    "gs_ab = GridSearchCV(estimator=pipe_ab,\n",
    "            param_grid=adaboost_param_grid,\n",
    "            scoring='accuracy',\n",
    "            cv=3, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit Adaboost model using grid search\n",
    "gs_ab.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Print out the best accuracy scores and parameters for each model\n",
    "\n",
    "# Best accuracy SVM\n",
    "print('Best accuracy for SVM {}'.format(gs_svm.best_score_))\n",
    "# Best params SVM\n",
    "print('Best params for SVM {}'.format(gs_svm.best_params_))\n",
    "\n",
    "print()\n",
    "\n",
    "# Best accuracy Random Forest\n",
    "print('Best accuracy for Random Forest {}'.format(gs_rf.best_score_))\n",
    "# Best params Random Forest\n",
    "print('Best params for Random Forest {}'.format(gs_rf.best_params_))\n",
    "\n",
    "print()\n",
    "\n",
    "# Best accuracy Adaboost\n",
    "print('Best accuracy for Adaboost {}'.format(gs_ab.best_score_))\n",
    "# Best params Adaboost\n",
    "print('Best params for Adaboost {}'.format(gs_ab.best_params_))\n",
    "\n",
    "#Highest accuracy - Random forest with:\n",
    "#{'clf__criterion': 'gini', 'clf__max_depth': 5, 'clf__min_samples_leaf': 0.05, \n",
    "#'clf__min_samples_split': 0.05, 'clf__n_estimators': 120}\n",
    "\n",
    "#create SVM pipeline with best parameters\n",
    "pipe_rf_best = Pipeline([\n",
    "            ('clf', RandomForestClassifier(criterion = 'gini', max_depth = 5, min_samples_leaf = .05,\n",
    "             min_samples_split = .05, n_estimators = 50,random_state = 123))])\n",
    "\n",
    "#Fit model to the dataaset\n",
    "pipe_rf_best.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "preds = pipe_rf_best.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy with best model: 0.7948717948717948\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "\n",
    "#Test model accuracy\n",
    "print(\"Accuracy with best model: {}\".format(accuracy_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No_Honors    31\n",
       "Selected      8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(preds).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Machine learning model performs about as well as best-tuned neural network - both about 79.5% accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    194\n",
       "dtype: int64"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_indices = []\n",
    "\n",
    "for item in model.predict(scaled_features_4):\n",
    "    highest_prob = item[0]\n",
    "    highest_prob_index = 0\n",
    "    for i in range(1,len(item)):\n",
    "        if item[i] > highest_prob:\n",
    "            highest_prob = item[i]\n",
    "            highest_prob_index = i\n",
    "    prediction_indices.append(highest_prob_index)\n",
    "    \n",
    "pd.Series(prediction_indices).value_counts()\n",
    "\n",
    "#Machine learning model guessed everything as not selected\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceed with Best Machine Learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare ML predictions to real labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find entries for which the model erred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TSP</th>\n",
       "      <th>a/t_ratio</th>\n",
       "      <th>Year</th>\n",
       "      <th>Player</th>\n",
       "      <th>concat</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>MP</th>\n",
       "      <th>Honors_Next_Year</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2673</td>\n",
       "      <td>0.7</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.633689</td>\n",
       "      <td>1.545455</td>\n",
       "      <td>2014</td>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>2014Kevin Durant</td>\n",
       "      <td>SF</td>\n",
       "      <td>25</td>\n",
       "      <td>OKC</td>\n",
       "      <td>3122</td>\n",
       "      <td>No_Honors</td>\n",
       "      <td>Selected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3415</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.549926</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2013</td>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>2013Damian Lillard</td>\n",
       "      <td>PG</td>\n",
       "      <td>22</td>\n",
       "      <td>POR</td>\n",
       "      <td>3167</td>\n",
       "      <td>Third</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4453</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.588652</td>\n",
       "      <td>1.882353</td>\n",
       "      <td>2011</td>\n",
       "      <td>Pau Gasol</td>\n",
       "      <td>2011Pau Gasol</td>\n",
       "      <td>C</td>\n",
       "      <td>30</td>\n",
       "      <td>LAL</td>\n",
       "      <td>3037</td>\n",
       "      <td>No_Honors</td>\n",
       "      <td>Selected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4713</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.550128</td>\n",
       "      <td>2.242424</td>\n",
       "      <td>2011</td>\n",
       "      <td>Derrick Rose</td>\n",
       "      <td>2011Derrick Rose</td>\n",
       "      <td>PG</td>\n",
       "      <td>22</td>\n",
       "      <td>CHI</td>\n",
       "      <td>3026</td>\n",
       "      <td>First</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5180</td>\n",
       "      <td>2.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.586265</td>\n",
       "      <td>1.521739</td>\n",
       "      <td>2010</td>\n",
       "      <td>David Lee</td>\n",
       "      <td>2010David Lee</td>\n",
       "      <td>C</td>\n",
       "      <td>26</td>\n",
       "      <td>NYK</td>\n",
       "      <td>3019</td>\n",
       "      <td>No_Honors</td>\n",
       "      <td>Selected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ORB  DRB  STL  BLK       TSP  a/t_ratio  Year          Player  \\\n",
       "2673  0.7  6.2  1.2  0.7  0.633689   1.545455  2014    Kevin Durant   \n",
       "3415  0.5  2.4  0.8  0.2  0.549926   2.142857  2013  Damian Lillard   \n",
       "4453  3.2  6.7  0.6  1.5  0.588652   1.882353  2011       Pau Gasol   \n",
       "4713  1.0  3.0  1.0  0.6  0.550128   2.242424  2011    Derrick Rose   \n",
       "5180  2.7  8.6  1.0  0.5  0.586265   1.521739  2010       David Lee   \n",
       "\n",
       "                  concat Pos  Age   Tm    MP Honors_Next_Year Predictions  \n",
       "2673    2014Kevin Durant  SF   25  OKC  3122        No_Honors    Selected  \n",
       "3415  2013Damian Lillard  PG   22  POR  3167            Third   No_Honors  \n",
       "4453       2011Pau Gasol   C   30  LAL  3037        No_Honors    Selected  \n",
       "4713    2011Derrick Rose  PG   22  CHI  3026            First   No_Honors  \n",
       "5180       2010David Lee   C   26  NYK  3019        No_Honors    Selected  "
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use ML model to predict all entries in the dataframe\n",
    "ml_preds = pipe_rf_best.predict(scaled_features_4)\n",
    "df_4['Predictions'] = ml_preds\n",
    "\n",
    "#create a df for the entries that have honors and predictions that don't match\n",
    "dont_match_preds = df_4[df_4['Honors_Next_Year'] != df_4['Predictions']]['Predictions']\n",
    "dont_match = df_2.iloc[list(df_4[df_4['Honors_Next_Year'] != df_4['Predictions']].index)]\n",
    "dont_match['Predictions'] = dont_match_preds\n",
    "dont_match.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find entries for which the model correctly predicted to make jump to all-NBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolate true positives\n",
    "df_final = df_2.iloc[df_4.index]\n",
    "df_final['Predictions'] = df_4['Predictions']\n",
    "import re\n",
    "\n",
    "selected_correctly = df_final[(df_final['Predictions'] == 'Selected') & (df_final['Honors_Next_Year'] != 'No_Honors')]\n",
    "selected_correctly\n",
    "\n",
    "honor_this_year = []\n",
    "\n",
    "for i in range(len(selected_correctly)):\n",
    "    previous_yr = selected_correctly.iloc[i]['Year']\n",
    "    plyr = selected_correctly.iloc[i]['Player']\n",
    "    row = df[(df['Player'] == plyr) & (df['Year'] == previous_yr)]\n",
    "    honor_this_year.append(row['Honors'])\n",
    "\n",
    "\n",
    "honor_this_year_edited = []\n",
    "\n",
    "for item in honor_this_year:\n",
    "    honor_this_year_edited.append(re.split(' ', str(item))[4][:-6])\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgoldstein24/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TSP</th>\n",
       "      <th>a/t_ratio</th>\n",
       "      <th>Year</th>\n",
       "      <th>Player</th>\n",
       "      <th>concat</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>MP</th>\n",
       "      <th>Honors_Next_Year</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Honor_this_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1193</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.617315</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>2017</td>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>2017Karl-Anthony Towns</td>\n",
       "      <td>C</td>\n",
       "      <td>21</td>\n",
       "      <td>MIN</td>\n",
       "      <td>3030</td>\n",
       "      <td>Third</td>\n",
       "      <td>Selected</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1464</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600245</td>\n",
       "      <td>1.651163</td>\n",
       "      <td>2016</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>2016James Harden</td>\n",
       "      <td>SG</td>\n",
       "      <td>26</td>\n",
       "      <td>HOU</td>\n",
       "      <td>3125</td>\n",
       "      <td>First</td>\n",
       "      <td>Selected</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4481</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.548404</td>\n",
       "      <td>1.384615</td>\n",
       "      <td>2011</td>\n",
       "      <td>Blake Griffin</td>\n",
       "      <td>2011Blake Griffin</td>\n",
       "      <td>PF</td>\n",
       "      <td>21</td>\n",
       "      <td>LAC</td>\n",
       "      <td>3112</td>\n",
       "      <td>Second</td>\n",
       "      <td>Selected</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7350</td>\n",
       "      <td>3.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.565179</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>2006</td>\n",
       "      <td>Dwight Howard</td>\n",
       "      <td>2006Dwight Howard</td>\n",
       "      <td>PF</td>\n",
       "      <td>20</td>\n",
       "      <td>ORL</td>\n",
       "      <td>3021</td>\n",
       "      <td>Third</td>\n",
       "      <td>Selected</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10233</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.562618</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>2001</td>\n",
       "      <td>Paul Pierce</td>\n",
       "      <td>2001Paul Pierce</td>\n",
       "      <td>SF</td>\n",
       "      <td>23</td>\n",
       "      <td>BOS</td>\n",
       "      <td>3120</td>\n",
       "      <td>Third</td>\n",
       "      <td>Selected</td>\n",
       "      <td>No_Honors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ORB  DRB  STL  BLK       TSP  a/t_ratio  Year              Player  \\\n",
       "1193   3.5  8.4  0.7  1.2  0.617315   1.040000  2017  Karl-Anthony Towns   \n",
       "1464   0.7  5.0  1.6  0.6  0.600245   1.651163  2016        James Harden   \n",
       "4481   3.1  8.3  0.7  0.5  0.548404   1.384615  2011       Blake Griffin   \n",
       "7350   3.4  8.7  0.8  1.4  0.565179   0.576923  2006       Dwight Howard   \n",
       "10233  1.1  4.9  1.6  0.8  0.562618   0.966667  2001         Paul Pierce   \n",
       "\n",
       "                       concat Pos  Age   Tm    MP Honors_Next_Year  \\\n",
       "1193   2017Karl-Anthony Towns   C   21  MIN  3030            Third   \n",
       "1464         2016James Harden  SG   26  HOU  3125            First   \n",
       "4481        2011Blake Griffin  PF   21  LAC  3112           Second   \n",
       "7350        2006Dwight Howard  PF   20  ORL  3021            Third   \n",
       "10233         2001Paul Pierce  SF   23  BOS  3120            Third   \n",
       "\n",
       "      Predictions Honor_this_year  \n",
       "1193     Selected       No_Honors  \n",
       "1464     Selected       No_Honors  \n",
       "4481     Selected       No_Honors  \n",
       "7350     Selected       No_Honors  \n",
       "10233    Selected       No_Honors  "
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to see if model slected any players who weren't repeating as all-nba selections\n",
    "#Potentially diamonds in the rough\n",
    "\n",
    "selected_correctly['Honor_this_year'] = honor_this_year_edited\n",
    "selected_correctly[selected_correctly['Honor_this_year'] == 'No_Honors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The above players were correctly predicted to be all-nba players based on their stats\n",
    "#the previous year - by continuing to build on the model, this analysis could be a useful\n",
    "#tool to identify players poised for breakout years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find entries for which the model incorrectly predicted to make jump to all-NBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n",
      "LeBron James\n",
      "      Year        Player            concat  count Pos  Age   Tm   G  GS    MP  \\\n",
      "3445  2014  LeBron James  2014LeBron James      1  PF   29  MIA  77  77  2902   \n",
      "\n",
      "      ...  ORB  DRB  TRB  AST  STL  BLK  TOV   PF   PTS  Honors  \n",
      "3445  ...  1.0  5.6  6.6  6.1  1.5  0.3  3.3  1.6  25.9   First  \n",
      "\n",
      "[1 rows x 32 columns]\n",
      "\n",
      "2011\n",
      "Karl-Anthony Towns\n",
      "Empty DataFrame\n",
      "Columns: [Year, Player, concat, count, Pos, Age, Tm, G, GS, MP, FG, FGA, FG%, 3P, 3PA, 3P%, 2P, 2PA, 2P%, FT, FTA, FT%, ORB, DRB, TRB, AST, STL, BLK, TOV, PF, PTS, Honors]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 32 columns]\n",
      "\n",
      "2010\n",
      "James Harden\n",
      "      Year        Player            concat  count Pos  Age   Tm   G  GS    MP  \\\n",
      "5721  2010  James Harden  2010James Harden      1  SG   20  OKC  76   0  1738   \n",
      "\n",
      "      ...  ORB  DRB  TRB  AST  STL  BLK  TOV   PF   PTS     Honors  \n",
      "5721  ...  1.0  4.1  5.1  2.8  1.7  0.4  2.2  4.1  15.6  No_Honors  \n",
      "\n",
      "[1 rows x 32 columns]\n",
      "\n",
      "2010\n",
      "Kevin Durant\n",
      "      Year        Player            concat  count Pos  Age   Tm   G  GS    MP  \\\n",
      "5659  2010  Kevin Durant  2010Kevin Durant      1  SF   21  OKC  82  82  3239   \n",
      "\n",
      "      ...  ORB  DRB  TRB  AST  STL  BLK  TOV   PF   PTS  Honors  \n",
      "5659  ...  1.2  5.8  6.9  2.6  1.2  0.9  3.0  1.9  27.5   First  \n",
      "\n",
      "[1 rows x 32 columns]\n",
      "\n",
      "2007\n",
      "Kevin Durant\n",
      "Empty DataFrame\n",
      "Columns: [Year, Player, concat, count, Pos, Age, Tm, G, GS, MP, FG, FGA, FG%, 3P, 3PA, 3P%, 2P, 2PA, 2P%, FT, FTA, FT%, ORB, DRB, TRB, AST, STL, BLK, TOV, PF, PTS, Honors]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 32 columns]\n",
      "\n",
      "2006\n",
      "Blake Griffin\n",
      "Empty DataFrame\n",
      "Columns: [Year, Player, concat, count, Pos, Age, Tm, G, GS, MP, FG, FGA, FG%, 3P, 3PA, 3P%, 2P, 2PA, 2P%, FT, FTA, FT%, ORB, DRB, TRB, AST, STL, BLK, TOV, PF, PTS, Honors]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 32 columns]\n",
      "\n",
      "2006\n",
      "LeBron James\n",
      "      Year        Player            concat  count Pos  Age   Tm   G  GS    MP  \\\n",
      "8037  2006  LeBron James  2006LeBron James      1  SF   21  CLE  79  79  3361   \n",
      "\n",
      "      ...  ORB  DRB  TRB  AST  STL  BLK  TOV   PF   PTS  Honors  \n",
      "8037  ...  0.8  5.2  6.0  5.6  1.3  0.7  2.8  1.9  26.5   First  \n",
      "\n",
      "[1 rows x 32 columns]\n",
      "\n",
      "2005\n",
      "Kevin Durant\n",
      "Empty DataFrame\n",
      "Columns: [Year, Player, concat, count, Pos, Age, Tm, G, GS, MP, FG, FGA, FG%, 3P, 3PA, 3P%, 2P, 2PA, 2P%, FT, FTA, FT%, ORB, DRB, TRB, AST, STL, BLK, TOV, PF, PTS, Honors]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 32 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Isolate false positives positives\n",
    "selected_incorrectly = dont_match[dont_match['Predictions'] == 'Selected']\n",
    "\n",
    "honor_this_year = []\n",
    "\n",
    "for i in range(len(selected_incorrectly)):\n",
    "    previous_yr = selected_incorrectly.iloc[i]['Year']\n",
    "    print(previous_yr)\n",
    "    plyr = selected_correctly.iloc[i]['Player']\n",
    "    print(plyr)\n",
    "    row = df[(df['Player'] == plyr) & (df['Year'] == previous_yr)]\n",
    "    print(row)\n",
    "    print()\n",
    "    honor_this_year.append(row['Honors'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No one incorrectly selected who is way off base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this case, the evidence of true positives and no glaring false \n",
    "#positives is more important\n",
    "#than false negatives - it is more important to find diamonds in the rough than \n",
    "#to scrutinize over every option you might have missed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
